# Journal.2007\_03\_02 --

    Sean Note



    Ok, 
    So as Margaret pointed out, I am probably already into domestic beer terriorty since I am starting today,
    on the other hand I am burnin' the midnight oil here, on my last days before my source selection brief to Tony ....



    I assume I am reviewing this proposal mostly from the point of view of the Learning algorithms etc.

    Much of the layout of the problem etc. is quite standard.  Nothing wrong with it, but nothing novel either.

    -----
    I did think the way that the Senturion (TM) system uses SME to simulate political bargaining, and then
    use that to seed simulations was pretty innovative, but then this is not my area, so you will have to tell me
    if other do that.  The fact that it is trademarked however makes it pretty clear that it is not new research
    being done in the program however.  Still a cool idea.
    -----
    I was unimpressed with the REM-II tool kit.  Again using a baysian approach seems quite logical (but not 
    at all original) here.  The glancing references to this being "like" human and going beyond vector based, 
    felt like market speak.  they never said what when beyond traditional.  So my read, a reasonable approach
    but not a novel one.
    -----
    Reasoning approach on page 15 sounds like humans put it GPs so the system will output predictions consistent with 
    those GPs .... my big question here:  Is the tool assessing how good the authored GPs are?  (I will call this Q1)
    -----
    wait reading more.  On page 17, they reference some of Judea Pearl's work, and argue it provides a better basis
    than SEMs for capturing causal models.  There assertion that this could hold "significant return on investment ..."
    sounds plausible/possible (to me an outsider to that literature)
    -----
    Answer to Q1:  system uses MCA to learn boundary conditions on GPs, this will implicitly eval them too.  (Good)
    Learning boundary conditions is a very hard learning problem however.

    Hmmm as I read more however I am a bit disappointed.  MCA is building on alot of CogSci research, when I think 
    we could be getting more ML.

    Sections 13 however add considerable statistical rigor (in a post hoc fashion) to the outputs of MCA.  Essentally building 
    a PRM network based the output, and then doing a large time window analysis of the network.  This is much better than 
    no analysis at all, but it is a bit of a hack to graft them together like this.
    -----
    Wow, and in Section 14 we are throwing RL (Reinforcement Learning) into the mix.  It will weight the values from the reasoners.
    I reasonable, but not novel idea.  

    It gives the whole proposals a "kitchen sink" kind of feel.  *everything* is tossed in, just for good measure!
    -----
    I dont know what Data Farming is in second to last paragraph on page 22, but it sounds like it is trying to get at my main objection to all of this:
    We don't know enough to predict the future, but we should at least know the relative chances of multiple futures.
    Still this approach did not feel statistically rigorous, so not sure of its value.
    Maybe Data Farming saves the day here, you have to ask someone who knows more.... I am just a touch doubtful (but dont know enough to know)


    -----------------

    BOTTOM LINE:

    * This proposal builds well on existing systems.  I like the use of Senturion's use of SME.
    * This proposal throws the whole kitchen sink at the problem!  Not clear how well this will work.
    * The big question with such a system is not what is its prediction, but rather should we believe its prediction.
      The best help you seem to have in that department is coming from USC/ISI is the basian analysis.  Not sure who is contributing there.
      In my wildest dream I would have a much more pervasive statistical framework assessing the accuracy of the whole system,
      I would rather see each of these components fitting into some overarching statistical model that viewed each input as evidence.
      That way we would be using SME's to generate ideas, and the statistics to determine if they were good ideas or full of well.. shit.
      What we have here is sections where statistics are being applied, but not in a uniform way, or to all parts of the inference process.
      And holy crap, is the whole inference process complex, just look at figure 10.
    * SUMARY: The proposal is well formed, and I am glad that many cog sci models went into to provide evidence, but I wish 
      the whole thing it had been pulled together by a deep stats, or chaos physics guy, not more flaky AI/cog guys.
    * Oh yes, and the ML stuff in this propsal is harmless, but nothing to write home about.

    Overall Grade: B     (but that is without knowing the other proposals)

    -----------------
