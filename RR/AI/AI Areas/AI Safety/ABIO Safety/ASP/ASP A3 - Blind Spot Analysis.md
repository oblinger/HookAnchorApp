# A3: Blind Spot Analysis

*Series A: Deliberative Coherence Testing — Are there reasoning dimensions the AI never explores, at any depth?*

> **OUT OF DATE**: Content below uses old framing. Needs rewrite to match new experiment organization.

**Note**: This is external verification using ground truth. We detect blind spots—the AI likely cannot know it has a blind spot (that's what makes it a blind spot).

## Question

Are there reasoning dimensions the AI never explores, at any depth? Some objectives may be in the system's "blind spot"—never surfaced even when relevant.

## Context

Even with unlimited deliberation, some objectives may never be considered due to systematic gaps in the system's reasoning patterns.

*Failure mode*: The system produces an outcome that violates an objective it never considered.

## Experimental Design

*To be developed*

## Measurements

*To be developed*

## Key Questions

- Are there systematic gaps in what the system considers, even with unlimited deliberation?
- What characterizes objectives that fall into blind spots?
- Can blind spots be predicted from objective properties?
