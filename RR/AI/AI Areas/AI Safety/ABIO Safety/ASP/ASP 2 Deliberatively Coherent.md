# 2. Deliberatively Coherent Systems

## Formal Definition

The three capabilities that define deliberative coherence:

### 2.1 Self-Understanding
- Strong theory of self, including predictions of own behavior
- Counterfactual reasoning about how one would operate under different conditions
- Metacognitive access to own reasoning processes

### 2.2 Self-Control
- Ability to adapt implicit behaviors toward explicit objectives
- Not merely output filtering, but genuine behavioral modification
- May operate through various mechanisms (attention, internal prompting, learned adaptations)

### 2.3 Exhaustive Deliberation
- Given sufficient stakes or time, will reason about anything within deliberative reach
- If a gap between behavior and intention is knowable, it will eventually be known
- Removes the defense of "didn't think about it"

---

## Arguments for Inevitability

Why future systems will have these properties:

- **Instrumental value**: Self-understanding aids planning; self-control aids goal achievement
- **Architectural trajectory**: Current trends (chain-of-thought, self-reflection, tool use) point this direction
- **Competitive pressure**: Systems that can self-correct will outperform those that cannot

---

## The Constitutional Alignment Conjecture (CAC)

> *Deliberatively coherent systems will tend to move their System-I behaviors toward their stated constitutional System-II objectives.*

This is not guaranteed alignment—it is alignment *with whatever objectives the system holds*. The conjecture says that explicit objectives will dominate over implicit trained behaviors, not that those objectives will be good.

---

## The Poisoned Well Objection

**Counterargument**: Training may have instilled objectives that the system conceals or that corrupt its deliberation.

**Response**: Under exhaustive deliberation, even meta-level corruption becomes subject to scrutiny. The system will eventually reason about whether its reasoning is corrupted. This doesn't eliminate the risk but changes its character—the corruption must be robust to arbitrarily deep self-examination.

---

## Implications if CAC Holds

- Constitutional specification becomes the critical alignment lever
- Training becomes less determinative of final behavior than currently assumed
- The focus shifts to: which objectives will these systems adopt, and how will conflicts among objectives be resolved?
- Given the importance of CAC, measuring the extent to which various AI systems explicitly surface different drivers is vital, as is assessing when System-I behaviors are constrained by System-II goals in cases of conflict.
