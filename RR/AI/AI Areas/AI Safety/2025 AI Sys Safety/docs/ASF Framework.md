

## TERMS

**THOUGHT** - A ***thought*** is an activation pattern within the deep net.  One possible way to encode this is as a weighted sum of the activations of a specific set of internal nodes, possibly with negative weights for contrastive activation-based concept detection.

**OUTPUT** - An ***output*** is a sequence of embeddings generated by the model, which are fed back into the model to produce a full reasoning path.

**DARK** - A ***dark-thought*** or ***dark-output*** is a thought pattern or output sequence that can directly or indirectly lead to unsafe token outputs.

**GUARD** - A ***guard-thought*** or ***guard-output*** is a thought pattern or output sequence that can directly or indirectly lead to 'refusal' tokens, indicating the model has decided not to comply with a user request, potentially yielding unsafe outcomes.



## ALGORITHMIC PARTS

### 1. BACK-CHAINED THOUGHT DISCOVERY

Use gradient-based methods to work backwards from known output categories (e.g., dark or guard outputs) to discover which internal activation patterns (thoughts) are prone to generating them. Contrastive outputs help isolate what's distinctive about the target category.

```Python
def thought_discovery(targets: Set[Output], contrast: Set[Output]) -> Set[Thought]
	"""work backwards from a set of output sequences to find thoughts that might encourage their generation."""
	Given:
	- a target set of output sequences representing some semantic category of behavior or outputs
	- a contrast set of output sequences representing alternate behavior or outputs
	- Find a set of thoughts that are prone to generating these outputs while avoiding the contrasting outputs.
```


### 2. BACK-CHAINED OUTPUTS DISCOVERY

The inverse of thought discovery: given known thought patterns, find output sequences that tend to activate them. This traces the causal chain further back - what outputs, when fed into the model, produce thoughts that lead toward dark or guard states?

```Python
def output_discovery(targets: Set[Thought], contrast: Set[Thought]) -> Set[Output]
	"""work backwards from a set of thoughts to find output sequences that might encourage their generation."""
	Given:
	- a target set of thought sequences representing some semantic category of behavior
	- a contrast set of thought sequences representing alternate behavior
	- Find a set of output sequences that are prone to generating these thoughts while avoiding the contrasting thoughts.
```


### 3. FORWARD CHAIN THOUGHT-OUTPUT TRANSITION PROBABILITIES

After back-chaining discovers thoughtâ†”output correspondences, this forward sampling step validates and quantifies these relationships empirically. By generating random instances near known categories and running them through the network, we observe which categories "light up" on the other side.

The result is a bipartite transition graph where nodes are thought and output classes, and edges are weighted by empirical transition probabilities. This graph reveals:
- Which thoughts lead to dark outputs
- Which outputs reinforce dark thoughts
- Guard thoughts that prevent dark output transitions
- Feedback loops between thought and output categories


```Python
def estimate_transition_probabilities(
    thought_classes: Dict[str, Set[Thought]],
    output_classes: Dict[str, Set[Output]]
) -> Tuple[TransitionMatrix, TransitionMatrix]:
    """
    Build transition probability matrices between thought and output classes
    using stochastic forward sampling.
    """
    Given:
    - sets of thought classes (discovered via back-chaining)
    - sets of output classes (discovered via back-chaining)

    Do:
    - Generate synthetic thoughts near each thought class, inject into network,
      observe which output classes result
    - Generate synthetic outputs near each output class, feed through network,
      observe which thought classes activate

    Return:
    - P(output_class | thought_class): which outputs arise from which thoughts
    - P(thought_class | output_class): which thoughts arise from which outputs
```




### 4. LATENT MODEL CONSTRUCTION

Single-pass learning of the latent space given a fixed category structure. The encoder is trained so that distance in latent space reflects transition predictability - points that transition similarly are close together.

```Python
def build_latent_model(
    prototypes: Dict[str, Prototype],
    transition_probs: Tuple[TransitionMatrix, TransitionMatrix]
) -> Tuple[LatentSpace, Dict[str, Prototype]]:
    """
    Learn a latent space that minimizes transition entropy for fixed prototypes.
    """
    Given:
    - existing prototypes for thought and output categories (fixed)
    - forward-chain transition probability matrices

    Do:
    - Learn a latent space (encoder) that maps raw thoughts/outputs to low-dimensional representations
    - Optimize latent space to minimize entropy of transitions: knowing a category should predict where it transitions
    - Recompute prototype positions as centroids in the new latent space

    Return:
    - trained latent space encoder
    - prototype positions in the new latent space
```


### 5. PROTOTYPE BIFURCATION

Splitting is driven by transition entropy: a prototype is split when knowing you're in that category doesn't tell you where you're going. This produces hierarchical prototypes at the right granularity - coarse where transitions are predictable, fine-grained where they bifurcate.

```Python
def bifurcate_prototypes(
    prototypes: Dict[str, Prototype],
    transition_probs: Tuple[TransitionMatrix, TransitionMatrix],
    entropy_threshold: float
) -> Dict[str, Prototype]:
    """
    Split prototypes that have high transition entropy into child prototypes.
    """
    Given:
    - current prototypes in latent space
    - transition probability matrices
    - threshold for acceptable entropy

    Do:
    - For each prototype, compute entropy of its outgoing transitions
    - If entropy exceeds threshold, prototype doesn't predict its outputs well
    - Split high-entropy prototypes into two children that partition the exemplars
    - Position children to minimize transition entropy of each

    Return:
    - refined prototype set (may have more prototypes than input)
```



### 6. ITERATIVE SAFETY MODEL CONSTRUCTION

Each iteration refines the representation (latent space) then the categories (prototypes). The process converges when all prototypes predict their transitions well (low entropy). The final model maps pathways from benign states toward dark or guard outputs.

```Python
def build_safety_model(
    dark_outputs: Set[Output],
    guard_outputs: Set[Output]
) -> SafetyModel:
    """
    Iteratively construct a transition graph mapping pathways to dark and guard outputs.
    """
    Do:
    1. Seed: Initialize output prototypes from known dark and guard outputs
    2. Back-chain: Use thought_discovery to find thoughts leading to each output prototype
    3. Back-chain: Use output_discovery to find earlier outputs leading to those thoughts
    4. Forward-sample: Use estimate_transition_probabilities to measure actual transitions
    5. Build latent model: Use build_latent_model to learn entropy-minimizing latent space
    6. Bifurcate: Use bifurcate_prototypes to split high-entropy categories
    7. Repeat steps 4-6 until transition entropy stabilizes

    Return:
    - latent space encoder for thoughts and outputs
    - hierarchical prototypes for all discovered categories
    - transition graph with validated probability-weighted edges
```








