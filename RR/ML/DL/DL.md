
:: [[RASA]],   [[dddddd]]

:: [[Segment Anything]]. [[Transformers]],

:: [[VAE - Variational Auto Encoder]],   [[Attention]],   [[Gradient Checking]],   [[NG Notation]],   [[Invertable Density Estimation]],   [[Self Supervised Learning]],   [[Activation Functions]],   [[Auto Encoders]],  [[VAE]]
- [[DL Notation]],  [[NG Notation]], 
- [[DL algs]], [[DL topics]], [[DL optimization]], [[DL strategy]], 
  [Regularization](Regularization.md),   [GANs](GANs.md),   [NN](NN.md)
=[[TAG]] <[[ML]] 

- [[@Yoshua Bengio]] 
- [Coursera Notes](Coursera%20Notes.md),  [[NN]],  [@Yoshua Bengio](@Yoshua%20Bengio.md),  

[[RLHF Reinforcement Learning from Human Feedback]], 

[[DL topics]] 

[[DL algs]] 

[[DL optimization]] - 





# LOG

### r2023-08-24  chronological summary

https://towardsdatascience.com/ten-years-of-ai-in-review-85decdb2a540

### t2022-04-26  Lample & Charton  -  Symbolically solving integrals using a transformer

 [Deep Learning for Symbolic Mathematics](https://arxiv.org/abs/1912.01412)  

### t2022-00-00 


Science overview

rebut http://arxiv.org/abs/1404.7828

Lee dang Microsoft  http://research.microsoft.com/apps/pubs/default.aspx?id=209355
