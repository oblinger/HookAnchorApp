

Cross Entropy Loss
-?-
- loss = sum{ y_i * log( y_hat_i ) } = nn.CrossEntropyLoss()
- Same as nn.BCELoss() given a two class setup


[[Logistic Regression - Logit Function]] 


[[Loss Functions]] 

#dl 