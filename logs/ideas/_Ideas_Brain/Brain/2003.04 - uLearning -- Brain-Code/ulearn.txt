UniversalLearning
* nuggets::  
* design::  
* DefiningTasks::  
* AutonomicComputing::  


_______
* bias is output from leraning
* Computable
* Small lex delta means limited hypspace delta
* Understandable

- Concepts are recursively built up from constituents automatically
  as thinking is occuring.



_______________________________________________________________________________
We can build complete-control systems, 
- we dont have systems that bootstrap rep & alg.
- we wont program the first thinking machine  (except at the lowest level)
  we wont even architect the most interesting peices

Is common sense reason primal or ephemeral in human cog processing?
Is FO-like (variable binding) resoning primary or ephemeral?

right rep @ right time.
learning by telling: sub-graph mapping and graphing



Q&A from TREC  Dave Fruchie under alan Marwick



Dan bought "the lord of the rings" for $5 

DB:{Dan Buyer}
LOTR:{"lord of the rings"}  <-really structure represeting parse
LR:{BookTitle LOTR}
BC:{PurchaseAmount C1}
C1:{DollarsCost Integer5}

Lots of activated structures
BC:{LOTR C1}
BB:{??? Buyee}



Node: design, Up: UniversalLearning
* Menu:                                 

* associator::  






THE ASSOCIATOR (V1.0)
- Accepts a stream of tuple sets, and
  remembers patterns seen previously.


GENERALIZATION
- A Grouping of tokens based on their role in a recurring relationship
- A Pattern with fewer constraints


A PROCEDURE
- Graph of internal contexts, where each context is has an associated
  search state.

AN ACTIVE CONTROL CONTEXT -- A SEARCH STATE
- A search control strategy (controled by internal context)
- Controls which associatations are noticed


ACTIVATION STATE (SEARCH STATE)
- State of activivation for all nodes


THINKING
- Following associations (controlled by the search state)


ACTIONS
- Outputs (motor control)

FEEDBACK
- Control over training???
- Positive reinfore of search that produce novel connections or understanding
  CONNECTIONS previously seen tokens (which are combos of tokens)
  UNDERSTANDING -- state achieved by subconscious procedure that attempts
  to map input graph into memory


________
MODELING
- An external entity generates a tuple stream.
- A model attempts to mimic the association behavior generated by stream.
- Attepts to predict important concepts
- Both world model (projection) and thinking model. (reflection)

__________
REFLECTION
- System can see its thinking
- It sees the active control contexts
- It sees it status

- STATUS.  Concept that expresses some aspect of the status of thinking:
  Productive,Unproductive,Novel,Important


_______
DESIRES

- Hardwired objectives expressed in model of world, in thinking status

- Adopted objectives ????

- IMPORTANCE.  Association with a concept that controls thinking.


___
>>> HOW DO WE LEARN IN THIS SYSTEM?
- By demonstration of the procedure


___
>>> HOW DO WE CAPTURE AND REASON ABOUT RELATIONS? (FIRST ORDER)
- Tuple reasoner  (Positional set reasoner)



Changing thinking behavior under contrl of reflection


Node: associator, Up: design
* Menu:                                 

The associator save and retrieves patterns.


FEED FORWARD ACTIVATION
- Patterns trip other patterns
- Detect surprising connections
- FO structure recognized and collapsed into non-FO pattern nodes.



RETRIEVAL METHODS
- Direct retrieval of tokens, patterns, and threads
- Retrieval of similar elements to a target
- Retrieval of containing elements from fragments of elements.


ASSOCIATION
- Creation of new tokens to represent the


TOKEN
- A TOKEN is a newly created symbol token.
- The symbol is "defined" by a vector of activated "children" tokens.
- It is the basic building block for patterns stored in the associator.


PATTERN
- A pattern is a gensym defines an observed or imagined pattern among a
  set of tokens.
- For example "Dan bought the book" could be captured as:
  D="Dan", B="Book", P="Purchase", P1="Purchaser", P2="Purchasee",
  DP={D,P1}, BP={B,P2}, PATTERN=DPB={D,B,P1,P2,DP,BP,P}

THREAD
- A sequence of patterns.



Node: DefiningTasks, Up: UniversalLearning
* Menu:                                 

* Learn model of fluid from many stmts.

* Learn to use a rerepresentation in a domain.

* Reproduce a shown procedure, or known fact.

* Generalize?

* Apply an effective line of reasoning in a related problem.

* Learn what is a "related" problem.

* Learn knight fork from board positions

* Learn about translation and rotation invarience from 
  board positons????



Node: AutonomicComputing, Up: UniversalLearning
* Menu:                                 



Build Scaffold model of graphs representing computing systems,
and code algorithms for diagnosis and recovery over general graphs.

Have the system *learn* the many instantiations of this model.



(1) Hard code
    - Instrumentation for system inspection
    - Instrumentation for operator monitoring
    - Instrumentation for action exeuction (optional)

(2) Write
    - Simple graph model of computing system
      (specific system would be a complex expansion/instantiation of this
       simple graph)
    - General algorihms for diagnosis; inspection and repair
      over these graphs.

(3) K-Acquistion system fills in details in scaffolding
    - Restricted learning of expectations and detectiong
      of triggers from watching system and operator.
    - Active leraning of PK.
    - Learning from text????




__ ___ _____
So you learn:
- TCP/IP drivers for Win2000 is a communication layer.
- They run only when the hardware port is working and connected.



