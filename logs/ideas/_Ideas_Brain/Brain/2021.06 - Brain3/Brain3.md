  [BrainDomains](BrainDomains.md)


# ### LOG ###
### 2022-01-16 - Using GANs

INPUTS -- Raw experiential input nodes
DNET -- Deep Net of CNN/RNN abstraction layers with no or limited supervisory signal

SUB -- Subsumption DAG -- A subsumption DAG with exclusion links
FWD -- Forward propagation network -- Forward propagation network

CTX -- Context Hiearchy -- 
INTENT -- Intention DAG -- 

### 2022-01-11 - combining DL and logic

https://medium.com/ontologik/ai-cannot-ignore-symbolic-logic-and-heres-why-1f896713525b

Uri, I tend to agree.  Still after having simulated such a thing enough it seems we can somehow the generalize reasoning pattern w/o requiring the simulation step.




So I think there is still a profound gap yet to be filled between DL, simulation and logical representations of the same things.




you are an NLP guy and a DL guy what are your thoughts:




it seems to me we have evidence that the human mind is a sequence of lingual/semantic token generalizer.  e.g. I can tell you when one should insert the determiner 'the' in a phrase, yet it takes WORK for me to tell you (or invent) the rule I am using.




This suggests to me, that perhaps generalizing such grammars is the native ability, and things like reasoning, logic, algorithm following etc. are co-opted versions of this underlying native ability.




if this hypothesis is correct, then the gap to be filled is the mechanism that drives executive reasoning in a way that follows grammar structure -- but in this case it is the grammar of thinking patterns.




the question for me is how to train such systems.  with language it is easy.  we have many examples of language captured in digital form.  but thinking is not as easy.




it is difficult for a person to even speak or write thoughts as fast as they come, and even then, we have much smaller corpora to work with.




how do babies do it?  Do you think humans ruminate enough that their children can hear enough of the reasoning pathways that they can generalize the thinking paths (rules) by listening to adults?






_
### 2021-06-18 - AML - Artifical Machine Learning   (formalization & claim)


CLAIMS
- REPRESENTATIVE TASK LEARNING
	- The learning capacity of an agent is analogous to the capabilty of a rock climber:
		Measured by the difficult of the 'hardest' substep they are able to perform.
	- Learning hardnesses:

PARADIGM
- IMITATIVE --
- PRACTICE BASED -- 
- CORRECTIVE FEEDACK -- 
- ROTE -- 

DIFFICULTY
- NON-PARAMTRIC -- Non-parametric concept formation
- RECURSIVE -- RELATIONAL -- Recursive relational concept reification and application
- MULTI -- implicitly combined learning steps w/o intervening validation
- PROCESS -- 
- POST GENOMIC -- learned by algorithm developed w/o knowledge of task; 
	configurned entirely by knowldge that could have been recurively learned
- META LEARNING -- The learning of strategies about strategies
- META COGNITION -- Reasonging about ones reasoning (& about failures / gaps in it)
- MENTAL -- learning of processes that are entirely mental
- SCAFFOLD -- learning that leverages scaffolding explicitly or implicitly provided
- BOOTSTRAPPED -- learning built entirely from prior learning
- HINTING -- acquisition greatly facilitated by instructor hinting
		words, pointing, 
- FEW SHOT -- Learning from one or few presentations
- ADAPTED -- Applying learned capability to related domain


- theory of mind
- social pragmatics
- Multi-step mental processes -- 
- Linguistic scaffolding -- concepts, expressions, relevant subtargets, strategies
- Meta-stratgic processes -- strategies informing both learning and execution


Artifical Machine Learning (AML)

AML is a _cooperative_ process where an agent (called the student) acquires some knowledge or performance capability (called the target) utilizing a context (call the environment) that has been intentionally crafted other agents (called the instructors).

A centeral aspect of AML is this cooperative setting, it always efforts on an instructor's part to in some way support the student's success in acquiring the target.  
Here are aspects that are often part of this AML process:

INSTRUCTOR INSIGHTS
- The instructor has aprioi knowlege of how a student might perform we attempting to learn given targets.  They use this knowledge strategically and collaboratively to arrange for the student's success in target acquisition.  Specifically they:
	- They know which sub-targets are likely to support the learning of given super-targets.  They can use this to provide 'curricular' support for the student.  that is to organize larger targets into specific progressions of sub-targets in a way that maximally simplifies that learning task.
	- They know which approaches to learning specific targets are likely to be successful and how much effort is likely to be required.  This allows the instructor to slect appropriate lessons within the curricular structure.

LESSON MATERIALS
- CURRICULAR SUPER STRUCTURE -- 
- EVALUATION PROTOCOLS --
- TRAINING PROTOCOLS -- 
- TRAINING MATERIALS --
- WORLD SETUP --
- DEMONSTRATIONS --


THE WORLD
- Settings where the student may practice the target in a way that they can assess their proficiency with the target.

THE CURRICULUM
- An intentionally structured ladder (DAG) of lessons that are each intended to provide some sub-target which is useful in acquiring the final target.


_
### 2021-06-18 - AGI Agenda intro text

GAI built from Real Machine Learning not Machine Discovery



When Leibniz came to understand Calculus, we don't say he LEARNED it, we say he DISCOVERED it.  When I came to understand Calculus, we don't say I DISCOVERED it, we say I LEARNED it.  The distinction is quite an important one: learning involves the intentional collaboration using materials and interactions.  It is between person(s) who has some capability or understanding (the instructor), and other person(s) who do not have that capability or understanding (the student).  Discover on the other hand occurs without any collaboration from an instructor.  Often discovery is employed when there can BE no instructor since humanity does not yet know this thing.

Discovery is generally much much harder than learning.  If we gave thousands from antiquity their entire lives to come to understand how to derive volumes for arbitrary solids few if any would succeed.  Today many or even most would succeed.  This is a very visceral example of just how much harder discovery is than learning.

It turns out the "Machine Learning" employed today is most often actually a form of "Machine Discovery".  Machine Learning is primarily an Engineering discipline.  The goal is often (but not always) to use ML to aid some human to know a thing that is not presently known by anyone.  This is fine as an Engineering discipline; indeed ML is productively used to model a great many things that humans don't have models for.

But, we argue it is entirely WRONG as the basis for GAI.  It is too hard, and it is needlessly hard for the many many things a GAI must come to know.  Its as if we stranded a baby on a deserted island with a bunch of lab equipment, and came back 30 years later and expecting to find a post graduate in physics or chemistry.  We all intuitively understand without guidance, feedback, distilation of key insight derived over the melinnia we understand the baby will not get far at all.  So why do we expect GAI to bootstrap from such an impoverish setting?  It is just CRAZY, but this is precisely the tact that much (but not all) of current AI takes.

Here we attempt to formalize "real machine learning"



they do not currently know.  In this 

 
 understanding calculus

want to know if a particular person is likely to be able to understand Calculus the most important question to ask first is when where they born.  If it is before the time of Leibiz it will be EXCEEDINGLY difficult for them to 



_
### 2021-06-06 - Inputs to ML

- FPN -- FORWARD PROPAGATION NET
- A/V -- CONVOLUTED AUDIO/VIDEO/SENSOR INPUTS

_
### 2021-04-30 

* INTELLIGENT AGENT / KNOWN CAPABILITY
* COOPERATIVE PARTNER
* NO SHARED CONSENSUS DEFINITIONS
_