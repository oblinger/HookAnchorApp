

  E N G I N E S   O F   C O N T R O L
  = = = = = = = = = = = = = = = = = =

# Book

## ===== INTRODUCTION =====

### preamble 
Several noted scientists have warned that Artifical Intelligence may ultimately poses a threat to humanity.  It seems, however, that most AI researchers and the population at large believe that while this may be true, it is in some distant, hazy future -- surrounded by so many unknowns that it is impossible to assess if there really is a threat, must less to do anything productive today to prepare or act against that threat.

In this book, we argue that this is not so, instead that many aspects of the threat can be (and actually are) already understood.  Further, that it is pressing that we do understand this threat as clearly as possible as fast as possible.  It seems a primary determiner of how this threat will play out is a function of its developement (1) relative to the speed of development of complementary technologies, and (2) the degree to which humanity can collaborate at expense of their individual shorterm interests to shape outcomes that are in everyones interest.

This book lays out arguments for these claims based on the evidence we have today.  But we wont act decisively until we collectively have clarity.  Thus, more ambitiously this book aims to gavanize action to gain the remaining clarity needed for decisive action, before complementary technologies make this treat immediately uncontrollable right at is birth.
### GLOSS OF THIS BOOK'S THREAT ARGUMENT

The point of this book is to convince the broadest audience that there is a threat, it is credible, and our speed in understand this threat will determine what options we have at our disposal once we do collectively decide to act upon the threat.  So here in encapsulated form, is an abbreviated version of the argument made in more detailed form in the 'defining the threat' section.  The argument:

(1) **SEED VIABILITY** -- It is possible in principle to build a seed AI -- an embodied intelligence that grows up to be able to emulate many of the functional form of reasoning that humans exhibit today.  Why?  humans are an example of such a seed intelligence, and there seems to be nothing magic about human physiology that it would be impossible to implement a different seed upon some other base substrate -- for example, modern computers seem a possible substrate.  Section ZZZZ considers in detail evidence that building a Seed AI appears likely to be viable.

(2)  **SPEED DOMINATES** -- If we ever do build a seed AI on our computing substrate, the single most important consideration about what happens next will be the power of the processors that this seed AI is executed upon.  Specfically it seems, given a collection of embodied intelligent agents of similar intellectual capacity where some agents execute their thinking many many orders of magnitude faster than the rest, those 'fast' intelligences will tend to dominate the others mentally then later physically.   The chapter **DEFINING THE THREAT** argues why 'mere' speed along with other capacities expected of a digital intelligence are likely to result in domination.

(3)  **INEVIBILITY OF EXECUTION** -- Construction of a seed AI which if possible, in principle, today, given our current trajectory will be executable in practice some day.  Further, once it is practical for a small team to build a seed AI, we will be, as a spiecies, unable to stop ourselves from building it.  Section ZZZZ outlines why it is implausible that society could avoid producing a seed AI in the case that it were possible to build one.


Therefore, in this book we argue that we should build such a seed AI, and build it sooner rather than later.  Specifically we should construct it before the computational resources will be available to this AI that it would immediately be in a position of dominance.
### WHY ASSURANCES SHOULD NOT ASSURE US

~~~~rewrite intro
Many AI researchers today view the prospect of a "killer AI" to be  almost comically improbable.  We believe much of this skepticism stems from the paltry performance of today's AI system (as measured against the performance persumably needed for a killer AI).  Also this skepticism stems from the large array of things we know humans can do, yet we as reseracher's don't know how to construct systems that can perform these many feats.

**WHY ASSURANCES SHOULD NOT ASSURE** -- For each voice that has sounded the cry of alarm, there have been multiple who have voiced either skepticism at the alarm, or assurance that there is no immediate danger.  Here are the reasons why I believe many of these assurances are misplaced:
~~~~



**PERFORMANCE IS THE WRONG MEASURE OF PROGRESS** -- This assurance is based on the current capacities of AI and ML systems relative to human capacities.  In this book we agree with the skeptics that the gap is amazingly large, and the progress in closting this gap is slow.

Later in the book we argue that todays AI and seed AI are really not constructed in the same ways, and so the performance of the former provides little evidence for the distance remaining according to the latter.


**UNDERSTANDING IS A FAULTY MEASURE OF PROGRESS** -- Constructing AI systems or learning systems that are human comparable for even very narrow task domains is currently very expensive or simply impossible.  Thus it will be along time before we can create a human comparable AI.

But this assumes we need to understand it, in order to build it, in section XXX we argue that building a seed AI would not involve the domain understanding and encoding that we currently understake  in order construct the seed itself.  If that turns out to be true, the arguments about present day difficulties and complexities in building and configuring AI and ML systems will be irrelevant.


**A "RIGHT" MEASURE OF PROGRESS** -- 

what the fuck was I going to put here?
### LEVELS OF EVIDENCE

	This book aspires to document the consequences of technologies that we have yet to build -- this requires a certain amount of speculation.  There is a tradeoff between the specificity we choose to operate at and .....

	Thus there is not one best level to consider this issue.  The coarses models make the fewest specific assumptions instead relying on broad trends and argument, thus apply to broadest set of futures, but also are in the least concrete in the connections they make since.  Stories told about the interplay of very specific capacities, agendas, etc. are far more concrete in the connections they make, but are also more suseptible to invalidation, in the case that one of the many more assempled connections turns out to not hold as expected.
	
	Here we consider a range of analyses regarding how GAI will evolve:

#### LEVELS

##### LEVEL 1 EVIDENCE -- Reasoning From Macro Trends

	LEVEL 1 -- Arguing Directly About Quantitative Outcome Trends -- At this level of argumentation observations, assertions, and justifications are made directly at the level of key quatitative measures relating to computational abilities.  Ray Kirtzweild's book ``Singuarity'' holds many examples of such justifications.  He measures thinks like row computational speed, or complexity over time, and discussion why such trends should or should not hold in the future, and what consequences will occur if those trends to hold in the future.  The distinguishing characteristic of these level 0 arguments is that they generally do not descend to the level of the spectific technologies and agendas involved which might cause the trend to continue.  Instead they look empirically at the trend in the past.  These justifications focus on those general properties of the world that the author argues were broadly responsible for the many specific historical events which make the past trend, and then argue that these same properties will continue the trend into the future at least for the required period for their analysis.

	The advantage of these arguemnts is that they generally have fewer 'moving parts' to justify, and fewer specfics that if wrong would invalidate the whole argument.  The disadvantage is that the gaps between the assertions is commesurately quite large.  It is hard or impossible to really be sure that antecedents the athor points to are really those generating the consequences seen, or whether there are other un-named antecedents that were also needed, but will not be true in the future.

	I recall the population explosion arguments of the 1970s and 1980s.  At the time I was quite convinced that we had a massive inescapable meltdown in humanities future.  It is startling to me how quickly such an in-escapable outcome because irrelevant with the single counter trend that increases in wealth and education seems to reliably and dramatically reduce reproduction rates.  In the same way, trend arguements can be invalid in ways that simply cannot be seen by looking at the argument itself.  Its flaw comes from a factor not considered.

	Still such arguments have their place, often they are the only arguments one can make at the greatest distances into the future, since they don't depend on the specfics of the technologies they discuss.

##### LEVEL 2 EVIDENCE -- Reasoning about a specific approach holistically

	LEVEL 2 -- Reasoning about the interplay and consequences of specfic capabilities and agendas.

	At this level we are often also discussing trends and their future consequences, but we are doing so at multiple intermediate levels.  We are exploring some web of interrelated trends at at least two or more levels of justification.  These arguments can be far more specfic about the connections between the one capacity and another.  For example evidence about the availability of birth control and subsequent birth rates would be an example of a level 1 realationship in that such a connection if established empirically might be reasoned about in much greater detail than empirical results about overall population growth.  The former connection is much narrower in scope and is affected by fewer things.   (I DONT LIKE THIS EXAMPLES AS AN ARGUMENT)

	The brief gloss of an argument is a level one argument (allbeit a simple one).  In the later chapter 'defining the threat' we provide a more indepth level 1 argument.

##### LEVEL 3 EVIDENCE -- Reasoning about individual components / properties required by the approach.

LEVEL 3a -- Implementation Sketch

Ultimately many arguments about complex computational systems are resolved empirically by BUILDING the proposed system and observing it behavior.
In simpler more precisely understood contexts one can create proofs about properties of specifically implementations w/o acutally implementing them, but instead by reasoning in a proof theoritic way about the implementation.

In complex contexts on can reason from past experience about related implementations to provide weaker evidence about specific implementations.

LEVEL 3b -- Historical experimental evidence from related problems as a proxy.

LEVEL 3c -- Proof theoretic evidence
prove theorems about implementation over all instances of some relevant domain of application.

##### LEVEL 4 EVIDENCE -- EMPIRICAL RESULTS FROM IMPLEMENTATION

LEVEL 4a -- Implementation level peicewise emprical evidence

build pieces and see that they perform their intended key roles as indicated by the relevent level 1 argument.

LEVEL 4b -- Implementation level holistic empirical evidence

build entire system and empirically verify its properties "in the small"  

LEVEL 4d -- Full "thin-slice" execution

Achieve Human level intelligence "from zero" within specific "representative" domains where the system was not "setup" for success

LEVEL 4e -- The whole enchalada

Develop Seed AI and drive it to human levels of performance over a typical human-breadth of abilities.


#### KINDS OF EVIDENCE AFFORDED BY THIS BOOK

Many others have provided rich level 1 arguments about the consequences of GAI.  Here we do not add further level 1 arguments, but the level 2 and level 3 arguemnts we do provide are generally consistent with the outcomes predicted by those arguments.  One can view each level as providing a more concrete explanation of the specific mechanisms that will cause the more general level's arguments to come true.

Specfically our arguments are consisten with Kirtzweil's, xxxx, and arguments.

* We provide a Level 2 evidence for an approach for a SeedAI
* The bulk of the book is devoted to a Level 3 evidence.
* We propose an agenda for acquiring level 4 evidence -- that is, building a SeedAI, and talk about the current state of the art


#### OUTLINE OF THE BOOK

	In the defining the threat section, we argue that if one believe each of these the three assertions above then logic dictates that one must also believe that AI represents a credible exestntial threat to humanity.  To NOT believe this conclusion we argue that one must disbelieve at least one of these three underlying tennants.  In this section, take each of these assertions in turn and arguing that it appears likely that each of them in fact are true -- thus the threat to humanity is very real.

	In the section 'time is short' we consider where we are today in computational terms for building a dominating seed AI, and what our expectation is of what it will take to power such a threat.

	In the section "we might be closer than we think" we consider evidence from the current performance of AI systems, current agendas within the AI and ML communities, plus what we know based on our only available example of a seed intelligence -- a human baby -- in order to assess how close we might be in building a seed AI.

	In this section we argue that today we are mostly not attempting to build a seed AI, and the AI that we are building is build upon assumptions that are inconsistent with a seed AI.  Thus the trajectory of our progress towards a seed AI to date is a poor measure of the distance we have remaining.  Indeed while most AI today is not framed as construction of a seed AI some parts of ML can be applied -- thus in requisite knowledge terms we are closing in on the knowledge needed to construct a dominating seed AI.

	In the section "agenda for action" we consider courses of action that humanity might take given the arguments made here.  Can we stop ourselves from following this path?  Can we control or affect the outcome if we do follow this path?  This section speculates about these questions.

#### outline of second part of book (needs integration)
second part of book -- towards construction.


Even though we don't collectively realize it.  It seems to me we may already have the broad outlines of a framework sufficient for constuction of a seed AI.  Hard reserach challenges remain -- and doublessly others challenges that are not aparent to us now given our current level of implementation, also remain, and remain un-articulated even within this framework that we are arguing in some ways in 'sufficient'.  Arguing the sense in which we already have a 'complete' framework for a seed AI is the slippriest argument made in this book.

Yet is it perhaps the most important job of the book.
Humanity is capable of strong sacrific and great action, but only in the fact of strong evidence.
(above was a separated section)



In the part of the book -- towards the construction of a seed AI, we consider the question of how close we are today to building a seed AI, and what is our rate of progress towards building it.  This section is inherently speculative -- in order to assess the distance remaining to building a seed AI, we must enumeate ALL the components required for building a seed AI, and all of the key properties the combination of these componenets must possess in order to construct a seed AI.  None of us know what those components are -- even as they are listed in this section.  Further one ca
nnot know if that list is complete nor what properties on the ensemble are required, until each of those compoenets are actually constructed, they are stitched together, and run on an architecture of sufficient power to allow them to produce sufficient progress to assess the intellectual boundaries of the emergent AI.

Ultimately it is liekly we will have to actauly construct and execute a seed AI, in order to know what it takes to construct and execute a seed AI.
Such proof by construction will liekly be the only test that proves we know how to build a seed AI.

The evidence offered here is obviously of much weaker form:
- we create a formal framework in which we can characterize existing machine learning and also our only example of a seed AI -- a human baby.
- we characterize systematic gaps in much of machine learning today as viewed in this larger context.
- we consider possible algorithms which one might create which address each of these viewed gaps.
  ....
- we enumerate known shorcomings in existing AI systems which must be addressed to by a fully functional seed AI and consider possible ways
  each might be addressed by existing technologies.

- we argue that at a course level we know more than we think we know about how intelligence works, and we can used this understanding to assess how far we are from building a seed AI.

- specfically we argue that we understand a sufficient set of human-like learning drives, and that we can assess our progress along a defined agenda for building a seed AI, by assessing our progress in implementing each of these HLLDs, as well as our progress in bootstrapping performance capabilities on one HLLD using results generated from other HLLDs.

- we argue that it is plausible that we need not exactly match or even understand exactly how each HLLD is implmented in the human form in order to assess the viability of specific machine surrogates for these HLLDs.  Instead it is sufficient for us to consider the kinds of knoweldge that humans can learn using combinations of the HLLDs and try to assess whether the sketches we propose for each HLLD taken in combination could also result in knowelege forms that afford the seed AI human like capacities in each case.

- By considering several of these stories about how specific form of some of the most complex forms of abilities learned by humans we try to gauge the level of completeness expressed by the framing of a seed AI.  if it had each of these HLLDs and they connect as we expect, does it seem it would generate the scope of knoweldge that humans can generate?

- Essentially this is a gut check, if this proposed agenda could be a complete listing of the stepping stones required for a seed AI.


The final section of this part of the book "the distance remaining" we squint our AI-eyes at each one of these sketeched capacities in turn, and provide some assessment of how much we understand today about acheiveing each.







##### Older texts

((Maybe talk about PART II of the book))
LEVEL 3 -- Sketch of an implementation
THE ALTERNATE PARADIGM
Alot of this books arguments hinge directly on their being a different paradigm for AI.  One that is similar enough to AI of today that we can have some gauge of our abilities in the other paradigm, yet different enough that outcomes between the two become unrelated.

So the persuasiveness of this book will come down to its persuasiveness in arging that these speicific paradigm changes do avoid the criticisms above, and that the proposed alternate is itself plasible -- this is the point of the second half of the book.


==========
 learned knowldge could result from machine instantiations of algorithms that phenotuypcailly match known HLLDs.
///
what we know today about how close we are to domination on the computational front, and how close we are to domination on the knowleldge required for a seed AI, and the computation required for domination.
///
So how close are we?  And if we were to follow an agenda for building a seed AI, what steps might we take?



The reaction of many of my AI contemporaries it to view the idea of a killer AI as a bit of futuristic fancy which might or might not be true, but is so far away, that we need not concern ourselves with it right now.  Indeed I have believed the pieces of this argument for over a decade, yet could not bring myself to really emotionally believe the implied conclusion.

To such researchers I ask them the following questions?
-- Do you disbelieve that a seed AI is possible and could be implemented?
-- Do you agree that if it is possible, do you agree its abilities will be propoortional to its speed as defined above?
-- Do you agree that processing power continues to grow exponentially and that it is possible that our most powerful computer networks approach human power?

If you answer yes to each of the above how can you not also conclude that this is indeed a credible threat, and that time is also of the essence?

## REFRAMING THE MACHINE LEARNING PROBLEM

### THREE KEY DISTINCTIONS -- between human and machine learning

**Open-Loop vs Closed-Loop ML** -- Today's Machine Learning is open-loop.  Humans configure the ML learning system, and it iteratively learns within some bounded universe.  Human learning by contrast is closed-loop in that during the course of learning, the configuration of the subsequent learning is modfied from the original.  This process can iterate with out bound yeilding very different and greatly expanded results.  Section XXXXX formalizes these notions, and Chapter YYYY provides framework.


**Discovery-based vs Emulation&Social based Learning** -- 


**Hand-Encoded vs. Experentially-Acquired Learning** -- 

Learning theory dictates that both human and machine learning is constrained in what can be learned.

Still Human learning is dramatically specializable we not only learn facts, but we learn new ways of learning.  The evidence of this difference can be seen in the transfer that humans exhibit, and the way that years long or lifetime long trajectories can be taken which incrementally update human learning in ways that allow a sufficiently trained human to show strong learning abilities in areas where other untrained humans simply cannot learn at all.

NOTE this is not simply a matter of not knowing certain definitions -- even if these are provided, and arbitarary time is allotted those humans simply cannot learn or perform.

It is a tautology, but the entire range of human learnable knowledge can be learned by human learning that itself has been specialized by a sequence of 

~~~~~
HUMAN ACCESSIBLE KNOWLEDGE -- Knowlege that can be acquired by humans by sequence of learning experiences, and we know what the sequence is...


#### Man vs Machine 
((badly written))
THREE STATEMENTS THE MOST AI RESEARCHERS WOULD AGREE WITH:
1. The AI systems developed today are opposite of the choices made by humans on each of these points.
2. It seems plausible to build AI systems which make the same choice poeple do on these three points -- but for 'environmental' reasons this would hard work to scale, and might make less immediate engineering impact.
3. If one is not attempting to do an activity A, but instead is focusing on activity B, then one cannot assess the doability of A, based on incidental progress achieve while persuing B.



##### Johnny's Algebra class example
- The reader may not immediately grasp the enormous difference between these types of learning.  
- todays human and machine learning both make a key mostly-unstated assumption.  but shockingly they are the opposite assumption.
- Can bring distinction into shocking relief by mapping the ML assumption back into the human domain for consideration
- imagine Johnny returning from class stating he's never going back 'cause the teacher cant even to the problems.  this would be normal -- though if true deplorable reason for leaving class.
- but imagine johnny return from class stating he's never going back because he does not need to go back.  the teacher can solve all of the math problems so there is no need for him to learn how to.

### TERMS USED IN THE REFRAMING OF ML
##### Knowledge as Ability or Articulation

To avoid getting hung up on semantic distnctions the don't aid the present discussion we refer to knowlege and abilities/capacities interchangably.  Asserting that an agent 'knows' something, is an assertion about that state of its mental processing.  This state can be indirectly assessed by the abilities and articulations demonstrated by the agent appropriate circumstances.

Certain knoweledge/capacities are more fact like, (e.g. being able to answer who is the president), while others are more performance like, (e.g. ability to hit a baseball)  But in both cases we only concern ourselves with knowledge/capacity categories that we know human acquire, and via the methods that have observed they have used to acquire them.  Essentially we seek a Seed AI that, when exposed to the same experiences, learn the same capacities.


##### Learning Proficiency 
Cannot measure the effectiveness of a human-like learning system in isolation.  Since proficiency is a measure of knowlege transfer one can only measure the proficiency of an ensemble system--measuring proficiency of the learner in isolation is meaningless.

proficiency is measured as a kind of ROC curve where the ensemble receives a 'effort' score for each abilitity that might be acquired.

##### Learning Ensemble -- learning context -- learning system
learning complex

Ensemble includes: learning agent, peer/teaching agents, the world, and the pedigogy applied.

##### Learning Profile
The learning profile for an ensemble is the mapping from possibly acquired knoweldge to the level of effort required by the ensemble for transferring that knoweldge using the best possible pedigogy.


##### Human Learnable Knowlege
The set of capacities transferrablle by human agents within the modern human societal context within some level-of-effort bound.

##### Human Level Learning Agent
((horribly written))
A learning agent that when embedded in a reasonably adapted ensemble has a learning profile as comparable to human-enembles as human ensembles are comparable to each other.

## THE SEED AI AGENDA 

Assessing feasiblity and building the first seed AI.


### LEVEL 1 ARGUMENTS


### THE LEVEL 2 ARGUMENT
Our level two argument proposes a specific approach for constructing a seed AI, and then attempts to assess the plauibility of this approach.


We begin this section with the central thesis of this book---the _loop-closing conjecture_.  There are caveats but this conjecture posits that closing the learning loop "in the right way" is sufficent for building a Seed AI.  Today we are too far away from implementing this for us to prove or disprove this conjecture in the confines of this work.  Still there is value in clarifying the the conjecture itself an assessing what we can of it today.

-- First, while we cannot prove or disprove the LCC, we can assess its plausibility---the plausibility that the proposed characteristics (presuming they could be implemented) would yield a Seed AI.

-- Second, we can assess how far current technology is from achieving each of these characteristics.

-- Third, to the degree that we assess the LCC as plausible, it provides a kind of timeline or countdown -- a rough measure of how far away we are from building a SeedAI is -- at least presuming the particular trajectory laid out here is a viable trajectory.


#### LCC - The Loop Closing Conjecture

THE LOOP CLOSING CONJECTURE
In its barest form, the Loop-Closing Conjecture posits that a Seed AI can be constructed by a specifically endowed closed-loop learner.

Specifically the LCC posits that these capacities are aparently sufficient for a Seed AI:

##### LCC - Plausibility Argument

Argument 

(1) HUMAN-COMPARABLE LEARNING -- 


##### LCC - Requirements for implementation sketch
======== LIST 2

* A HUMAN-COMARABLE SET OF LEARNING DRIVES
	* DISCOVERY DRIVES
	* MIMICRY DRIVE
	* SOCIAL DRIVES
* REPRESENTATIONAL SUFFICIENCY -- EXPRESSIVITY SUFFICIENCY
	* GENERATIVE -- SUB-SYMBOLIC -- NON-PARAMETRIC -- OPEN ENDED
	* TEMPORAL / RELATIONAL
	* LEARNING CONFIGURATION
* ENVIRONMENTAL SUFFICIENCY
	* PHYSICAL EMBODIMENT
	* SOCIAL EMBODIMENT -- PEERS & MENTORS
	* NURTURING -- INTENTIONS, PLANNING, CURRICULA
	* COMPUTATIONAL SUFFICIENCY
- SYNERGISTIC EMERGENT BEHAVIORS
	* AGGREGATIVE -- New knowledge (mostly) does not degrade performance.
	* SOURCE INDEPENDENCE -- 
	* OPPORTUNISTIC ADVANCEMENT -- 
	* PERCURSORLY COMPLETE
	* NON-DIMINISHING --

SEED CORE

* REDUCTIVE -- complex caps are built from simpler ones, w. small increments.  (all caps are contructable from reductionst caps, by trajectory of transforms each w. of bounded complexity)
* AGGREGATIVE -- Knowledge is cumulative, once learned it is not 'un-learned', and aggregates each time conditions for acquiring new knowlege is experienced.  We express this formally by saying a learner is aggragative, if a given sequence of experiential learning epoches E1, ... En are sufficient for acquiring some knowldge K,  then all non-distracting expansions of that experience E1,... Ei, X, Ei+1, ..., En also result in the same acquired knowledge K.
* UNIVERSAL -- if it can be thought it can be taught -- if it can be expressed in langauge, then it can be thought, if it can be thought it can be taught.  (expressible in symbol system w. computable operators?)
* FULL-CONFIGURATION-COVERAGE -- Any parameters/setup which must vary over the full range of capacities to be acquired must be itself acquriable based solely on a pedagogic experiential history.
* EMULATORY -- COPYIATATIVE -- MIMICK -- if cap/k is held by peers it will be acquired by self.  (learning happens as peers expose trajectories w. bounded complexity)
* NON-DIMUNATIONAL -- the bootstrapping does not "peter out" -- it is not tapping some latent resource that is being diminished in some way, making subsequent iterations less effective.


LEVEL 2 ARGUMENT -- the proto - architecture






###### Clipped text


====

LLC -- The Loop-Closing-Conjecture
 A transition to learning of the latter form affords many advantages to the learner.  By taking full advantage of the advantages and contexts afforded by this different learning context one is able to then transition to fully closed learning over a broad universe of performance capacities.

This closed learning in turn is the basic ability which drives a Seed AI

=====
Stating the LCC in its barest form: 
A shortest path to the construction of a Seed AI capable of dominating humanity is the full leveraging of advantages afforded by emulative learning in service of closed-loop learning.

THE LOOP CLOSING CONJECTURE  --- ((see notes in the atlas))

======
**Nothing New Here** -- Each of these ideas has been considered by the AI field.
**NOT NEW** -- Resist urge to frame learning paradigm here as 'new'.  No AI today embodies the full framework expressed here, and certainly the consquences of an implementation of this framework are far from understood, still we do not describe it as a new framework, since each of its parts have been well considered in isolation within many reserach agendas over the last 50 years.  in that sense it is not new.



**Structural Reasons Why Research Has Not Been Vigourously Persued** -- 



REWRITE -- what others say about this threat.

[[EXPAND --
First, as measured against the killer AI we agree todays ai is paltry, but this we argue in section XXXX that a seed AI won't be constructed as today AI, so its performance will not follow todays. indeed we argue that todays performance is expected to be a dramatic under estiamte of that other performanc

It is difficult to quantify capacities of humans and machines in a way that allows us to plot machine progress against its human target, but if we could make such a plot, there would be no disagreement that machine progress is slow, and quite far from human capacity.


]]

[[EXPAND --
It is also true that a great many things that people can do effortlessly are well beyond what we understand how to encode into machines today.  

Encoding even the simplest domains of human expertise in computable form, requires enormous effort.  Even encoding the starting points for Machine Learning to adaptively home in on human performance is quite costly and challenging for even the simplest task domains, and it is simply beyond current capactiy to  encode knowlege appropriately for more complex, more open ended task domains.

As XXXX at Google eloquently summarized what many feel this says about the state of AI today:  ``We trained YYYY computers for ZZZZZ years on the internet and all it learned was to recognized what a cat is.  that is where we are today.''

but this large gap in capabilties does not imply a commesurate gap in time before we have a dominating AI.

]]





Ancellary Points

Over the course of this book we make the case for a number of ancellary assertions which related to the core thesis of the book.  As an aid to the reader we outline each of these positions here without their accompanying justification.

TODAY'S AI IS OPEN LOOP, BUT WE CAN AND WILL BUILD CLOSED-LOOP AI

PAST PERFORMANCE LIKELY PROVIDES A DRAMATIC UNDERESTIMATE OF FUTURE PERFORMANCE


---- THE "NO NEED TO WORRY" FOLKS  and the  "IT WILL BE A LONG TIME" FOLKS ----

>>>>move and rewrite!

A CHALLENGE TO AI RESERACHERS ON RECORD SAYING "NO NEED TO WORRY"
Answer these three questions:
(1) Do they believe that today's AI is 'open-loop' AI, and that their assessement that we are safe from AI for a long time to come is based on our current progress in AI

(2) Do they believe that the performance of 'closed-loop' AI will be dramatically different from 'open-loop' AI. 

(3) Do they believe that 'closed-loop' AI is possible.



(1) Do they agree their statements are about



------ CLOSED-LOOP VS OPEN-LOOP AI

The broadest message of this book is that humanity must contruct the first seed-AI before a point on the Moore's performance curve where we immediately have little control over that seed.

Within the context of that message here we propose a specific agenda f


-------- THE ALTERNATE PARADIGM
 -- Alot of this books arguments hinge directly on their being a different paradigm for AI.  It similar enough to AI today that we can have some gauge of our abilities in the other paradigm, yet different enough that outcomes between the two become unrelated.

So the persuasiveness of this book will come down to its persuasiveness in arging that these speicific paradigm changes do avoid the criticisms above, and that the proposed alternate is itself plasible -- this is the point of the second half of the book.

## TOPICS
### ANSWERING THE SKEPTICS

There is nothing new here -- yet we don't have dominatig seed AIs.  why not?

Not succeeding at building a seed AI because we are not trying to build one

- Many of my collegues who are taking on one aspect or another of this alternative view of learing might loudly take issue with an assertion that we are not even trying do push this agenda.
- indeed section xxxxx we outline much of the progress there.
- Still there are several systematic structural reasons why the particular reserach agenda is dramatically under-explored, and  thus why progress to date is not a very good measure of what we could produce if we focused in the area.
	1. ITS CHEATING
	2. DATA IS NOT AVAILABLE
	3. ITS BAD ENGINEEERING -- the outputs are paltry relative to the inputs.

## LEVEL 3 EVIDENCE  ===== THE SEED AI AGENDA --  =====
AN AGENDA FOR HUMAN-SCOPED, CLOSED-LOOP, EMULATIVE LEARNING

### Formalizing a Least commitments model of the CLL conjecture
 sufficient for capturing HS-CL-EL

###### intro
- Formalize Least Commitment Model of HS, CL, E learning as roadmap for specific work to be done
- least commitment so it covers all approaches that fall within the broad umbrella of the CLL approach to building a seed AI
- intended to measure current state of AI against this specific agenda.

#### Formalize Socially Embodied Learning Agent
* Agent:  inputs, outputs, learning-configuration
* Universe: percepts, actions
* Society:
* Agent's intentionality: 
* Social learning -- sequence of interactions that ultimately results capacity acquisition

#### Formalized scope of a learning algorithm -- learning reach
* Performance task
* Learning system's scope -- set of tasks addressible by system given any intentionality, and given any initial leraning configuration

#### Formalize Open vs Closed-loop learning
* tasks reachable assuming multiple-configurations vs. those reachable given single common learner configuration.
* Scope of a closed-loop learner.


#### Formalize Emulative Learning

- In trying to formalize emulative learning we might start from existing machine learning, and describe emulative learning as traditional supervised induction of embodied performance capabilities in the context of other agents that indend to aid in the learning through their behavior.

- But formalizing this is a bit tricky.  at first blush it seems to admit all sorts of things the we would not want to call 'learning'
	- BRAIN COPYING EXAMPLE --> language of brain is not accessible -- no vulcan mind melds
	- IMPLICIT KNOWLEDGE EXAMPLE  --> cant learn what teacher does not know how to teach
	- TENSOR CALCULUS EXAMPLE   --> cant learn what others don't know.

Informally we can kind of view this as the 'rock climbing' model of learning.  According to this model learning is a sequence of moves where each learned capacity may depend upon prior learned capacities--and just as with rock climbing methphor the difficulty of a given route is roughly measured by the difficulty of its single most difficult move.

In both cases this assessment of complexity makes sense .... [[it comes down to difficulty of single step, too hard and the whole route becomes impossible]]

Also just as w. rock climbing the difficulty of achieving any given point is not fixed.  It all depends upon the specific route chosen.  they same target might be easy via one path, and quite challengine via another.  [[indeed climbing gyms typically layout 6 or 8 dramatically different levels of difficulty aiming to a single topping point.]]

LEARNABILITY IS FUNCTION OF ENSEMBLE NOT INDIVIDUAL
* Seems at odds with existing ML -- learnability is function of the learning alg.
* But it is just as it should be.  Learning calculus is difficult, but learning it in a society of agents that don't know calculus.... now that is **REALLY** difficult!


LEARNING IS NOT JUST FUNCTION OF ENSEMBLE, BUT ALSO OF INTENTONALITY OF AGENTS WITHIN ENSEMBLE
* learning only results if agenda collectively followed results in that learning.




LEARNING REACH IS NOT A FUNCTION OF THE LEARNER
- Implies the complexity of learning a given target is not at all fixed.  But upon deeper consideration 


## old txt to merge to seed AI AGENDA -- SUFFICIENT INGREDIENTS FOR A SEED AI
While there are many things about a super AI that we don't know, there are also many we can see from this early vantage.  There are probably many paths towards agents that could dominate present humanity.  Here we present one possible path for consideration.  This path is indicated in the sense that we are aggressively persuing many aspects of the path, and it seems to be a minimal path in the sense that not part of the path seems like it could be removed and have it still achieve dominance.

By laying out a sufficient set of components for constructing agents that dominate humanity, we don't mean to suggest that this is a solved problem -- that we already have all knowledge needed to acheive this fearsome end.  

But we do mean to lay out each of these pieces in a way that allows us to see that they connect end to end in a way that yields a seed AI.  We then consider what capacities a seed AI endowed with these facilities should have.

Some of the components that we present are ones that are fairly understood, employing them in the context of this seed AI would be a matter of engineering.  Egineeering of significant complexity to be sure, but engieering that many AI researchers would have consensus on its possibility and its outcome.

Other components are more speculative.  As an AI researcher, they are components that I see as plausible, and I have approaches I would take to address them.
Still these are speculative in the sense that AI researchers would not have a consensus about the outcome and about possible approaches.

For each of the components below we provide an assessment of the degree of speculation vs proof that exists for each.  Later in the proposed agenda section of this book we outline the kinds of experiments one could undertake to show in principle each of these more speculative portions are also a matter of engineering.


### LIST OF INGREDIENTS OF A DOMINATING AI

-- Intelligence copying machine
   -- Representational generativity
   -- Constrained K acquisition

-- Aggregative
   --- Non-diminishing bootstrapping
       ---- Referentially stabalizing -- traiangular refinement
-- diverse -- Multi-dimensional progress
   -- Physical Embodiment
   -- Social Embodiment
   -- Physical and social parity
-- Open-loop agenda setting  ?????
-- Sufficient computational power


-- embodied 
-- Intelligence Copier

Specifically no architecture has been explored where an embodied agent 
embodied, k-copier that leverages  Non-diminishing, rep-generative, multi-social drivers, 
embodied -- multi-drives -- 
abilty to encoded
>>>> nature of knoweldge acquisition -- bubbles under the wall paper


##### list of definitions
SUFFICIENT COMPUTATIONAL POWER --In order for the seed AI to have sufficient experience to build upto human level knowledge about the world and the agedas etc. of those in the world, it should have comparable experience to a human.  Because its knoweldge, like ours, is composed of knowledge and concepts derived from earlier experience, it is important that we have sufficient computational resources for our seed AI to have order of magnitude one a human lifetime's worth of experience.

REPRESENTATIONAL GENERATIVITY --
ability to generate novel representations.  
non-parametric learning


PHYSICAL EMBODIMENT


SOCIAL EMBODIMENT
### Sufficiency Argumennt 
An AI reseracher reading this list above might view it as a Program Manager's Christmas wish list.  
"Yes Santa, and I would also like representationally generative learning system, and a ..."

In some ways that is right.  Each one of the capabilities are things that we might build ambitious research agendas around, but here I argue that they are more that that.  They represent a SUFFICIENT SET -- a set of interlocking capabilities which if afforded to a seed AI would allow it to follow in our footsteps to achieve human levels of intelligence.

We cannot prove this here.  Such a proof will come in stages:
- first we will need to demonstrate that each capacity is even possible to achieve each individually.  It is possible that humans somehow achieve the same ultimate ends thru some other path way.
- second we will need to demonstrate that our implementation of each ability operates in a manner that supports the other required abilities as we are expecting
- third we will need to build it and test it.

In this book we take a "zeroth" step in this progression:  We show how each of these ambitious capacities connect to each other in a way
that plausibly builds upon each other.  We argue that these broadly defined chacteristics are in fact those that humans use
(in one embodiment or another) as stepping stones 

can connect these components logically to each other  components 


=====
ARGUMENT
   DOMINATION <-- COPY + POWER + OPEN-LOOP
   COPY <-- AGGREGATIVE BOOTSTRAPPING + GENERATIVE + DIVERSE 
   GENERATIVE <-- CONVERGENT STABALITY + STRONGLY GUIDED LEARNING
   Human learning is AGGREGATIVE BOOTSTRAPPING  ==  NON-DIMINISHING + LINEAR + COMPOSABLE
   NON-DIMINISHING <-- PATH-INDEPENDENCE 
   PATH INDEPENDENCE <-- CONVERGENT STABALITY

copying is key
- an intelligence copying machine exposed to humanity would copy its intelligence
- given that intelligence with sufficient computational power it would dominate.

opportunistic aggretation over multiple drives
- humans employ distinct drives to learn knowlege.
- certain knowlege in certain circumstanes is much easier to obtain via certain heuristics

human learning is aggregative -- non-diminishing bootstrapping

key to bootstrapping is the handoff of knowlege from one 
### Ingredient Details
#### Discover vs Copy
xxx
#### BOOT-STRAPPING FROM MULTIPLE HEURISTICS
xxx
### How are we missing the boat today?

>>> Discovery vs Copying

>>> Thin mono-typed feedback

>>> Non-embodied

>>> Non-social

>>> One-shot
### Progress Meter

Answering the question about how close we are to achieving human level intelligence in our AI systems has always been a challenging endevour.  Primarliy difficult because we have always tried to answer that question while being open to all possible paths on could take to achieve it.  This reduces us to graphicing exponential curves of performance etc. and arging that some how the details will work out to keep those trend lines intact.

Having a specfic agenda for how one might achieve HLAI puts us in a position to answer a much more specfic question:  What is our current progress against this specific agenda?  Of course it is always possible that a better agenda exists and thus measures of progress along this pathway are over estimates of our actual progress, but still having an over estimate is nontheless a valuable thing.

If one believes the agenda will succeed in its aim then it provides a very rough clock for at most how much time remains.


**Demonstrated Capacities**
**Physical Embodiment**
**Social Embodiment**


## ===== DEFINING THE THREAT =====
### A SEED AI THAT GROWS UP TO OWN US

### CONTROL -- Its all about control

ITS ALL ABOUT CONTROL -- In this section I argue that we are already aggressively building towards systems whose central aim in to exert control.  We don't have wave our hands and imagine future AIs designed in very different ways, for very different purposes, to see a threat to humanity.  Simply extending the agenda we are already persuing in nearly every arena of human competative endevour will result in systems that will achieve that agenda we already have for them -- control.

In the first part of this section we clarify what we mean by control, and 

All creatures -- even the most rudimentary -- are centrally occupied with the issue of control.  Consciously or unconsciously they seeking to manipulate and control their world towards specfic ends and away from others (e.g. survival, procreation, etc.)  Social creatures live in a world comprised of other creatures, so for them control of their world amounts to control of other creatures.  This sets up a natural competition, if two creatures aim for conflicting ends, then the one who is able to achieve thier aim does so at the expense of the other.  Generally by manipulating circumstance, and the other agent, in a way that acheives their end as the expense of the other.

This competition for control is universal for all social agents -- it spans from the most primative single cell organism to the most nuanced human endevors. it occurs in very conscious deliberate way in some contexts, and equally it occurse in unconscious 'pavlovian' ways in other contexts.

----
it is the central underlying activity of all social creatures and will be a central consideration for all AI systems designed to operate in any social context.
Thus we will argue that making an AI which is effective in nearly all areas of human endevor will involve making AIs which can understand and control 
other AIs as well as us.
We will 
Thus it will make no sense to 
/////

>>> EXAMPLES  single cells 'trick' signals.  


The ameboae responds to a phermone gradient and thus ...

the cat silently lies in wait from a vantage where it cannot be seen and from a wind direction where it cannot be smelled by the gazellel.  The cat is controlling the information available to the gazellel which in turn controls the behavior of the gazellel in a way that increasese the chances that the cat will achieve its aim of having a fresh meal, at the expense of the gazellel whose aim is to avoid being a fresh meal.

Soldier

The architect listens intently to their clients wishes for their new home, and 

#### Formalizing notions of control


BRAIN-RATIO METRIC --- human vs machine



ACHIEVEABLE AIMS -- A agent is said to have an achievable aim in a situation if there is a sequences of actions it can take to achieve its aim.  In the social context this includes taking actions which causes others to take actions which ultimately achieves ones aims.

SITUATIONAL MASTERY -- An agent is said to have agency dominance over another in some a situation, if both agents have achieveable but conflicting aims,  and yet the first is able to selection actions which cause it to achieve its aims at the expense of the second agent not achieving theirs.

AGENCY DOMANACE -- One agent is said to have AGENCY DOMINANCE over onother if there are a braod range of social situational contexts where the two agents have conflicing achievable aims, and where the dominant agent nearly always acheves situational mastery at the expense of the other.

SPECIES DOMINANCE -- Is simply an assertion that nearly any agent of one species will dominate conflicting social contexts containing
the dominated agents.


An agent, A1, is said to have agency dominance over another agent, A2, is a situation, S, if it is able to choose actions in a way that 

#### The exceedingly short distance between understanding and control.

#### Enromous energy devoted
 Enormous energy devoted to building engines of control

### THE LAST KEY
Last key "Moores Law"

### JUMPING BOX -- Box jumping is inevitable
fifty ways to mislead your maker.

## ===== Implementation Agenda =====

## Speculation / TOPICS
### Consciousness
#### Functional Awareness

- Functional Awareness
  Awareness is the mapping of an embodied knoweldge acquisition agent's model of its physical 
  and mental embodiment onto its direct sensory inputs from that embodiment.
#### ATTAINING CONSCIOUSNESS

Our argument that AI systems will grow to dominate humanity does not depend upon the notion that such systems would also grow to be conscious.  This prospect is more speculative, and the primary argument made by this book does not depend upon it.  Still it is relevant to the discussion, the consequences of a dominant AI that is conscious are different from those for an uncounsciouss one.  Further many of the capabilities required for aparent sufficiency are also required for cousciousness.

DOMINANT BUT UNCONSCIOUS
If the reader is disturbed by the notion of a dominant AI that is a self-aware consciouss AI, consider for a moment the consequences of an unconscious dominant AI.  This would be an AI that has modelled humans so well that it can effectively control them.  It has goals and subgoals to which it applies these abilities, but it -- itself is not conscious.  Perhaps it is not in a position to reflect on its own programming and to evaluate the ultimate ends to which is goals are driving things.

This also seems quite terror inducing -- in many more terrible than a conscious AI, one that could at least possibly see a parallel between us and itself, an AI that could possibly be able to imagine that it was the one being controlled, and have some possible attenuation of its most extreme actions.

Of all the terrors imagined in this book, it seems the notion of an unaware but still dominant AI, if that were possible, could be the most terrifying concept of all
.  Fortunately on this score, this possibility seems less likely.  At least according to the model of consciousness we advance here, it seems the capabilities 
needed to dominate -- to understand and control others, are quite overlapping with the abilities to understand oneself in a way the yields awareness.



DEFINITION OF CONSCIOUSNESS

But in all of this, we are getting ahead of ourselves, before we can argue that a dominating AI would likely also be conscious, we must first define what we mean by consciousness.  We must then go on to convince ourselves that this working definition has some meaningful connection with what is generally meant by consciousness--in order for arguments about it to have any relevance for us.

---DEF---
The mapping that an embodied modelling system has from its model of itself onto direct perceptions from itself.





UNPACKING THIS DEFINITION
### Preable

A limitation of this book is that we are focused on one general trajectory towards a dominating AI.  
This has the disadvantage that perhaps there are other faster paths towards a dominating AI that are not considered here, and thus anything we say on the matter is really just an upper bound of the complexity of that quicker path.  Still this approach also has a great advantage as well.  Since we are proposing a specfic path, we can provide milestones as a kind of measure of humanities progress towards these advanced AI systems.

Here we make a very crude attempt at a count down timer


==========

Acquisition-ratio equals fraction of college student acquisition of given material.

Categories of capacities.

  -- Nouns
  -- Nouns + Properties


building blocks & scaling components



_______
The model of an embodied bootstrapping intelligence in this book is argued to be aparently sufficient, we do not expect each of the pieces (for example, each of the many learning drives) to all be necessary.  Indeed one of the resilliant aspects of human intelligence that we aim to replicate is its abilty to recover from many specfic gaps in performance.  

LAUNCH BEFORE ZERO
Thue while we express this as a countdown to zero, we really expect that 'launch' will occur as some unknowable value greater than zero.
Still there are certain aspects of the design that we expect to be necessary (at least for this particular path toward a dominant AI).  
Those we express with an astrisk, and explain why they seem necessary as well as sufficient.

WE DONT KNOW THE ORDERING FOR ALL
In some causes 





ROUGH DRAFT
We wanted to provide some sort of explict measure of progress thus this timeline was born.  Still we expect discussion among researchers will afford a refined view of the components of this timeline.  Thus the reader should threat this as a tentative first stab which can productively refined from collective thinking into a more accurate measure of our progress and remaining gap.


# >>>DELETES<<<
### non-continuous improvements
Many discussions of the trajectory AI will follow (both optomistic and skeptical) tend to treat system capability as a numeric quantity which is monontically increasing in some approximately continuously fashion.  While we understand the reason behind this simplification we believe it hides......
### From the intro -- not to be re-added

In writing this book I am filled with a form of dread -- honestly not the kind of dread that I should feel in thinking through the contents of the book.  Instead it is the dread of imaging fellow researchers ridiculing the book as a heap of unsupported fancy, rather than anything approaching science.  And my fear is justified -- for I know I cannot support the claims of this book at the level that one demands of academic work.

Still I am compelled to express the argument here in its very imperfect form, because I believe that its broad outlines are correct, and if the broad outlines are correct then it indicates a collosal barely imaginable threat.  Further it also seems that how this threat will manifest will depend centrally on our relative progress on two complementary technology fronts.  If this is true, then it is important for humanity to have as clear a picture of the threat as possible, as soon as possible, in order to have its greatest chance to shape ultimate outcomes in some more acceptable way.

**or just drop this?**
The claims of this book read much more more like science fiction, than they do science fact.  I have half-believed these conclusions for more than a decade before deciding to write this book, not because I understood the basic argument that much better after a decade.  Instead it is the time it took staring at outlandish conclusions looking for the flaw in the reasoning before emotionally coming to accept they really might be correct -- outlandish as they are
# >>>EXTRAS<<<
## ===PARTS===

#### Quote

   ``As the water crest the top of the hill the path it will take next is unknowable.
     Each stone, root, or divot will compete to set its path in a hopelessly complex interplay.

     Surely still if your house is sitting at hills bottom, you would be wise to prepare for 
     that waters arrival, even as you admit you really have know way to know that path it will take.''


   In the same way, humanity needs to prepare for an impending loss of control.


#### The Three Sentence Summary

This site aims to be a warning to humanity -- and a call to action, even as both action and outcomes are still murky.

We argue that 
  --  a probable future is one where humanity looses control of itself and of the resources of the earth.
  --  to a first order of approximation our position on the Moore's law of computational progress will
      determine our ability to affect outcomes -- thus humanity needs act, while it still can.
  --  the change will be swift: at any fixed scale exponential curves tend to look flat then vertical.


##### more text

 the available computing resources available to a human mind relative to 
      the computing resources availble to an AI will determine their relative strenght

  --  the primary method for blocking or staving off this eventuality, is the progression block moore's law.

  --  yes stopping moore's law is nearly as unthinkable as stopping water's flow down hill, still if 
      humanity knew for a certainty, that this was its **ONLY** defense against a CERTAIN destruction
      it seems at least plausible that it might with colossal effort succeed -- at least temporarily 
      in doing this.

  --  The point of this site is to give humanity as much certainty as possible as early as possible,
      since its ability to limit itself away from some boundary becomes exponentially harder the
      closer humanity has approach that boundary, before putting the breaks on.


#### Predicting the future is impossible right

Predicting the future of a complex self interacting system is impossilble.   Yes and No.

- Certain aspects of about how complex systems will unfold are difficult / impossible to predict, 
  while others can be predicted with a fair certainty.

As an example consider predictions about the future value of the S&P 500 stock index.
Because of its value at any moment is a function of the buying and selling actions of 
tens of thousands of individuals each following unique signals with unique agendas
predicting its immediate direction as up or down for any given second on any given day
is very nearly impossible in many contexts.

Still I would be willing to bet that in exactly 20 years from today's date it will be
at a level higher than it has ever been in the entire history of the index.

Viewed according to certain faulty logic, this prediction should be even less certain than
a more immediate outcome, since the course it will take will be affected by more things.
Further this is a prediction that somehting will happen, which has never every happened
in all of history.  Faulty logic would conclude that we have little basis to make such
predictions, and further that the fact that it has never occured before means that we should
be inclind to think it wont happen then.

what is wrong with this logic?


Well the first prediction is about the outcome between competing forces -- ones that pull the market 
up and push it down.  The second is a prediction about a trend.

- Outcomes that depend on the RELATIVE strenght of competing factors are difficult to predict, since
  it is not enough to be able to predict the continuation of each factor -- rather one must assess 
  the progression of each factor relative to the progression of the other.

- By contract predictions the depend simply on the contiunation of some factor are much easier to make
  they only depend on the continuation of the conditions that enable the factor.
  
  Of course 



- Competing factors are more difficult to 




#### There are so many things to worry about, why is this one so important?

Few other scenerios are such that the most probable path forward is one where humanity looses control.






#### The witch's brew

-



#### The Bomb Analogy

Humanity does have experience in trying to limit the threat of damaging technology.
      Nuclear Non-proliferation

After world war II we correctly saw the dangers of nuclear weapons and sought to limit risks associated.
Non-proliferation came down to control of two things:
  - limiting the knoweldge required to build a bomb
  - limiting the materials needed to build a bomb

After a handful of decades this deterrent was boiled down to a focus on exactly one piece of this complex
puzzle -- limiting access to fissile material.

Initailly we tried to limit the spread of knowledge required to build a bomb, but limiting knoweldge is mostly futile
once it is know that something in principle is possible, and broadly how it was achieve in the past.  Replicating
that knowledge is many times easier than it was initially.  Further, progress of humanity on many other fronts
also means that the replication becomes easier over time simply because the building blocks are more potent 
in each subsequent year.

Also the physical building blocks for such a weapon also become more available.  Over time ever more uses for 
each ingredient will be found.  Even esoteric materials and devices find increasing application the longer 
humanity knows about them and their properties.  Thus many of the parts (electronics, etc.) needed to build
a bomb are now commonplace.

In the case of nuclear weapons, fortunately their is one ingredient -- fissile material -- that is difficult to produce, and is 
valuable only in a constrained set of applications.  

This has made it possible -- though difficult slow access 










  



#### Surpassing Humans

- The main point here is that as some competing technology increases it will spend much time 
  well below human ability, then rapidly it will cross over to well stronger than a person.

MAXIMAL FORCE

MAXIMAL SPEED
## ===TO SORT===
#### Consciousness -- self determination

EFFECTIVE AWARENESS -- 

  An embodied agent's mapping from its model of its embodiment onto its direct singals from from that embodiment.

-- Enough for it to have the basis for operating beyond its innate drives
-- Enough for it to wrongly conclude that it could not be functionally determined.



### MOTIVATIONS -- Why this site

I think we know a great deal about a specfic shape that this threat might take on, and haw it might come together.
Further, I believe we may be rapidly loosing the only longer term break that I can see we might apply if we chose to control this technology.

At heart I am an optomist about the human ability come together to meet most any challenge before us.
Once it is clear to all that the threat is real and it is pressing we will act, and we will act decisively.
But a threat, no matter how extreme in its consequence -- if garner little decisive action until at least some of those consequences are known with certainty.

That is the purpose of this site.  To organize an agenda for uncovering the true nature of general AI as fast as possible in order to provide humanity 
with its greatest chance of securing an accepatble outcome.

-----

The point of this site is to express a specfic possible threat to humanity is the most concrete terms possible, both as a means to further our
understanding of the threat, and 

The ideas rolling around for more than a decade
have mostly been embarrassed to talk about it
## useful snipits


###### text -- crying wolf
THE ARGUMENT
Claims that "the end is near" have been regularly made thru humankind's history.
"Wolf" has been cried so many times that humanity rightly demands incredibly strong evidence 
in order to decisively act upon the next claimed threat.

The threat outlined in this book is so fantastical according to modern sensibilities, and
it is so far from the embarrassingly paltry performance of today's AI systems

 and experience
that in one step we will not achieve this level of evidence -- we will have two build an example
of this threat, to touch it and feel it before we really belive it.  Even for myself who has considered
the parts of the argument shown here for more than 

###### text -- nothing magic here

We dont mean to propose that this architecture is somehow 'magic' in that it is organzied in a fashion that is dramatically better or different
from other ML architectures.  There are no details in this architecture that make it able to achieve dominance when other ML
architectures could not be extended to also acheive it too -- doubtless even those that more effectively acheive it.  

To argue otherwise would be like arguing that one CPU design can be used to execute compiled "C" programs where as other CPUs
would be unable to be used to executed compiled C.  This should strike the reader as improbable -- one architecture might be
more tuned for executing C programs while anohter might not.  Still within some factor of performance different generally different architectures
both will be able to execute "the same" C programs, and fail on the same other C programs.

In an analous way, this architecture is simply one possible realization, and likely not the most auspicious one.

Stll this architecture has been designed to be extended in the critical ways listed in the "sufficient set" chapter.
Other architectures have been implemented which exhibit most of the sufficiency properties taken individually.
I don't know of an architecture sketch which attempts to stitch all of the sufficiency properties into a single architecture
(mostly because we don't yet have firm mastery of each constituent thus leaping towards an integrated architecture is
 premature from an academic maturity perspective.  it is flying by the seat of ones pants in a way that will be hard 
 to make progress since it will be hard to
## eh, maybe


####### sufficient system
A sufficient system.  

  -- a human-life's computation
  -- bootstrapping
  -- generativity
  -- social context
     -- embodiment



###### text -overview parts

Following the agenda from section XXXX, we need one or more learning substrates to encode
our seed AI's human-like learning drives.  This 


>>> Human-like Learning Drives
>>> Physical embodiment sufficient for supporting for HLI
>>> Social embodiement sufficient for supporting for HLI
>>> Non-parametric learning system that can be programmed with human aparent drives


