LOG


2021-01-23 - Al Intro Email


Al,


It is great to electronically meet another friend of Yashin!  It sounds like we may share a common interest regarding disinformation and hyper partisanship.  I am a computer science researcher and an entrepreneur…  How to electronically take on this issue has been swirling in my mind for well more than a decade.  I have never really done anything with it, since I was never clear if I could turn it into some kind of sustaining business  (I am still not clear about that).  Still, perhaps I have made some progress thinking about a novel approach to pulling our nation together.  Below I have framed goals of the effort just to give you some clue what I have been thinking about.


I would love to get some feedback on these ideas… they are still very much a work in progress, but I am long overdue for just getting a reality check in on how others see the value of such a system, and what edits might be made in order for it to be workable.  If you have time and interest, I would love to chat sometime!




Cheers,
Dan








Below are the goals for an online discussion forum that connects folks with disparate views to hash out which things are agreed and supported, and which things are areas of disagreement.  It is a cross between wikipedia and a chat forum, but it tries to boil complex issues down to single sentence sound bites that capture the essence of each group’s thinking.  Here are its goals:










(1) SYNTHESIZE SUCCINCT SUMMARIES


Discussion forums today allow passionate folks to discuss ideas, but unless you have the time to read the volumes they have written, it is difficult for others to gain insight from all of that effort… it is kind of wasted.  I dream of a discussion forum that also synthesizes extremely pithy “rollup phrases” like “climate change is overhyped” or “climate change is at a catastrophic tipping point” where a reader can then drill in and see the most pithy rollups of evidence and argumentation for each.  So the participants discuss topics just like today’s chat forums, but the output of this forum is very very different from today’s discussion forums.  It’s more like a deeply-linked wikipedia but one that contains contradictory summaries of the same topic.




(2) DRIVE CONSENSUS


But it is not enough to just list different points of view.  The second aim is to judge the quality of the evidence and argumentation behind each synthesis.  The aim is generally not to declare one view the “winner,”  but rather to give the reader a quick (color coded?) way to understand which synthesis claims are “generally accepted as having strong evidence” versus those that are “unsupported or are not logically coherent”.  Just as a way to imagine what that would look like, imagine a list of 20 climate-change claims ordered from the most ardent claims of imminent catastrophe down to the most strident claims of that it is all a hoax.  Probably on both ends there will be claims that neutral judges would agree are not well supported, while in the middle would be claims like “CO2, a greenhouse gas, is now present at levels greater than in many centuries.” Some of these middle claims might receive broad agreement from all sides.  Having things annotated in this way would allow a reader to quickly get a sense of which claims are generally accepted and where the pivot points are for the hotly debated parts, as well as the best rollups for evidence for and against each.  Each reader would be able to quickly drill into arguments and places that make sense to them in order to arrive at their own conclusion -- but a conclusion based on many pieces of consensus evidence as well and best rollup points made from all sides.




(3) ALGORITHMICALLY SELECT ACCURATE AND HONEST JUDGES


The problem with rendering judgements regarding evidence and logical coherence is that those judgements will be no better than the judges making them.  But who is judging the judges?  I know of some kinda freaky ways to build algorithms that use judges’ judgements and how they relate to other judges’ judgements in order to assess the judges themselves.  (Say THAT three times fast!).  It is very tricky to build a system like this that is not gameable.  The idea is to piggyback on the back and forth discussions each person is having as they are debating and trying to improve the rollup synthesis arguments that others are creating.  In these discussions they are explicitly “clapping” certain parts of others’ texts, and giving labelled feedback like a “claim needs evidence” mark on other parts.  These interactions form a huge continuous stream of feedback signals that are a kind of judgement.  We capture this stream and perform inter-participant agreement scoring, participant bias scoring, and many other tricks to assess the judgement of the judges.  By doing particular kinds of graph analysis on how these feedbacks relate to each other and to the biases that each person has, one can compute how accurate and honest of a judge you are.  (lots and lots to say about how to do that.)


The result is that we can trust the consensus syntheses and judgements generated by the community, since we have evaluations of each participant-judge, and we can trust those evaluations since they are backed by a transparent 100%-mechanical algorithm which itself has no bias.


Indeed this “algorithmically-driven judgement of the judges” would be an extremely powerful idea if it can be made to work.  A primary criticism of fact-checking-websites like Snopes and media-bias-measuring organizations like Al Fonte or AllSides is that no one can know what biases those orgs themselves have, so how can one trust anything they say.  Imagine if you could algorithmically look at how judgments relate to each other in ways to test bias, accuracy etc.  Then you COULD trust them, or at least you could know what biases they bring to the table.
















________________


Yashin asked me for a concrete example of how this synthesis might work.  This is how the tree might look after much debate had taken place:
You can look below to see a few nodes in the tree just to get the idea.  Here are some point to keep in mind:
* Each note has a hook line that has been iteratively edited to try to most succinctly capture the key idea of the whole note.
* In the level above a note one will only see the hook line so that one line is a compact summary of all that is critical.
* In order to gain the most consensus points a hook line should contain the key idea, but then also contain a most important qualifier
        (e.g. for the USB hack claim, the greatest consensus was achieved by adding  “no evidence found, but it is plausible they were hacked”)
* Each node in the tree is essentially a discussion thread between interested parties.  The system keeps track of most “clapped”, least biased, most accurate, most supported hooklines and body texts.
* Participants can propose edits to the hook lines or body text and others can clap.  If a variant gets many claps it will overtake the original hook line and replace it as the default seen first.
* In the end you might end up with a simple consensus, or you might end up with several incompatible positions that each have significant but biased support.
* Either way results are shown as one or a few hooklines with their supporting body text.
* Notice the ‘...’ in each section, if you really care about a section you can dig into lower scoring variations.  Nothing is ever lost, but if it is very biased, low accuracy, or low support it will get pushed down the list.






TOPICS:


________________________
TOPIC:  Politics > USA > 2020-election > 2020-election-fraud
HOOKLINE:  Was there large voter fraud in the US 2020 Presidential election?


SUMMARY
Forum is split 55/45 with a large minority seeing massive voter fraud.  Strongest arguments for voter fraud do not have high accuracy scores, there are high scores on accuracy on some claims of fraud and possible fraud but not enough evidence to flip the outcome.  Highest accuracy claims against fraud focus on rulings of judges and what the biases of those judges might be.


TOP POSITIONS
-- Conclusive evidence of massive fraud.  Trump won!        [ MAGA; New-Right; Anti-Media ]        Consensus 15%, Accuracy 20%
-- Terribly corrupt election. No way to know the result.        [ 
-- Clear evidence of fraud, but not enough evidence to know conclusively flip a state’s result
-- No evidence of increased fraud, no reason to doubt election
-- Biden won.  All election fraud claims are bogus.
...
TOP CLAIMS
-- Four states actually won by Trump:  Arizona, Pennsylvania, …
-- No evidence found, but it is plausible that hackers could have significantly changed vote counts in three states.        Consensus 70% Acurcy 90%
-- Even Trump appointees dismissed Trump’s claims as not having sufficient evidence                Consensus 60%, Accuracy 90%
-- 40% of the judges that threw out Trump’s claims of election fraud were republican nominated judges
...




________________


____________
CLAIM: Politics > USA > 2020-election > Electronic-voting-machines > Dominion machines could have been hacked
HOOKLINE:  No evidence found, but it is plausible that hackers could have significantly changed vote counts in three states.        
STATS:   Consensus 70%  Accuracy 90%   Language neutrality 95%  Logical coherence: very high  Support: very high
SUMMARY:
The design of the dominion voting machines with exposed usb port would enable hackers that gained momentary physical access to the machines to “hack them”.  In eight states those machines were directly attached to the catch bin for the ballots.  In these cases if they were set to “auto accept mode” then hackers could edit both the vote counts AND the printed ballot to flip certain votes if the voter selected “accept without viewing” 


We don’t know how many districts had the machines set to this mode, and we have no specific evidence that they were hacked.  Still if they were the number of votes affected could easily flip the election in at least three states.  Pennsylvania, Michigan and Arazona. 


TOP COUNTER:
This is a hypothetical without any evidence supporting it.  We don’t even have evidence that any machines were to set to allow accept w/o viewing.  All states except Michigan expressly forbid setting the machines into this mode according to the election commission rules for the state.
...
TOP CLAIMS:
-- An person given the right USB stick & phillips screw-driver and 4 minutes with a voting machine can hack it.   Accuracy 95%
-- Given election rules almost no states were using the “accept without viewing” option.  Accuracy 70%
...


___________________
CLAIM: Politics > USA > 2020-election > Electronic-voting-machines > the-4-min-dominion-hack
HOOKLINE:  A person given the right USB stick & phillips screw-driver and 4 minutes with a voting machine can hack it. Acurcy 95%
STATS:   Consensus 85%  Accuracy 95%   Language neutrality 100%  Logical coherence: very high  Support: very high
SUMMARY:
In the attached video two grad students (with contact info here) from the University of Minnesota’s computer science department demonstrated the hack using a late model dominion machine they purchased off of ebay.  The second attached video is Professor McClusky at U Michigan arguing in 2017 that these machines should not be certified in their state because they can be hacked.  He explains how starting at 18:25 on the tape.


TOP COUNTER:
They bought it from ebay… we don’t even know if this is the model that was used in the 2020 election.
































































Older text


My aim is a discussion forum that synthesizes succinct (single phrase) summaries of what different communities think about important issues.  e.g. is there significant evidence of climate change?  is there significant evidence of 2020 election fraud?  The first aim would not be to arrive at a single “correct” answer, but rather succinct summaries of different schools of thought.


The second analysis , however, would be to try to push as much consensus as possible around these issues. e.g.  conservatives agree giving global consensus that certain minimal statements about climate change are empirically supported, while liberals agree giving global consensus that other stronger statements are specifically not supported.


The resulting synthesis could be looked as a spectrum of statements  (which could be succinctly shown on a single page! ). At the ends of the list would be statements broadly agreed, with hotly contested statements in the middle.


Such a summary could really advance the societal discussion, since it could show everyone which statements are not really even supported by their own clan when their members look deeply at the topic.


~-~~


But this only works if the system can mechanically identify within each school of thought who are good judges of scientific questions, who are good and honest judges of logical coherence, etc.  (otherwise you never gain consensus on anything).


But that output of such a mechanical system only has value for you as a reader if you trust the mechanism. And so that is what I have done a bunch of thinking about.