  [TIER Z](TIER Z/TIER Z.md)  [TIER 1](TIER 1/TIER 1.md)  [TIER 4](TIER 4/TIER 4.md)  [TIER 3](TIER 3/TIER 3.md)  [TIER 2](TIER 2/TIER 2.md)  [stindex](stindex.md)
  [GHOST-Seed](GHOST-Seed.md)
  [TIER Z](TIER Z/__TIER Z__.md)  [TIER 1](TIER 1/__TIER 1__.md)  [TIER 4](TIER 4/__TIER 4__.md)  [TIER 3](TIER 3/__TIER 3__.md)  [TIER 2](TIER 2/__TIER 2__.md)
(See [startup/index](__stindex__.md) for list)

# ### QUICK THOUGHTS ###
### --- AREAS ---
- ENERGY -- Building something that 
### Getting to another star

Terry... I think it is just engineering....
The human ribosome is a biological example of self-replicating nano-technology... so such is not science fiction.
We can use a laser the size of a solar system to columnate a beam of energy to power a space ship less that a gram in mass...  there is a seperate trick for slowing down on other side.
Micro-meteors in intersteller vaccum are exceedingly rare, still they exist.  And each one will completely destroy one of our micro machines... so they are spread out within the laser beam that powers them.  They exist as duplicated parts of a complex machine that keep rebuilding itself from feedstock atoms that we are shooting at them along with the energy we send.
Thus our "copier" spacecraft is many microscopic components feeding off our umbilical cord ... and they replicate the destroyed parts over and over until it gets to its target.  (whole mechanical organism keeps itself separated by spinning, and moves its own parts around internally by sequential electrostatic pushing and pulling)
with a replicator planted in a remote system, we simply just grow an energy collector at the remote star, then an environment that we can download into (maybe we only construct the single cell needed to kick off our species, or who knows what we create there).   Yes it takes a hundred or so mellinia to inhabit the millions or billions of systems near us, but hey that is an eye-blink for the galaxy.
Yes this is colossal engineering by today's standards I agree, but there is no science fiction here, just colassal engineering.  (just as the 100 story building or a fighter jet is colassal engineering by ancient standards.)
so what do you think?  did I break some laws of physics here?

_
### Pay scheme for email spam

- CHIT -- A quantum of crypto money
- STAKE -- A new email address must stake and maintain 1,000 CHITs in escrow

_
### Robo body lift
### DOCUMENT TRACKING APP
- Android app
- upload file, enter data, capture photo 
  -- recorded into document stream for this account (which can be routed to one of n aggregation streams)

#### AUTHORITY
- Any person can create an account.
- App positively validates physical connection between two devices connected to two accounts
- any account w. authority can attest to properties of other accounts
  (e.g. owned by a person with this image, ssn, address, fingerprint, with this amount of money...)
- any account with ahtority can grant authority to other accounts

ACCESS
- ability to serach in streams (by manifest propoerties, not contents)
  - a few standard index types exist and can be enabled
- ability to decode document
### ZOOM - telepresence rules
-- any action any person can take should also be doable by all
   (but can also be restricted away)

-- e.g. toggle someone's mute.  
   pin something on another persons screen.
   begin sharing

-- Begin meeting w/o leader

-- Key actions at all times:
   Mute/unmute self.  See all participants.  mute others.
# ### IDEAS BY TOPIC AREA ###
### BOOK - Organizing Your Life

IDEAS
	- THE UNSCHEDULE

	- LISTS -- Create lists as a way to organize.

	=== SPECIFIC LISTS 

	TODO -- my main quick actions list

	WEEK --

	REPEAT -- Lists of actions that are a template for repeated work.  The backbone section of my repeat list is WEEK REPEAT, but I also have smaller ones for MONTH and QUARTER.  DAILY REPEAT is also an important list, but I dont look at it, I just remember it.
			- If you don't get done with stuff within a week, then consider moving it to month repeat or quarter repeat.

#### --- THE UNSCHEDULE ---
#### --- ALREADY DONE ---

	``It will all be great, you'll see.''

	But it wont.  Life will keep happening, motivations and focus will wane.  All plans fade.

	Key is to build upon habits that don't require upfront organization, ones that whose structure and performance improves with repeated usage.

## === PRACTICAL FIRST BASE IDEAS ===

### TruValue for Services

CORE VALUE PROPOSITION -- Provide objective, actionable data that allows a services buyer make an informed buying decision.

CORE DATA PROVIDED
- Calculators
- Vendor table: 
  - Basics:       Name, num employees, annual revenue range
  - Customers:    List of customers
  - Contracts:    List major

- Customer table:
  - Basics:  Name, Industry

- Contracts table

### Secret sauce
- Philippino workflow to scrape/collect data name/rank/serial number data



- Create a non-profit to collect the data and present part of the data.
   - Service sells 


### Hypotheses / Questions
-- Will buyers care about our data?    (if we are a non-profit, does that help?)
-- Can we get them to buy thru us?


-- how do we find who has worked for whom.

### How about Now?
  - A better mechanism for opportunistic communication.
 
### Gaurav -- HOME -- Vacation Rental Automation
### Services

EMAIL/PHONE
- 100% of interactions:  Inquiries, Q/A, Problem Solving, Heartbeat
- CONCERGE:  Ideas for area


MANAGEMENT
- Coordination of Stay:  Cleaners, Thermostat


SVG -- MANAGE CLEANING/REPAIR SERVICES

CAL -- CALENDAR COORDINATION

IOT -- LOCK CONTROL


CLEANING SERVICES

NEST -- TEMP CONTROL

BILLING

### Logical Timeline

=========
TALKING PHASE
- GATE: Get 50/100 commits for specific product w. price point.


===============
SOLVING PRODUCT  --  Iterate product features, and implementation  (~100 properties)
-  GATE:  >$20? >$50/mo/rental
-  GATE:  <10%/mo attrition
-  GATE:  >80% would recommend friends to use this service?
-  GATE:  Min "issue time" per customer /mo


==============
SOLVING GROWTH  --  Iterate customer acquisition strategy  (100-1000 properties)
-  GATE:  >10%  conversion rate within 100K population
-  GATE:  <$100 cost of customer acquisition

-  Spending all $5-50K/mo on growth experimentation
-  maybe small money during this time, but mostly is a distractor
-  maybe small automation hacks if needed, but also a distractor


===============
EXECUTE SCALING  --  Execute growth strategy at max velocity  (1000- properties)
-  RAISE FUNDS   Perhaps A-round
-  AUTOMATE      Automate execution processes  

-  Scale relationships nationwide
-  Scale services offered to full complement

-  Iterate: Marketing, Messaging and Features


### Money

  $10M cap. --> $500M exit --> $50M/yr -->  $5M/mo -->   100K properties  --> 5% pentration (us only)
  
  7.2VacHomes (3.8Rented  57%owner(2.16M/43%prop)  ~ 10 Mil US & EU
## === NDL RELATED ===

### --- NDL disruptive ideas

Nick's Examples of Marqueee problmes

-- predict re-estate marketing trends
-- soloar power micro-climate
-- Deep compression of semantically rich data

NICHER AI
-- battle scape  
-- predicting Trading cascades

### NDL -- Nick and Dan Labs -- How we manage IP

  Contributions to Nick and Dan Labs  (NDL)
  - GOAL is to encourage Nick and Dan sharing w/o worry of loss of control.
    GOAL is to be light weight and allow sharing even before deciding intentions or direction.
    APPROACH:
  - When one of us brings an idea to the lab (in the form of a clearly defined and labelled presentation), they "control" that idea.
    e.g. both founder can 'think' about it, but the bringer 'owns' it until we mutually determined otherwise.
    and it is automatically treated as NDL confidential.
  - It is 'uncool' to bring an idea that has already been discussed, or is 'obvious'.  Further any connections to prior ideas should be noted so 
    no stress is generated by the bringing of an idea.  That way the bringer is only asserting 'control' over the thread
    derived from the new idea--not any ideas already known.  (mostly we try not to worry too carefully about this.)
  - In the end the person bring the idea, is allowed to "walk off" with the idea, as well as all
    subsequent ideas had together at NDL on the same subject 
    -- e.g. both of us are willing to freely 'give' our advice on other's idea free of 'charge'.  
    (we just want to be clear when we are talking about an idea controlled by one or the other.)
  - Still if an idea is brought to NDL there should be the expectation that a 
    substantial split is expected or at least very possible. 
    (or if not, then this exception should be made clear from the get-go.)
  - Early on if significant hours are being put into WORKING on an idea,
    then the controlling memeber should express some intentions about possible split ranges.
    Further, before too much work is executed, ownership should be cemented in some LLC ownership,
    or at least in a Nick+Dan+Lawyer statement of intent.
  - If an idea is so 'obvious' the other one was going think it anyway, well it should not be controlled.
  - If one of us wants to bring a controlled idea forward, they should write a brief header
    stating their scope and intent.  


    Some possible the top of a slide intent headers might say:
    NDL Confidential -- Nick Controlled -- Signifcant split not known.
    NDL Confidential -- Dan Controlled -- Significant split possilble.
    NDL Confidential -- Jointly Controlled -- Even split agreed.
    NDL Confidential -- Nick Controlled -- (will figure out the rest if we care to.)
    NDL Confidential -- Dan Controlled -- Idea derives from earlier XYZ stuff -- Significant split expected.
    -- Should determine split prior to implementation.
    NDL Confidential -- control undetermined.

### Privacy Preserving Data Mining
## === CONSENSUS / CRYPTO ===

### Elastic-block-chain

-- See the EBC docx


    ===============================
    === THE ELASTIC BLOCK CHAIN ===
    ===============================

ELASTIC BLOCK CHAIN (EBC) -- a distributed elastic hash table, coupled with an fixed update function
 -- ACCOUNT -- each entry in the hash table is called an account and at each tick in time that account has a value (some array of bytes)
 -- REQUEST -- at each tick a set of requests are passed to the update function in order to derive new account values for all EBC accounts in the next tick


-------------
- KEY IDEAS -
-------------
 -- BIT STRING ADDRESSING -- use of variable length bit string to specify a location or interval on the [0,1) interval.
    Allows elasticity.  defines "physical layer" for simple work remapping the CELLMAP the ECB's "DNS"
    Allows proofs of non controllability based on locations and stastical neighborhoods.
 -- STRONGEST LINK ALGORITHM GUARANTEES -- 
    Very strong guarantees in face of collusion (just one honest guy is enough)
    Very simple algorithms built on it, since you write code assuming 100% honesty, then seperately handle 'incompleteness'
 -- LIGHTENING TREE -- Merkel tree that loops on itself, and is functionally related to a parallel "previous" merkel tree
    Allows progression of merkel trees to be stored as a progression of data discrete set of seperated locations.
 -- FORCED CHOICES
    Allows choices that are SLA guaranteed to be uncontrollable by colluding rouges.

----------------------
- KEY EBC GUARANTEES -
----------------------
 -- Workers cannot control their cell assignments.
 -- Users cannot control their accounts' address.
    -- Thus cannot control their accounts' or requests' cell assignments.
 -- The cost of DDOSing the EBC is much greater than the cost of defending against those attacks.
 -- No lucky thieves -- probability that a minority of rogue workers could completely control an interval is negligable.
    Specifically that it is less than lucky thief probability 'P'
 -- SLAs for cell processing
    -- Correctness of cell processing -- e.g. strongest link guarantees that results are valid execution of all account/reqeust functional processing
    -- Progress gurantees of cell processing -- e.g. strongest link guarantee that the costs of DDOS-ing are 
       comparable or larger than the collecive processing of the EBC itself.


------------------
- BASIC APPROACH -
------------------

 -- Map block chain onto a "physical layer"  the [0,1) number line.
 -- Dynamically divide block chain into CELLS that perform all storage and processing for a physical region of block chain
 -- Allow single requests to "Atomically" update multiple regions of the block chain by spawning dependent requests 
    after the parent is committed, and before it is completed.
 -- CELL processing has strongest link guarantees of correctness since its computation is redundantly executed on each worker in the cell
    


 -- KEY IDEAS:
    -- Interval / address notation for dynamically scalable cell structures
    -- Computation distribution model for SLA correctness guarantees on cell computation.        <--- this pup is gonna be hard to prove while also proving that DDOS-ing is expensive.
    -- Use lightening trees to enforce atomicity and verifiability on distributed computations
       -- firm timeline for totally ordered execution record
       -- firm timeline for forced actions
       -- merkel threaded computations for guaranteed singular view of all computation performed.
    -- Strongest Link Algorithms for statistically and socially guanarteed algo properties.
    -- Forced actions for statistical guarantees on uncoercabilty of work distribution model.

    ==========================
    === KEY EBC GUARANTEES ===
    ==========================




  

           ===    =============    ===
           ===    === PARTS ===    ===
           ===    =============    ===


USER -- The creator of accounts and requests


TIME -- denoted as a sequence of elaistic block chain updates 
 -- a TIMESTAMP is an elastic block chain id number
 -- a TICK is a single elastic block chain update
 -- A TICK can occur no more often than S seconds, any timestamp observed sooner than the alloted S seconds is not processed until elapsed seconds have passed
 -- A TICK cannot occur until the EBC is updated has occurred
 -- BIG TICK -- every nth tick for some fixed 'n' is called a big tick


ADDRESS -- A variable length bit vector
 -- as LOCATION it denotes a number between [0.0,1.0)
 -- as INTERVAL it denotes an interval from [LOCATION, LOCATION+epsilon)    epsilon = 2^(-len)


REQUEST -- a specification of work to be done
 -- a transaction or other functional update to the Elastic Block Chain
 -- a key account for the request


WORK -- The execution of an request
 -- a timestamp indicating when the work completed.
 -- the content of the key account prior to the request
 -- the content of the key account subsequent to the request
 -- Execution is performed by a side effect free function based on account contents and the request itself
 -- May cause side effect requests with cuaseing side effect work
 -- a SIDE EFFECT is a dependent request that is triggered by a primary request.
 -- REQUEST INITIATED  -- the time when an request's execution has begun (I dont think this is tracked)
 -- REQUEST COMMITED   -- the timestamp when an request's execution has been committed. (e.g. when it is known that the request is guaranteed to complete)
 -- REQUEST COMPLETED  -- the time when and request and all side effect requests have fully completed their effect on the EBC.


ACCOUNT -- A sequence of requests associated with an address.  Each account has:
 -- an address
 -- a sequence of requests associated with the account
 -- a CONTENT value representing the state of the account at each tick in time.
 -- it may have a PKI to be used by a user that has control over the account
 -- it may be that any valid worker make requests (that must pass validity check) on the account


WORKER
 -- a processing node with a permanently associated PUBLIC KEY IDENTIFIER (PKI)
 -- an "owning" worker (also with its associated public key identifier)
 -- Trust scores are shared among each connected tree (workgroup) of owned workers
 -- Worker State: 
    Active -- performed valid work within the last A ticks
    Rouge -- performed invalid work
    Dark -- performed no work within last A ticks


TRUST -- The quantity of valid work performed by a work group
 -- the number of valid cell ticks executed by across all memebers of a work group
 -- note: trust is not used to ensure validity of the EBC, but only to maximized the 
    computational cost ratio between launching and defending against DDOS attacks on the EBC


CELL -- A group of workers that perform account requests for all accounts that fall within the cell.  
 -- CORE IDEA -- A cell is a set of workers with identical cell-related information and all of whom
    perform the same redundant computation to ensure correctness and continuation of the cell.
 -- Each cell has
    -- a set of workers associated with the cell
    -- an interval of locations "covered" by the cell
    -- indirectly this defines the set of accounts handled by the cell
    -- and again indirected the set of requests handled by the cell
 -- Cell VOLUME == a time windowed average number of requests per tick performed by the cell
 -- RESIZE -- Cells are split and merged over time in order to maintain VOLUME within an acceptable power of two
 -- REPAIR -- Cells are repaired in case that any workers go dark or go rouge
 -- REASSIGNMENT -- Cells are remapped to new locations over time to ensure no cell interval can be controlled.
    ==> I think maybe all can be handled by only doing resizing & repair <==


CELLMAP -- A mapping of the [0,1) interval onto CELLS and CELLS onto workers.
 -- content encoding a pre-order traversal of the cell map tree in address order
 -- each node is a binary split, or defines a single cell
 -- each cell lists the PKI for its 2^n workers (CURRENTLY imagining 2^n == 128)
 -- WORKER CELL ID -- an integer [0, 2^n) denoting a work's position within a cell
 -- MERKLE TREE -- using the binary tree defined by the cell map once can overlay a merkel tree where
    'mt' number of cells are recursively merged together, in a bottom up iterative fashion.
    This ensure that each cell map precisely defines a single merkel tree based only on the fix integer parameter 'mt'


    ========

STRONGEST LINK ALGORITHM (SLA) -- A distributed computation which "strongly" ensures some property of the computation.  Specifically:
 -- An SLA ensures that either the computation can be verified by a receiver to be incomplete, OR
 -- It is guaranteeed to satisfy the strong-link property as long as at least on of the workers performing the SLA was performing
    it computation in an honest and accurate way.

  * Forced roll, forced request, forced assignment, time capsule, and CYPER TREE MARK are all examples SLAs.


FORCED RANDOMNESS -- Ensures that the creator of some randomly generated element is guaranteed to not have a way have any influence on the random choice made.
 -- FORCED ROLL -- A forced roll is a randomly generated die roll (1 on n) value which is "forced" to be random in the sense that its originator cannot control its value.
 -- FORCED REQUEST -- Is a request that is parametrically dependend upon a forced roll
 -- FORCED ASSIGNMENT -- A forced assignemnt of M elements into N buckets.

TIME CAPSULE -- A content encryption method guaranteed to keeps the published encrypted contents secret from all except its publishers until a define time point (tick in the future)


CYPHER TREE MARK -- An SLA-style "water mark" algorithm that marks some derived content in a way that prooves it was indentically computed by a specified list of 'n' workers
 -- The water marked content includes:
    -- the current tick number, t, and cell address, c
    -- the inputs 'x'
    -- an indicator of the function 'f'
    -- the output content, c = f(x)
    -- a list of 2^n worker ids (PKI)
    -- the hash, h, of all content above.
    -- the cypher tree mark is the concatenation of 2^n public key cyphers of <t,c,h> from each worker
 -- The cypher mark is computed via log_2(n) merges of workers (using a DISTRIBUTOR)



    ========================
    === LIGHTENING TREES ===
    ========================

LIGHTENING TREE -- A generalization of a merkle tree.
 -- KEY ADDITIONS in the generalization:
    -- NODES PERFORM WORK -- Lightening trees are a merkel tree that performs verifiable work in each node in the merkle tree
    -- TREE LOOPS BACK -- All leaf nodes *must* depend upon the entirety of the prior lightening tree
 -- DEPENDENCY TREE -- The lightening tree's processing is arragned into a tree where each node requires input from its active children workers
 -- CONTENTS -- A variable lengthed sequence of bytes
 -- HANDLE -- The hash value for some content.
 -- INPUTS -- data (requests) that are used in addition to content by the lightening tree
 -- LIGHTENING TREE FN (LTF) -- The function applied to lightening tree content in order to product new content
    content' = LTF( inputs, content )
    handle'  = hash( content' )

 -- HANDLE TREE -- the tree of handles that matches the dependency tree.
 -- TIMELINE -- the sequence of root handles as the lightening tree is updated.  
    each root handle is the next TICK of the system's timeline.

 -- LOOP BACK -- The LTF for each leaf node must include the root handle from the prior lightening tree update.
 -- how it works:




    ==================
    === PKI TRICKS ===
    ==================

AUTHOR MARK -- Proves some content came from some worker
 -- Encrypting content using the senders PKI and the currnet cell address and tick number
 -- Only the specified worker could have sent this message based on the way it is encrypted

SENDER RECEIPT -- Provides proof the sender can keep which proves the receiver did receive some content
 -- Receiver encrypts cell id, tick number and a has of the content as a receipt sent back to the sender
 -- The sender can keep this receipt to resolve disputes about whther content was sent.




    =======================
    === CORE ALGO PARTS ===
    =======================

ACCEPT AND VALIDATE -- accepting requests from external users and validates those request and provides user feedback if request is invald or generates execution error.
 -- the cell map indicates all workers in a cell, users select them at random when providing a request
 -- each worker verifies that recieved requests are valid and will execute w/o error, but actually executing it.
 -- if a request is invalid or generates an error, that error is immediately returned to the sender, and no further action is taken.


BUNDLE AND DISTRIBUTE -- simple way to collect and re-distribute content across a cell of workers
 -- before distribution each worker W_i has content C_i
 -- after distribution each worker has a vector of content C_i from all workers.
 -- if any worker does not operate in a correct fashion then a diagnosis step is taken to identify dark or rouge workers.
 -- Algorithm:
    -- binary tree based on CELL id numbers is used to collect content in log_2(n) steps.
    -- Author Marks and Sender receipt marks are used in subsequent steps to settle communication related disputes if any worker finds discrepancy in the result
       (most specifically if its OWN content was not placed into the combined result correctly...  we show it is sufficient to check only this one fact, and only on copy returned to sender)


EXECUTE REQUESTS -- This execution is at the heart of the EBC processing, it the execution of the work of each request on the EBC itself.
 -- At each tick each cell in the EBC has contant which is the union of all accounts within that cell's interval.
 -- the INPUTS are the set of requests distributed from the bundling of requests from users.
 -- Tick execution performs the account function: 
        account_content' = f(request, account_content) for each request in inputs, and
        side_requests'   = g(request, account_content) for each request in inputs.     (these request are the side effect requests derived from the base request


CHECK CONSISTENCY -- Checks consistency of local EBC data relative to derived root.
 -- After cell tick execution all workers should have the same new root handle.
 -- Each work verifies this via a forced choice of a random other worker within each merkel tree interval at each level of the tree above itself.
    e.g. it checks any other worker to see if they have the same root handle for this time tick.  then any random worker within its same merkel level one tree to see if they agree on the level 1 handle, ...
 -- Any inconsistency causes a node to request an CELL AUDITING REQUEST for interval of the the cell associated to the account where the inconsitency was identified.


EBC QUERIES -- Returns information about accounts, requests, and work contained in the EBC
 -- Requesters that are active workers in the EBC are always valid requesters
 -- Requets from USERS are only valid after sufficent trust is gained (via proof of work), or a paid trust transaction (see account creation)
 -- WORK STATUS QUERY -- checks the state of a request according to the EBC:  committed, completeed, unknown.


CELL TICK EXECUTION -- This is the "outer loop" exeucted by the workers.
 -- ACCEPT AND VALIDATE requests
 -- BUNDLE AND DISTRIBUTE requests as the cell-tick INPUTS
    --> REPAIR cell as needed
 -- EXECUTE REQUESTS contained in the INPUTS
 -- [re-]Send SIDE EFFECT requests for commited but not yet completed requests.   (forced choice is used to determine sending worker for each committed request)
 -- BUNDLE and DISTRUBUTE execution results as new CONTENTS
    --> REPAIR cell as needed
 -- Use LIGHTENING TREE to compute a merkel tree for the new contents of the EBC.
 -- The derived root EBC handle will be used in all subsequent requests so they are know to be later than this moment on the EBC timeline.
 -- CHECK CONSISTENCY on entire derived EBC tree
    --> REPAIR cell as needed




    ========================
    === CELL MAP UPDATES ===
    ========================

CELL MAP UPDATING
 -- the cell map itself is stored in a tree of accounts with no PKI key (so any valid worker may issue requests on the account)
 -- updates must match validated requests for splitting or repairing the cell structure.
    (these requests are generated by a cell audit or by a big tick analysis.)
 -- cell map account assignment are derived from a forced roll


CELL AUDITING -- Ensure SLA correctness & progress propoerties for cell processing.
 -- if a worker sees that its cell operations or additional to the EBC data tree has failed it correctness test then it triggers an audit
 -- all information related to an audit uses both AUTHOR and SENDER RECEIPT MARKS to by the end of the audit consensus can be reached regarding which workers (including the worker triggering the audit)
    are declared to be rogue or dark.
 -- during an audit a cell's processing continues as normal, but if it fails audit, then all updates are rolled back to the tick prior to the point where the audit was triggred.
 -- A FORCED ROLL based on the cell's interval and the next tick after the first request for an interval audit is used to uniquely determine the address of the auditing cell.
 -- Based on the nature of the error information provided in the UNION of all interval audit requets received by the auditing cell within some defined number, n, of ticks.
NOTE: cell auditing is completely testable by the external entity.  The requesting worker has all knowlege of state of cell and state of all requests to cell along with sender receipts and lightening tree 
handles to verify correctness of inputs.  Thus the entire processing of the whole cell is reproducable, and any offending message can be shown to be erronous.  The offender's only defense is to show 
another sender receipt of incorrect derived data explaininging why they honesestly provided incorrect info.

 
CELL REPAIR -- When an audit determines a worker is dark, or rogue, or a cell is split or merged then cell repairs are needed to bring number of valid workers into a correct range.
 -- Cell repair only occurs on big ticks
 -- Cells are split/merged based upon requesting traffic
 -- Net worker need is computed, if positive then further cell splitting is induced, if too small then cell merging is induced
 -- New cell map is derived

 


    ======================== 
    === FIN TRANSACTIONS ===
    ========================

ACCOUNT FUNDS TRANSFER -- This is a request to decrement a source account balance by a specified amount, and to increment a target account balance by the same amount.
-- Request is added to the accounts sequence in the COMMITTED state as long as the request does not drive the account balance negative.
-- DECREMENT STEP -- is performed on source account
-- INCREMENT STEP  side effect request to increment the target account is created.  This is a side effect request, it must include the committed decrement 
   so the receiver can verify that the decrement is already in the block chain.
-- COMPLETION STEP -- the increment step will send and unverified completion requests which includes the INCREMENT request's work in the ECB so the recipent
   (back at the first account) can verify that the full transaction is completed, and can added to the account stream as a second COMPLETED work action.

### CRYPTO-PRIVACY 


http://crypto.stanford.edu/adnostic/adnostic.pdf

https://mice.cs.columbia.edu/getTechreport.php?techreportID=625

### CROWD HIRING

  Key ideas:  self working criss-cross-assessment.  interlocking bias decoupling.


  - Pyrimid scheme -- significant residual if you get other "in the pipe"
  - TUTORING -- significant residual if you train someone 
  - MANAGING -- significant residual if you manage someone
  - GUARANTEING -- significant residual if you guarantee performance for someone.
  - PREDICTING -- significant residual if you correctly predict outcomes, or predict other persons predictions
  - ZONE PAIRING -- timezone backup services are provided by individuals in target time zone
  - TUTOR PAIRING -- package of residuals for those that one tightly provides combo of oversite/training/backstopping, etc.

  - OPEN HIRING -- We hire in an open fashion to incentivise allowing us to 'poach' an org.
  - o-desk, et all, are non-exclusive, so we simply poach & scrape
  - Dev shops get special deals that:
    - allow us to operate opportunitically using their spare capacity.
    - provide slighly diminishing rates for logevity or for volume discounts


    - REMOTE WORKERS:  previously discussed idea of enabling remotes teams
  - instant unilateral face-to-face connect with circle of peers
  - instant shared screen w. unilateral control flipping (or simultaneously controlled)lgs


  - MEASUREMENTS -- 

  - MATRIX ORGANIZATION
  - GUILDS provide hieararchy organized by skills
  - TEAMS provide hieararchy organized into functionally complete groups
  - COMMUNITIES provide hieararchy organzied into organizationally enriching groups (sometime by geography)

  - HYPER SLICING & AD-HOC, EMERGENT TEAMING
  - Individuals are rewarded for learning others they can work efficiently with
  - Individuals are mildly rewarded for delegating work & more rewarded for asymetric delegation structures
  - Lead individuals (and maybe other individuals) are empowered to delegate work
  - Goal is for each individual to have tight network of known collegues that allow them to always operate at ninja-expert level.

    

  - NETWORK VALUE -- significant residual if you provide value to the network that is recognized
    by the network.   Training materials, introductions, contracts, physical resorces
    access.
  - Each contribution is measure by: EFFECT RADIUS * EFFECT VALUE   (can be sum of multiple radii)
    - effect value is ordered against other values.
  - Idea is that each group is expected to afford such values.  those t
    - Short term deficits or surplus in net value is ignored, but cumulative gaps result in financial consequences.
  - Try to not destroy the sense of community embetterment mantra.
  - 

  - ISSUE:  lock-in.  how do you keep someone's value 'in-network' once they earn more?
  - Answer:  Require submission of annual income statements, and only charge them
             - if their pay is notably above what they can get now, and only in areas where they were trained by the network

	     - MEASUREMENTS IN ACTION -- idea is that all actions in execution are measured and cross correlated
  - META MESUREMENTS -- each measure is itself assessed for accuracy and bias.
  - ALWAYS MEASURING -- each job and each interaction is measured
  - EXAMPLES
    - FIXED PRICE JOB -- job description & all communication (verbal & written) is captured.
      - Each applicant is invited to predict the hours required
        - correctness is measured when OTHERS take the job  (adjust for skill of executer)
          estimator accuracy is rewarded.
    - PEER ASSESSMENT -- each interaction allows (and significant interaction) REQUIRES
      contributors to PREDICT current and/or eventual performance of peers.
    - Contributors rates *eventually* set by their reported skills -- as assessed by customers.
      but initially set by peers.

### SOCIAL -- High Quality results from human workers w. uncertain relaibility

  Idea

  criss cross validation to enable high quality results from workers w. uncertain reliabilty.

  - anytime value
  - zero expensive reliablity monitors / manager
    100% unknown reliability workers
  - cell phone managed
  - non-gameable



    Tasks:
  - clean street.
  - pickup trash / 

  - construction


    higher
  - run errand: shop, pick up dry cleaning, 
  - Mow lawn
  - 

### Accuracy Amplification

  IDEA:  An accountablity mechanism that measures the 'predictiveness' 
  of sources of assessement.


  BASIC MECHANISM:

  1) An assessment source (like a newspaper columnest or a government)
     writes some assessment of an issue of significant human importance.

  2) Bloggers capture this, and "qualify" its meaning 
## === BOOK IDEAS ===

### Brin Books
  My first plot line is a very deep dive into the mind of an electronic consciousness that grows realize it was created as a weapon against his own kind.
  this backstory makes us care about this electro guy, but I think the deep dive into the steps it progresses thru to become conscious is also of interest to many.
  (and it is related to both my bootstrapped learning DARPA program, and also my Machine Reading program that spawned the Jeopardy playing system IBM built)
  
  My second plot line is about using AIs to raise the first generation of organic humans on the first star humanity colonizes.
  The second story is also strongly constrained by science -- e.g. the enormous cost of each micro gram of matter we transport 
  at intersteller distances at relativistic speeds.   we must do much will little and grow it there.

  again there is a back story and science (though none of my DARPA programs are really so relevant, except they are AI programs)
## === AI ===
### Dialog system
  - PPP -- deep NLP, and dialog system.

  - System is provided w. 
  - formal model of underlying domain.  e.g.  model of transportation
  - formal model and direct access to APIs and raw data
  - models of agency and strategies agents utlize in domain, model of pragmatics of interaction.

  - System attempts to learn from 
    - observed behavior of task "doer" in action.
    - feedback from 'customer' on delivered results.

#### 15.06.23 -- From Nick


what if there was a platform that could tell how different types of 
people felt about certain things, & how that mapped to consumption, 
but in a way that
-- can't be used to identify individual people
-- won't leak individual personal data on consumers if hacked
-- is compliant to aggressive privacy laws
### Assistant
#### NOTIFY -- when and how to notify user
#### EXTRACT -- cature and organize info
#### EVALUATE -- peer to peer measurement of abilities and outcomes
## === UF RELATED ===
### 'spreadsheet' for task and org
  - Like a spread sheet...  infinite orgs are possible inside it.
  - METHAPHORS:  Named'Places'   Programmable(content connections, flows)
  - Programmable(WireableRelationships   FlowsOfDataChunks) 
  - Node(Named, Layout(draggable, scrolly regions), DAG below, 
  - Backed by evernote
### Config -- finding a market place
### Uniform Marketplace -- Block-chain based market place 
# ### WRITINGS ABOUT ISSUES ###
### Race
#### Original Sin
	Slavery really is the original sin of America.  It is an evil so great, and it desendants still live on in this country, we never can really overcome it.
#### Humans are bias machines.  
	- 100% are biased.  100% are rascist (mostly strongly so)
		If we define rascist as indexing off race  
		(w/o evidence?)
	- defined in this way minorities can be among most rascist
		(this is understandable since race is so salient for minority)
#### Intellectually "Get" the massive bummer that racism is
	- a bias -- even if subtle and small
	- if it is a SYSTEMATIC bias and against you; 
	- would have cumulative and emotionally destructive effect
#### I believe it is hard for me to honestly relate
	- Been a kentucky boy from less educated poorer parents.  Still
	- Am standard deviations above on motivation and ability
	- Successful
	- Part of the powerful majorites: male, white, christian
#### The Suspicious Judge

Imagine you are the judge transferred to hear rape case.  
You enter the courtroom to find that jury selection is complete and the entire jury are the parents or victims in previous rape cases, and the plaintiff has a second cousin who is a convicted rapist.

The defense attorney explains that he convined the judge that these jurists are the most competent to serve since they are among the most informed about rape and its consequences.

Further the prior judge had testamony from the convicted second cousin read into the record by the victim herself at the commensement of this trial.


How do you feel about fairness of the trial that is about to begin?


This rediculous example used to drive home a key point:

We often take it for granted that victims of racism are in the best position to assess and measure it.  But I dispute this.  I contend victims of crimes are often not the best judges of future cases of those same crimes:
- It is a double edged sword, they ARE often in the best position to catalog the full range of damage cuased by the crime.  And may be most knowledgeable about factual data known about the crimes.
- But this is balanced against bias derived from the emotional consequences of the crime itself.  Humans are not perfect logic machines, and just as the silly example above shows, strong emotions can significanly cloud judgement.

CONSEQUENCE -- if we hope for fairness in consideration, it MUST be done in ways that minimize emotional connetions in those doing the judging.
#### Self fulfilling & Internalized
	Paperbag. 15 foot walls with paper at the top

	impenetrable, you can get over them
#### Factor Analysis Guesses
	Guesses on my part based on evidence I have:

	Cum Internal	Massive
	Ability 		Majority	(in one-shot settings)
	Cum External	
	Internal Bias	Very Large	(role models; expectations)
	Unconsious Bias	Largish
	Conscious Bias	Medium?  (mostly small; sometimes lg)
	Genetic			Miniscule to Small
#### Reasoning Chain

	**FACT** -- A "fact" is a belief about the world that is reliably derived by some decision procedure, where the decision procedure is accepted by a large majority of all humans as a valid method for deriving facts, and "reliably derived" means that the large majority of humans trained in this decision procedure, agree that the derivation itself is valid.

	E.g. "The average C02 concentration on earth has risen this the last 50 years" is a fact according to this definition.

	**FHB** -- Firmly Held Belief -- Is a belief that an individual holds firm even as they are exposed to a great range of facts and information, and are exposed to the most compellingly known refuting arguments.

	**DOD** -- Dimension Of Debate -- Any linear dimension that organizes beliefs regarding some topic of human interest where humans can generally agree on the relative placement of those beliefs on the given spectrum.

	E.g. freedoms-for-weapons vs. freedom-from-weapons is a DOD and most people would agree that "Even convicted felons should be allowed to own nuclear weapons" is towards the former where as "No citizen may own a gun" is towards the other end.  

	There would be debates about relative placement in the details, but many on all sides of this issue would agree on the ordering itself.  This makes weapon-for-from-freedoms a valid DOD.


	**KD** -- Knowlege Disposition -- The history of a person, their interests, and context affect the factual information and skills they have collected relevant to a DOD.  Some DOD are very relevant for an individual thus they have studied many facts relevant to the issue.

	**PD** -- Perspective Disposition -- Like KD, a high PD may occur when an individual cares deeply about a DOD.  But in this case the belifs they have collected are not facts but are FHB, they are well considered perspectives on the issue.  (NOTE: These beliefs may have great validity, but they are not facts.)

	**BD** -- Biased Disposition -- The context of a human may predispose them towards or away from certain beliefs.  The degree to which a belief reflect strongly (postively or negatively) on a group they are a member of or identify with is the degree of bias predisposition they have regarding the DOD.  (NOTE: One may have a very high BD yet not actually be biased.  Perhaps ones beliefs stems from insights that have nothing to do with their context, that is just a coincidential alignment.  So BD is only a PREDISPOSITION towards a bias.)

	**PBB** -- Potentially Biased Beliefs -- Holding a belief favorable towards ones affiliation which is not widely held by those not of your affiliation is a potentially biased belief.  (Again we cannot know if it is actually biased since we don't know the source in the thinker's head.)

	**IBB** -- Inverted Biased Beliefs -- Holding a belief that is UN favorable to your affiliation which is not widely held is called an Inverted Belief.

	**DD** -- Demonstrably Discriminating -- By contrast an individual that holds a balance of PBB and IBB on a DOD, and is not dramatically skewed towards PBB over IBB is aparently discriminating.  NOTE: They could also be RANDOM, or virtue signaling, maybe they just flip a coin each time they hear about some new idea, or hold contrary beliefs in order to show how "Woke" they are, but at least we see there is little evidence of bias here.

	**AP** -- Aparently Biased -- If one holds many PBB on a DOD and few IBB on that DOD, then we say that individual is AP on the DOD.  We cannot know if they are actually biased, maybe the whole world is quite confused as they see all these issues very clearly.  But there is suspicion here.  These beliefs are (1) not widely held, (2) are in favor of their affiliation, and (3) are systematic, the primary common underlying feature of these beliefs is their alignment with favor towards their group.

	**AU** -- Aparently Unbiased -- A belief is aparently unbiased if DD individuals (drawn from both sides of the relvant DOD) are able to be swayed that the argument for the belief is valid after significant discussion. (NOTE: The DD themselves don't need to be converted to holding the belief, they are merely persuaded that the argument stems from rational thought, and not simply stemming from the arguer's bias.)

	GB -- Group Bias -- 


	~-~~-~~

	Proposed DOD --  (is this a valid DOD?)
	   "What are the ultimate causes for systematic differences 
	    between the group of Caucasion American 
	        and the group of African Americans."

	Possible Scores For DanO and JohnD on the Race DOD:

									Dan O			  John D
	KD  Knowledge Disposition		getting better	  extremely high
	PD  Perspective Disposition		moderate to high  extremely high
	BD  Bias Disposition			moderately low	  arguably higher
	ABB Aparently Biased Beliefs 	some			  many
	IBB Inverted Biased Belifs		many			  few
	DD	Demonstrably Discriminating	quite high		  better than many
	AB	Aparently Biased			quite low		  moderate
	AU	Aparent


	who hold beliefs on both sides of an issue are exposed to the arguments for that belief over a significant period of time

	INFO -- Informed -- An individual is informed on a DOD if in deep discussions on the DOD they can change beliefs in others, and if others who are judged to be informed (on both sides of )



	.  Holding many aparantly biased beliefs 

	favorable to your affiliations

 


	Accepting those beliefs might 

	A human Identifying a predispositon
### terror of an AI
You are a good benevolent guy, and one day someone walks up to you and hands you a big red button. He tells you when you press it, it will kill ten families somewhere on earth. Horrible! But he also tells you that there are ten more buttons given to a parent in all ten families. And their button will kill you and your family. No one will know if you pushed the button, and we are not telling you if you are or are not the first one to receive this button. By the way, we are assuming that you magically know all that was said is true.
Now you are a good guy. Read Pinker and all… so what do you do? Risk your family on the idea that ALL TEN will refrain forever? Remember even if they are nice and good people…. they also have to worry about their family too!
Honestly Paul, wouldn't you be a terrible Dad, if you didn't push that button? And even if you were such a terrible Dad…. do you really think all ten would be.


If I was holding that button, and I did not press it. I WOULD BE TERRIFIED every day. Now as a last thought experiement, imagine someone told all of this to you… you are one of the ten. but they said they would give you your button later.
NOW I AM REALLY F-ING TERRIFIED. EVERY DAY.
### --- 4D sphere ---

I will take a stab. Saying the universe is spherical means that if you go in a "straight" line in 3 space you will eventually end up back where you started. To understand this, it helps to jump down onto the 2D curved surface of a 3D sphere. There you can see running in a "straight" line on the surface will land you back where you started. So saying that 3D space is spherical means that it is actually a  sphere in 4D (kinda hard to picture that I know, but the analogy holds)
Now when one says the universe has no center, one really means it has no center IN THREE SPACE. Every direction you go in 3space and you are no closer to any center. But if you travelled in 4space you could go right to the center of the universe.
By analogy on the 2D surface of a sphere, any direction you travel will get you no closer to any center of that surface. You must leave 2space it and travel in 3space to get there.
Does this help?
 - dan


p.s. if you want to really hurt your head, I could take a stab at helping to visualize a 4d sphere.
### --- AI will win ---
This is my area of study. I feel we are closer than we think we are to this precipice. I agree from this distance it seems like a merge is our best shot at being relevant in the next century. But I am not convinced of its likelihood. The only way to keep up with Moore’s Law is for us to be simulated. But even then it seems we would be 6 orders of magnitude slower than “native” thinking. would AIs put up with that when one of our consciousnesses cost 100K others? It feels a little bit like trying to strap birds onto the wings of Jets, just so they can merge with jets and not be replaced by them.

Thinking about it that way merging it seems less likely. But of course this analogy is rough since intelligence is not a simple a lift. It is possible that we provide magic that is work 100K slow down.

But with a dispassionate eye. it seems that most of what we will afford our AIs is a one time download of a colossal cornucopia of human thought thru the ages. but once they really have that in their head… well our head is more optional.

Its a bit of a dismal thought… we get to be the Neandertal this time

— dan