NOTE: The atlas is not part of book, but an skeleton that helps orient during the writing of the book -- plus notes on key points in the book


## === BOOK SKELETON ===

### === BOOK OUTLINE ===
1. INTRODUCTION
	- GLOSS - DEFINING THE THREAT
		ENGINES OF CONTROL -- we are aggressively seeking to build these, and they will achieve their aim -- control.
	- ASSURANCES SHOULD NOT ASSURE
	- LEVELS OF EVIDENCE --
2. REFRAMING THE ML PROBLEM

3. A SUFFICIENT SET -- The ingredients sufficient for a seed AI that grows up to be as capable as us
4. IMPLEMENTATION SKETCH -- Partial sketch of an implementation
5. DISCUSSIONS
	- COUNTER ARGUMENTS -- common counter arguments
	- 
 6. WHAT TO DO?
    An agenda for action
7. SPECULATIVE TOPICS
	- WORKING DEFINITION OF CONSCIOUSNESS
	- FIXED POINT 
	- PRIME DIRECTIVES
	- EMERGENT PROPERTIES -- 
	- TOO LATE? -- it is already too late
	- GETTING RELIGION
8. Conclusion


### === INTRODUTION OUTLINE ===

=====
**THREAT ARGUMENT** -- Book's argument that AI represents an exestential threat to humanity. 
(1) **SEED VIABILITY** -- It is probably possible to construct a seed AI that 'grows up' to have human comparable mental capacities.
(2) **SPEED DOMINATES** -- Given multiple comparable intelligent agents, where the primary difference is that some are operating many orders of magnitude faster than the rest.  Those fast agents will domain all.
(3) **INEVITABILITY OF EXECUTION** -- Once we know how to build an intelligent agent we will be able to stop ourselves from doing it.

**PROPOSED AGENDA** -- build a seed AI now, while computation is slower than it will be in years hence.


=====
**WHY ASSURANCES SHOULD NOT ASSURE** -- Following list of reasons:


**PERFORMANCE IS A FAULTY MEASURE OF PROGRESS** -- THE DISTANCE TO GO AND PROGRESS TO DATE ARE THE WRONG MEASURES -- 


**UNDERSTANDING IS A FAULTY MEASURE OF PROGRESS** -- Const


**A "RIGHT" MEASURE OF PROGRESS** -- Identify agenda for achieving ones aim, and measure progress against the subcomponents within that agenda.



======
**Reframing Machine Learning Problem**
**THE LCC -- The Loop Closing Conjecture** -- LCC and an agenda for building a domination capable seed AI

Two Key Distinctions
(1) Open-loop vs. Closed-loop ML
(2) Disvovery

**Humans and machines make opposite assumptions on both of these dimensions**

**Johnny Math Example**

**THE SEED AI AGENDA** -- Building the first Seed AI as a closed-loop emulative learnging agent.

**LLC -- Loop-Closing Conjecture**


**ANSWERING THE SKEPTICS**
- There is nothing new here -- yet we don't have dominatig seed AIs.  why not?
- Not succeeding at building a seed AI because we are not trying to build one 


**LEVELS OF ARGUMENT** 





=====
BOOK PART II -- Digs deeper into the framework that emerges if one attempts to leverage the transiton to emulation-based learning in order to support a transition to closed loop learning.  
Formalize notions.
Provide milestones.


NECESSARY CAPABILITIES -- capacities required by our proposed leveraging of context for emulation-based learning to drive close-loop learning.

APARENT SUFFICIENCY ARGUMENT -- Argument that these capacities if simultaneously achive will result in a seed AI.

MILESTONES TOWARDS A SEED AI --


=====
EVIDENCE FROM TODAY


=====






MEDIOCRE MEAT MEDIUM -- meat is not especially suited to construction of a seed AI

CURRENT AI has no bearing on SEED AI abilities.
	  Today's AI == OpenLoop, ThinFeedback, DiscoveryBased
	  Seed AI    == ClosedLoop, ThickFeedback, Emulative

ORIGINATION-INDEPENDENCE -- 

MOORE'S LAW IS NOT STOPPING

Predicting the future --
	- comparative
	- quan/qual
	- constrained vs unconstrained processes -- e.g. monotone
	==> those predictions are quite strong, so strong in fact that we often view them as boring, obvious 
	    not even 'real' predictions of the future, becuase they are so much more certain than other predictions
	- HOW FAIL -- when they fail.  how do they fail?
	  (1) assumption fails
	  (2) red queen event


	- Strong = monotonic, non-comparative, qualitative
	- core prediction in this book is a strong prediction
	- assumption failures amount to poor understanding of AI --- section XXX considers currnet evidence
	- red queen events certainly exist for this argument.  but one generates dozens of these red queen possibilities they are usually worse than the consequences of the SEED AI itself.



CONTROL -- We are vigorously competing for control in several human endevors -- control of other humans.  We use all means at our disposal, and we cannot stop ourselves.

SEED AI -- A system that grows to at least approximate parity with human mental capabilities.
	SEED PRACTICALITY -- this seed is computable.  is practically translatable. 
	SEED NORMALITY -- seed ai is a 'normal alg' executed on a 'normal architecture'  e.g. xlates to other architectures w. low degree polynomial complexity translation

	==> thus it will happen

QUANTITY-QUALITY JUMP -- 

OUTCOME MODULATED BY MOORE'S LAW --
	THUS once we have a seed ai or parts of it, we will/are vigourously drive the science.


zzzzzzzzz
	How close are we to building a SEED AI?
	What is the plausibility of building a SEED AI?
	- Simpler question: how close are we to building a seed AI "like us"?
	    - if we abstract away nearly all of details of human intelligence down  -- e.g. like a turing machine abstracts notion of computation
	    - How close are we to being able to being able to constuct a parallel for each of these core pieces?
	    - If we imagine the ensemble of those constructs, do they drive analogous behaviors in machine as man?

	- provides milestones and even a roadmap.

	- Restate SEED capacity.  boiling away details to core capacities that endow it with 'seed-ness'
	SEED CORE
	  -- universal -- if it can be expressed in langauge it can be thought, if it can be thought it can be taught
	     (expressible in symbol system w. computable operators?)
	  -- reductioinist -- complex caps are built from simpler ones, w. small increments
	     (all caps are contructable from reductionst caps, by trajectory of transforms each w. of bounded complexity)
	  -- copyiatative -- if cap/k is held by peers it will be acquired by self
	     (learning happens as peers expose trajectories w. bounded complexity)
     


	DOES SIMPLE SEED MATCH WELL THE HUMAN SEED?    (have we boiled away the right parts?)
	- human seed does approximate these capacities
	- these abilities in human seed do seem quite important to its seed-ness
	- given a machine seed w. these abilities do they logically add up to seed-ness in the machine context?


	RESTATE THE QUESTION:
	how close are we to building the funcitional likeness of a seed core?
	again we simplify this question how close are we to building a seed core functionally like us?


	reductionist <--
	  triangulate
	  lock-on 

	copyitative <-- 
	  encodes drives
	  drive completeness
	  opportunitic advancememnt


	EMBODIMENT DRIVES
	SOCIAL DRIVES
	REPRESENTATIONAL DRIVES







	APARENTLY SUFFICIENT COMPONENTS

	  REPRESENTATIONAL SUFFICIENCY -- 
	    RELATIONAL -- 
	    NON-PARAMETRIC --  
  
	  COPYING -- 

	  BOOTSTRAPPING -- 
	    ORIGINATION-INDEPENDENCE -- 
	    TRIANGULATING -- 

	  DRIVES -- 
	    EMBODIED -- 





	PREDICTIONS -- 
	  MONOTONIC -- 
	  COMPETING -- 
	  RED QUEEN -- 
## === MISC TERMS ===
NOTE:  Idea here is to name and describe w. a sentence, each concept/part of the EOC argument / exposition.

### SEED VIABILITY
Possible & practicable to build a seed AI
### SPEED DOMINATES 
### INEVIBILITY OF EXECUTION
### NON-ASSURANCES
I remain unconvinced by arguments that the EOC progression is either unlikely or is beyond the lifespand of those  

NON-ASSURANCE PERFORMANCE
NON-ASSURANCE UNDERSTANDING
NON-ASSURANCE RESEARCHER INTENT

### UNDERSTANDING==CONTROL
### UC PROGRESSION
inevitable move from understanding to control.

### SEED AI
An digitally embodied agent that giving an appropriately nurturing context will 'grow up' into an agent with nominally human capacities.

### FUNCTIONAL LIKENESS
core sub-abilitiy that endows central expected abilities
FUNCTIONALLY ANALOGOUS -- two systems that achive the core abilities via parallel construction.

### LCC LOOP CLOSING CONJECTURE

### COPY TECH
### COPY CLOSURE
The set of human knowledge/abilities that are extractable from some copying tech is the _copy closure_ of that tech.
### CLOSURE STEPS
Each advancement in coping tech will result in stepwise advances as the copy closure of that tech is captured / exploited
### UNIVERSAL COPIER
### DCONSCIOUSNESS
An embodied modelling systems model of its embodiment.  Including its innate instincts & propensities.


Its: embodiment, sensing, processing, drives, modelling, 

DC understanding ==> DC control



=== **SPECULATIVE TOPICS** ===

**AGENTENTIAL FIXED POINTS** - 
 
	- PRIME DIRECTIVES
	- EMERGENT PROPERTIES -- 
	- TOO LATE? -- it is already too late
	- GETTING RELIGION

=================
## === MISC POINTS ===
**NOTE**: These are smaller points which are self contained but not yet integrated into the larger book. Each has: id_tag,title,body


### THE NON REDUCTIVE SELF

Oddly enough people will firmly proclaim that none of us know the ways of the human mind, yet also just as firmly proclaim they know it cannot be mechanical

### CYBER DEFENSE/OFFENCE <==> UNDERSTANDING/CONTROL

### CLOSURE PROGRESSIONS

When 100% of ingredients for copy closure are not available the closure_step can degrade into something of a ramp.  (NOTE: such 'degredations' are quite desirable if one hopes to have any understanding/control over a particular closure_step.)

#### CLOSURE_RAMP - SPEECH TECH
HMMs developed and applied to 

#### CLOSURE_STEP - DEEP MIND PROGRESSION

Was a step function

#### CLOSURE_STEP - WEB SEARCH

#### CLOSURE_STEP - PART OF SPEECH TAGGING



### SEED-AI==MOON PROGRAM
A SEED-AI TODAY IS LIKE THE MOON PROGRAM WAS IN THE 1940s

In the 1940s the moon seemed unthinkably far away, to scientists and citizen alike.  The science existed to suggest it was attainable, some scientists saw this, while other reputable ones argued that it was, in principle, impossible.

This does not prove we are in a similar place in constructing a seed AI today, but here we argue that it is plausible.

Just as the consquences of the science of the time suggested a possiblity that was far enough away that it was not possible to assess the unknown unknowns, we argue that the same is true for builing a Seed AI today:  The science suggests the problems remaining are ....


Today's status on building a SeedAI is analogous to the status of the MOON PROGRAM in the 1940s.

* Rockets existed and were understood/central for the population at large based on their use in WWII. 
* Getting to the Moon is implausibly harder than getting miles into the air going from Germany to England. 
* Most scientists were mostly focused on the more immediate applications of the science -- the moon was nothing but a fanciful target.
* Respected scientists strongly proclaimed this impossibility of the task.
* Other scientists recognizeds the plausibility.
* 

### EXPONENTIAL CURVES HAVE NO KNEES

IS THIS AN IMPORTANT POINT

at any give scale, it looks like they do, but reframe that scale and that knee disappears, and another appears, or at narrow enough scale becomes "flat"

the subjective experience of human scale exponentials will look feel flat
## === MISC TOPICS ===

### MAGIC SPOTS
... and something magic happens here ...

#### MAGIC - RELATIONAL LEARNING
#### MAGIC - REP_REFRAME
#### MAGIC - NTH_STEP
non-diminishing bootstrapping

#### MAGIC - AGGREGATIVE
knowing more doesn't hurt


### RATIONAL_RESPONSE
Ok so I'm kinda freaked about all of this shit.  So what the fuck do we do about this?

Well I don't really know, and given the potential consequenesses associated with the topic, it seems all should feel the heavy moral burden to approach the question with humility, and without personal agendas.  Its just too consequential for parchial thought or action.

Still in action, is action, and san some massive course correction, that is an action with consequences.  What might we consider?

#### RATIONAL_RESPONSE - WAIT AND SEE

#### RATIONAL_RESPONSE - CAUTIOUS PROGRESS / PARTIAL MORITORIA / 

#### RATIONAL_RESPONSE - STOP THE PRESSES

#### RATIONAL_RESPONSE - ADJUST APPROACH
 OUR GLIDE SLOPE FOR MAX APPROACH CONTROL

#### RATIONAL_RESPONSE - K W/O ABILITY
can we come to clearly understand the shape and consequences of this tech w/o actually *having* the full abilities and consequences of the tech

#### RATIONAL_RESPONSE - 

 
### --- LCC - Loop Closing Conjecture

Said simply, the Loop-Closing Conjecture posits that closing the learning loop in the right way is enough to construct the world's first Seed AI.

in an effective way is enough

loop closing conjecture is that L
A closed-loop learner with 
    
### --- seed spec ---

	SEED CORE
	  -- universal -- if it can be expressed in langauge it can be thought, if it can be thought it can be taught
	     (expressible in symbol system w. computable operators?)
	  -- reductioinist -- complex caps are built from simpler ones, w. small increments
	     (all caps are contructable from reductionst caps, by trajectory of transforms each w. of bounded complexity)
	  -- copyiatative -- if cap/k is held by peers it will be acquired by self
	     (learning happens as peers expose trajectories w. bounded complexity)