
**Thesis**:
- Humanity's predicament is far more dire than most imagine. 
- In these [[EOCK Last stages AGI development]] there is a remote possibility that we can [[EOCK Shut it all down]].
- Failing that, however, our last best hope is that we can shape outcomes in a way that is not catastrophic for humanity.

**Antecedents**:
- [[EOCK Cannot Stop Ourselves]]  and  [[EOCK Apex Predator]] 

**Justification**:


Discussion:

Some worry about a "fast takeoff" scenario where AI takes over so fast, in hours, days, or weeks, that we don't have time to react.
I am personally doubtful about the plausibility of this scenerio, nonetheless, I feel we have little chance to 