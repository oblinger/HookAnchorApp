# Journal.2006\_12\_21 --

    NATURAL INSTRUCTION METHODS

    Ladder API
    - [L]ingual
    - [W]orld
    - [G]estures
    - [D]iagrams    (Expressed using World input, where the perceptions are nodes, and links, node<<>>link properties, node<<>>link types) 
    - [B]undle      Interrlated sequence L+W+G
    Interlingua
    - [S]yntax      Operations:  IsValidInstance, GenerateInstance, AllInstances
    - [P]rocedural  Operations:  New Instance, Send Message, Recieve Message, WaitForMessages, Terminate
    - [R]ule<<>>Logic  Operations:  Assert<<>>Retract, Execute, Implies
    Interlingua Composite Objects  (Built using specializations of Syntax, Rule, or Procedural)
    - [PROCESS]  A process is either a rule set or procedure set.  Once instantiated it executes sending<<>>receiving messages until it executes a terminate statement.
                 A process has a 'main' procedure, and optionally procedures that are triggered by receiving messages.
    - [FN]  Function.  Process with only one 'main' procedure which WaitsFor one message after instantiation, and terminates after sending exactly one message.
    - [BLC] Bootstrap Learning Component.   Very complex composite with many fields composed from the interlingua

    Interlingua Ontologies (fixed ontologies used to communicate between learning processes)
    - Explanation:  derives, justifies, 
    - Structure:    List, Set, Struct?




    Ladder:Lingual   (A set of ontologies used to capture linguistic input from the instrutor)
    - Instruction Ontology:  ValueOf, ReasonFor
    - Process:      goal<<>>sub-goal, agent, action, effect, process, ...
    - Meta:         [Include Process], failure, thrashing, deadlock, efficient, ...   (used to talk about processes of instructor<<>>student)
    - Math:         +,-,...  and,or,not, 
    - Conceptual:   [Include Math], define, ...    (used to define new terms as a composition of existing terms)
    - L Strategy:   
    - Causal:       



    [WAY TO ORGANIZE NATURAL INSTRUCTION METHODS]  Where does the structure come from
    - Imitation<<>>Encoding:  from ladder
    - Refinement:  from interlingua
    - Discovery:   from nothing
    - Memory:      from other BLC


    Natural Instruction Methods

    - LWGD->S        Syntax Learning
    - LWG ->  P      By Demonstration
    - L GD-> R       By Diagram Presentation
    -  W  -> RP      By Refinement
    - LWGD-> R       By Example



    -------------------------------------------

    BY EXAMPLE (function learning)   -- Teacher provides annotated examples (with labels)
       INPUTS
       (1) EXAMPLES (expressed as Set Of Bundles)
       (2) Optional INITIAL FN     <<>>
       OUTPUT
       (1) Classification Function  (expressed in Interlingua:Fn)


    BY REFINEMENT (using objective function)
       INPUTS
       (1) Optional INITIAL Ruleset or Procedure.  (Interlingua:Process is taken from an existing BLC
       (2) Optional GENERATOR of problems is used to construct a world for testing purposes.  (Or current 'real' world is used)
       (3) LadderAPI:World connection used for interaction
       (4) Interlingua:Fn used to encode Objective Function (to be optimized by refinement process)
       (5) Optional THIN REFINEMENT THEORY used to generate new processes <<>>
       OUTPUTS
       (1) Updated Ruleset or Procedure   <<>>


    BY LINGUAL INPUT
       INPUTS
       (1) Instructor's explicit exposition of knowledge. (Ladder:Lingual)
       OUTPUTS
       (1) Logical or procedural knowledge    <<>>
       OUTPUTS
       (1) Refined ontology for domain  <<>>    (Possibly also some logic, but that is not the focus here)

       Syntax learning is performs over all rungs of the ladder.  This learning method is 'watching' all interactions for clues
       about new predicates/functions/objects and their relation to known ontological forms.  The evolving domain ontology is used
       as a constrained universe of terms for use by all other learning processes.


    ---------------------------------------------------

    EXPLANATION BASED
       INPUTS
       (1) A derivation or justificaton  <<>>
       (2) An example <<>>   ????
       OUTPUTS
       (1) 


    BY REPRESENTATION BRIDGING     (analogy, and functional mapping?)


    BY SKELETON FILLING  (Plan recognition)



    USING LIMITED INFERENCE


    -------------------------------
    CBR/ANALOGY/INDUCTION/ABDUCTION/INFERENCE
      These methods are core capabilities that can be employed across many of these different Natural Instruction methods,
      but they generally do not constitute a full learning process capable of dealing with any one NI method.
      
