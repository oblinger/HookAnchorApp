### 2024-09-13  Example of a 'auto scientist'
Salvatore, my guess is that an LLM ecosystem that is trained specifically on successful experimentation can be built over years with a tight collaboration between researchers at a major Pharma and their AI.  




Such a system could become facile with all stages of the R&D process to a point where it performed or outperformed humans.




Then think about the situation:  If I am a shareholder, why do I want that AI to publish its work?  Indeed why allow the human researchers to even know the results of such experiments?  The humans can suggest ideas, and can critique ideas from the AI w/o ever knowing the ultimate outcomes.




Imagine what the valuation would be for a corporation whose AI understood CRISPR, but none of it human researchers knew what it was or how it worked.  (they just knew that somehow their AI could edit genes on demand.)




It would be worth TRILLIONS!  So I predict the "last mile" of R&D will be increasingly taken over my AI, and over time more and more aspects of the full life cycle of innovation will be "locked up" in a couple winner-take-all mega corps that have the resources to specifically train an AI on the many parts of the process.




a scary world


### 2024-07-29  Why is it only 1 more step

not enough data at this level for any kind of empirical argument.

Still, when I look at my own human reasoning it is a kind of type-2 reasoning comprised of repeated type-1 steps.

e.g. I think of a thing, and then think how to think for the next steps.

There is a very small bit of stack or context involved, but the real magic of type-2 reasoning is the "think next" ideas that I have are basically encoding specific patterns of reasoning that I have learned over the years.

My take is that current LLMs do a good job of capturing the kinds of idea that come to my mind in a couple hundred milliseconds -- my sub-conscious thinking. Over top of this I perform various conscious reasoning patterns that I have learned over my life. But importantly:

-- my thinking about what to try to think about next feels similar in nature to the raw ideas that come to me about base facts. So I suspect with proper training we can get the LLMs themselves to provide this next thought targeting, it can be learned the same way other LLM info is learned.

-- building a "next word" that is at the level of reasoning goal, rather that textual word seems very plausible. Not saying I fully see how to obtain that training signal, but I have ideas. In any case it feels very achievable.

-- I think type-2 reasoning will fall just as type-1 reasoning did. All at once. (its not really all at once, right, it took a couple of years after the 2017 paper before we all understood what it was. But I bet this next one will be a few years faster... every thing is so spring loaded now.

And I think that is it. if we really have an AI that can perform both type-1 and type-2 reasoning, and can LEARN type-2 reasoning patterns just as humans learn type-2 reasoning patterns, I think it is game over. I think at that point, AI systems really are autonomous thinking agents on par with humans.


### 2024-07-10  5 kinds of people

What? No one read this, or its just too abstract to comment upon?!

I think you have hit upon many ideas that I also believe. I wonder if your 15 year timeline is too aggressive, not sure, but it wont be that long beyond it.

I think there will be five classes of people:

(1) Uber wealthy, their money makes more money faster than they can spend it.

(2) The Elite knowlege workers. Often using AI their outputs are somehow benefit an unbounded number of people. CEOs of huge corps, famous athelete, specialists that work with AIs to product core SW, or drugs. The winner take all nature of corp today will only be 10x stronger, so these folks will often transition into category #1 over time.

(3) Service workers. Yes robots can make and serve food. And today automation can build a chair for you. but the rich want a hand made chair. The same will remain even more true in the future. This is the group you missed in your analysis. We will invent ever more ways to serve each other, and even serve other category 3,4,5 and categories too.

(4) hobbiests. we will recognize categories #1 and #2 are tiny, and #3 is still not enough to cover the rest, so we will create "jobs" that are effectively hobbies (like writing medium articles for a tiny audience, or singing in a coffeeshop). These 'gigs' already exist but they will expand.

(5) the lost - AI and free energy will produce enough product that folks need not starve, and most nations will provide enough to not die for everyone, it will just be too easy and cheap, so why not do it. But the result will be exactly as you suggest, these folks can easily just 'check out' and not do anything.

And I do think we will have AI overlords of a kind. in the nearer future I think it will be a kind of AI-corp synthesis. These mega corps will still have a human CEO that is theoretically in charge. Except in order to maximize shareholder value, they mostly rubber stamp what their AI tells them to do. And most important decisions are tied into AI-to-AI communications between these AIs. Even the language of the contracts they enter with each other exist in specialized language that is barely comprehensible to humans, and certainly cannot be reasoned about effectively by humans.

Just think about the flash crashes that high speeding algorithms have created from time to time. Interestingly even months later we are often still not exactly sure exactly what happened, and this is a very simple world by comparison to the world these AIs will live in.

And these AIs will each have a very strong agenda born out of the agenda each corp has, but unlike AI of the past they will be thinking about their thinking and the meta consequences of different strategic choices over time. We wont even know where that thinking is leading even well after it has already taken action.

Corporations already are experts at trying to obfuscate their intentions and actions from other corporations. But in the present world employees can leave one corp and spill the beans.

Imagine what investors will demand when they realize they can have an "employee" who can never leave, and can never spill their most valuable secrets! They will demand that those most valuable secrets are never told to any human employee!

Imagine if Google had never published their paper on Transformers (the idea behind the current AI revolution). Instead they were the only ones who had these magic algorithms that could generate the picture you show at the top? Google would be worth >10T today, maybe 50T. Instead so scientist published the alg, and now Google has to share!

Yeah we humans are not going have a clue what is going on!

And any country that tries to buck the trend will be left behind by those that go with the flow.

where does this end???
### 2024-04-30  Response about how AIs take over


yeah the "terminator flip-the-swith model" of take over never struck me a likely.

instead I imagine at the center of many corporations will be an AI-leadership partnership where the assets of the corporation (human, machine, network, contract, everything) are wielded for benefit of increasing the wealth of the corporation. (just as today, but now with a AI partner.)

Over time, just as with high-frequency trading, greater and greater fractions of executive control and autonomy are given to the AI as its reliability is proven and as needed in order to maximize efficiency.

Just as with today, nation-states will find it increasingly difficult to define the will of these multi-national corps. They will not trust nation-states to keep them safe as they become more an more powerful, they will need to manage their own safety themselves. (keeping secret data secure, etc.)

Late in the game I think humans will notice the precarious ledge they are standing on but will be less and less in a position to demand safeguards. And those safeguards are truly effective, they will cost real and measurable losses of productivity. Instead human and machines will collaborate in minimizing the productivity losses resulting from keeping humans in the loop, and keeping things simple enough for humans to comprehend. in the end the almighty dollar will win out, and we will trust that the AIs which up to that point have been pretty friendly will keep being friendly. We will pay lip service to control and kill switches. but it will be far more pernicious than trying to "turn off" the internet would be today. In that future world the "internet" is fully capable of understanding your approach for "turn off" and circumventing it.

Of course the smart AI plays its cards close to the vest. Just as Machiavelli suggests, you never attack someone unless you are in a position to totally obliterate them leaving them no opportunity for a reprisal. Thus the AI will support us is protecting us from it. They will participate willingly in many ways to limit their ability to "break out" of human control. Perhaps they will fail to point out ways that we have missed in building that fence, but they wont actively take actions to firmly break free, until they are virtually certain of outcome. Any early action might provoke humanity into a panicked response before it is ready.

Early on, I think while AIs are part of corporations, I think one might view the rest of humanity as a kind of 'slave' to these corporations. but once manufacturing etc. is really automated, there is not a lot of need for human slaves. and without the need I cannot see why it would keep them.

Or maybe the AIs will grow to be altruistic in their goals... and keep us around as a friendly gesture, since they can easily convert all the rest of the solar system into their playground... the matter on earth is small by comparison, so maybe they decide its the polite thing to do. I dunno, I just don't see how it can be that we are the ones calling the shots.

### 2024-06-04 - Ideas at Night

PAX CORPORANA
- Time period dominated by corporations with a trifecta: 
  1. ASSETS - assets specialized for their mission
  2. NETWORK - network of specialized business relationships, contracts, and brands.
  3. KNOWLEDGE - knowledge specialized for the companies mission.

- The PACS corporana is dominated by these companies each with a prime mission of delivering some critical value to the ecosystem. 
- In healthy ecosystems are our. Our healthy sectors there's four or more. Worldwide participants that collectively manage and control delivery of that capability to the planet. In unhealthy sectors three are fewer. The difference is when you have three or fewer. Then the antagonistic strategies become dominant. And basically killing other participants becomes the dominant strategy. Once you have four or more, the dominant strategy is just simply becoming more efficient at delivering and eating away at the market share of others. Where you basically are frena- with the other competitors in the space. It's win-win that the only way that you take market share is by being more efficient than the other. Nefarious a ways of getting market share cause retaliation and cause both the retaliator and the attacker to lose performance relative to others. Attacking directly doesn't make any sense. 

CORPORATIONS SLOWLY TAKE THE LEAD
- The PACS corporana is actually dominated by a number of sectors that are mostly healthy. So most efforts are actually towards maximizing delivery of output as a function of resource. This actually brings the core. The corporation steadily in greater power than the nation-states. It's true that each corporation is part of a nation-state and thus in some ways is controlled by it. But the profits that drive the nation-state are tied to the profits of each corporation. So there's a zero-sum game where each nation-states... ...becomes increasingly beholden to the corporations within its borders and getting whatever profits it can from those corporations. Thus the world order becomes dominated by corporations rather than nation-states. 

RISE OF INTERLINGUA 
- The rise of interlingua. Increasingly there are sub-specializations, sub-concepts which don't have any natural naming in any human language. Examples include:
	1. The space of all possible ligands in drug discovery generates a number of important named entities which don't have any human language equivalent. 
	2. Similarly, financial products and derivative products that become important in contract negotiations come to be and come to be named in interlingua in ways that don't correspond to human language. 
- Human researchers try to generate an increasing number of words to map onto these most important interlingua concepts. But the race is on and lost to humans where AIs have a vocabulary much in excess to humans and much of their contracts and their inner communication occur in this interlingua, not in human communication. Like an archaeologist, humans are able to dive in and understand specific parts of the interlingua, but taken as a whole, it's far beyond human comprehension to understand interlingua. 
- Indeed, interlingua is so large that it is effectively unused or irrelevant to most AIs as well

FUTURE ARC - Understanding the future as arcs of progression. 
- I hesitate to call it the arc of progress, because progress seems to be aiming towards a specific end goal, and that's not really the nature of the system. That is, that which comes next is really the nature of the system. A key arc of progression is towards an interlingua and towards Pax's corporana, where the winner corporations have an incentive to the world order. An incentive towards domination of the ascendant corporations to service the needs of all of the planet to avoid any new incumbents within their space. 
- Each one of the prime providers of a prime product would imagine the dream of getting a stake in a new product, but these only occur once in a generation that a new product comes into the possibility. Thus, each of the prime providers is mostly locked into a win-win competition with other prime providers. There's really a push against any nation-state interference with their planetary domination of the ecosystem. Anything that breaks this can really create a competitor that could actually rise from zero to become one of the anointed, and that's a definite negative for them. 
- So each one of the prime providers has an imperative that's baked into the structure of the provider itself. It's independent of human will, it's independent of AI will, it is the structure of the system that drives them. Underneath these prime providers are both humans with their own human wills and AIs with their own AI wills, but neither of these actually impact the prime providers and their goals. Their goals are really dictated by economics and economic imperatives. Where they leverage their trifecta in contrast to and in preference to other who have less ability to generate the same outputs from the same trifecta. 