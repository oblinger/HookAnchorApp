.[[ABio]].
  [[Alien Biology]],
  ,
  , [[ABIO CellMetabolism5]], [[ABIO Photosynthesis]], [[ABIO Queries]], [[ABIO References]]
  , [[ABIO Systems]], [[ABIO Task Example]], [[ABIO Tasks]], 

  ,
  ,
  [[ABIO References]],
  , [[AB Queries]], [[ABsys]], [[Alien Biological Tasks]], 
  DELS: [[ABIO Tasks]], [[ABIO Task Example]], [[ABIO Queries]], [[ABIO Systems]], 



# TODO





# OUT TAKES


**Problem**: Because LLMs are constructed from such colossal training sets, it's hard to find tasks to assess their ability to perform truly novel reasoning as opposed to some sophisticated form copying from its training data.

**Problem**:  It is difficult to assess the learning/inference performance of LLMs over novel tasks since nearly any complex task we might use likely already has connections to texts used to train that model.  Perhaps all of its learning and inference are just sophisticated forms of copying.  How can we tell?


**Problem**: It's difficult to assess complex LLM reasoning since nearly any complex test task is tainted by likely but unknown relation to the texts used to train the LLM.

