.[[OpenAI]].
  , [OpenAI Note](spot://openainote), 

# Top
#### kind: Big
#### area: CoreDL
#### stance: 
## Sections
### Cash
#### cash: 
#### funding: 384.62
### Coolness
#### cool: 
#### cool_why: 
#### cool_mission: 
#### cool_balance: 
#### cool_dan: 
#### mission: To ensure that artificial general intelligence benefits all of humanity ￼.
### Deep Learning Projects (DLP)
#### dlp: 
#### dlproj1: 
GPT-4 (2023) – A large multimodal transformer with 175B+ parameters accepting text and image inputs, achieving human-level performance on many academic and professional benchmarks (e.g. top-10% on the bar exam) after extensive alignment tuning ￼
#### dlproj2: 
ChatGPT (2022) – An AI chatbot based on the GPT-3.5 series (InstructGPT), tuned for conversational dialogue. It can answer follow-up questions, admit mistakes, and reject improper requests, demonstrating the ability to carry out natural conversations and assist users ￼
#### dlproj3: 
GPT-3 (2020) – A 175 billion-parameter language model that revolutionized few-shot learning. Without task-specific training, GPT-3 could translate text, answer questions, and generate articles, often matching or beating state-of-the-art models fine-tuned on those tasks ￼ ￼
#### dlproj4: 
DALL·E 2 (2022) – A generative vision model that creates original images from natural language descriptions. It can blend concepts, styles, and attributes to produce realistic art from text prompts, significantly improving resolution and fidelity over the first DALL·E ￼
#### dlproj5: 
OpenAI Codex (2021) – A descendant of GPT-3 fine-tuned on billions of lines of code. Codex translates natural language to code in over a dozen programming languages, powering tools like GitHub Copilot. It enables a user to describe a task in English and get executable code as output ￼ ￼
#### dlproj6: 
CLIP (2021) – A multimodal model (Contrastive Language-Image Pretraining) that learned visual concepts from 400 million image–text pairs. CLIP can recognize and classify images in zero-shot fashion by ranking which text description fits an image, enabling flexible image recognition without traditional training data ￼ ￼
#### dlproj7: 
Whisper (2022) – An open-source automatic speech recognition model trained on 680k hours of multilingual audio. Its large-scale training made it robust to accents, background noise, and technical jargon, allowing transcription in multiple languages and even translation to English, approaching human-level accuracy in many cases ￼
#### dlproj8: 
OpenAI Five (2019) – A deep reinforcement learning project that trained five neural-network agents to play the complex esports game Dota 2. OpenAI Five became the first AI to defeat the reigning world champion Dota 2 team in live matches, marking a milestone in AI teamwork and long-horizon game strategy ￼
#### dlproj9: 
Jukebox (2020) – A generative model for music that produces songs with vocals in various genres. Given a genre, artist style, and lyrics, Jukebox generates new music as raw audio. OpenAI open-sourced Jukebox’s code and model weights, demonstrating AI-created music with recognizable singing and instrumentation ￼
### Job Postings
#### job: 
#### job_why: 
#### job_bay: 
#### job_remote: 
### Toxicity
## Misc Fields
#### bam:
#### dlp_:
### funding_justification: Raised ~$10B from Microsoft in Jan 2023 (~25 months ago); base=10000/26≈384.62
### proj1: GPT-4 (Large language model powering ChatGPT)
### justification: 
OpenAI is the highest-profile generative AI company, creator of ChatGPT and DALL-E, which have driven widespread adoption of AI-generated text and images [oai_citation_attribution:28‡eweek.com](https://www.eweek.com/artificial-intelligence/generative-ai-startups/#:~:text=generation%20and%20editing%2C%20audio%20transcription,tuning%20and%20embedding%20models)
### proj2: DALL-E 3 (Text-to-image generation model)
