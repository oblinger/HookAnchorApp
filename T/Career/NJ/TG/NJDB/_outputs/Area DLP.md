| name | score | job | cash | cool | dlp | dlproj1 | dlproj2 | dlproj3 | dlproj4 | mission |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 1.   [[Cerebras Systems]] | 143 | A | a+ | B | B ? | Open GPT models on Wafer-Scale – Cerebras trained and open-sourced seven GPT models (ranging from 111M to 13B parameters) for the research community ￼. All models were trained on Andromeda, Cerebras’s 16-wafer CS-2 supercomputer, demonstrating the scalability of wafer-scale AI and providing ready-to-use generative language models. | Wafer-scale 120T support – Designed a hardware-software architecture (MemoryX and Weight Streaming) that enables a single Cerebras CS-2 system to train models up to 120 trillion parameters ￼. This “brain-scale” AI capability means Cerebras can handle models 100× larger than GPT-3, by streaming model weights from external memory, pointing toward future generative models of unprecedented size ￼. | Andromeda AI supercomputer – Built the Andromeda AI supercluster with 13.5 million cores (16 CS-2 wafers). It achieved near-linear scaling on large language model training, e.g. efficiently training GPT-3 and GPT-NeoX models without the usual distributed-compute bottlenecks ￼. This enables faster experimentation and iteration in generative model research. |  | To revolutionize AI processing through innovative hardware solutions tailored for deep learning applications ￼. |
| 2.   [[Aisera]] | 139 | a- | b+ | B | B | Enterprise LLMs & SLMs – Aisera has developed enterprise-grade LLMs (including 25+ domain-specific large models for IT, HR, banking, etc.) and smaller task-specific language models. These models are pre-trained on relevant context and terminology, yielding more accurate, contextually relevant responses in enterprise assistant scenarios while operating at a fraction of the cost of generic LLMs ￼ ￼. | LLM Gateway – Aisera’s platform includes an AI Gateway that provides a unified interface to various foundation models (OpenAI, Azure, Meta LLaMA2, etc.), handling load balancing, response optimization, and security. This middleware allows organizations to “bring your own LLM” and dynamically deploy or switch models for their virtual assistants without dealing with each model’s API idiosyncrasies | AiseraGPT Copilot – a turnkey Generative AI solution (“where chatbots meet action bots”) that uses Aisera’s enterprise LLMs to not only converse with users in natural language but also execute actions via workflow automation. For example, AiseraGPT can understand a user’s request in context and trigger the appropriate IT or HR workflow (password reset, ticket creation, etc.), delivering end-to-end resolution in a conversational manner ￼ ￼. |  | Aisera aims to help organizations drastically reduce costs, unlock productivity with best-in-class business operations, and grow and scale revenue efficiently. |
| 3.   [[Mashgin]] | 139 | A- | b+ | B- | B+ | Creator of a touchless self-checkout kiosk that uses computer vision to identify items instantly. Customers simply place their purchases on the Mashgin tray, and the system’s AI recognizes each product (even multiple items at once) without needing barcodes or manual input ￼. | Uses a deep learning vision model that considers an item’s shape, size, color, texture, and even its gloss/reflectivity to identify it in any orientation. This multi-attribute recognition approach allows Mashgin to accurately distinguish thousands of products in diverse environments for real-time checkout ￼. | Continuously improves via data: the system can learn new items in seconds, and with over 800 million transactions processed, its algorithms have become highly reliable. Mashgin’s AI gets more accurate with each use, making it increasingly adept at recognizing an ever-growing catalog of products in the field ￼. |  | We aim to make a frictionless checkout experience for all using advanced computer vision￼. |
| 4.   [[Abnormal Security]] | 137 | c- | a+ | B | B+ | Behavioral AI email security platform: Abnormal uses AI to model “known-good” communication behavior for each user and vendor, then applies deep learning/NLP to detect anomalies in emails (e.g., BEC or phishing) that deviate from normal patterns ￼. | CheckGPT generative attack detection: Tool that employs large language models to determine if a suspicious email was likely written by generative AI (e.g., ChatGPT), helping identify AI-crafted phishing and BEC attacks ￼ ￼. | AI Security Mailbox for phishing reports: Autonomous triage system that uses AI to inspect and categorize user-reported emails as malicious, spam, or safe (including automated feedback to reporters), thus offloading and speeding up SOC email workflows ￼. |  | To protect people from cybercrime by harnessing the power of AI ￼. |
| 5.   [[6sense]] | 37 | a- | B+ | C+ | B | Conversational Email + AI Writer – an AI-powered email outreach product that turns marketing emails into two-way conversations. Launched in 2022 and enhanced in 2023 with generative AI, it uses GPT-4 (combined with 6sense’s intent data and predictive analytics) to automatically draft highly personalized emails and even manage the replies. The AI Writer generates custom email text aimed at eliciting responses, and the system’s “auto-replies” feature uses an AI agent to continue the thread or hand off to sales at the right time. | AI Email Writer for Sales – a generative feature inside 6sense Sales Intelligence that helps sales reps compose one-to-one emails. It pulls in information about the target account (from CRM records and 6sense’s people & intent data) and, via generative AI, produces a tailored outreach email. This saves reps time in crafting pitches and ensures messages are informed by all available data on the prospect. | Pipeline Intelligence – 6sense’s platform, branded “Revenue AI,” applies machine learning to identify high-potential accounts and recommend next-best actions. Recent AI advancements include Model Lifecycle Management, which continuously retrains the predictive models on new data to maintain accuracy ￼. Combining generative AI for engagement and predictive AI for targeting, 6sense aims to automate large parts of the B2B sales pipeline.. |  | 6sense is on a mission to revolutionize the way B2B organizations create revenue by predicting customers most likely to buy and recommending the best course of action to engage buying teams ￼. |
| 6.   [[Chroma]] | 37 | a+ | b | C+ | B- | Chroma Vector DB – an open-source AI-native vector database for embeddings that serves as “memory” for LLM applications, enabling semantic search and retrieval-augmented generation with ease of use and scale ￼ ￼. | Chroma Cloud – a forthcoming fully serverless, elastic cloud platform for Chroma, allowing developers to access vector search capabilities via a simple API with automatic scaling ￼ ￼. | Ecosystem Integrations – deep integration of Chroma with AI dev tools (e.g. LangChain and even a .NET SDK by Microsoft) to accelerate GenAI app development by storing and querying domain-specific context embeddings ￼ ￼. |  | Chroma develops an open-source vector database designed to power artificial intelligence applications ￼. |
| 7.   [[Covariant]] | 34 | D | b+ | A- | B+ | Covariant Brain (Universal AI) – The Covariant Brain is a universal AI robotics platform that enables robots to learn new tasks and handle novel objects through deep reinforcement learning. It was tested in the ABB order-picking challenge, where a Covariant robot system, without task-specific programming, won by successfully picking a wide variety of unseen items ￼. The Brain’s neural network policies are trained on millions of grasp attempts, giving Covariant-powered robots the ability to generalize – e.g., a warehouse robot can pick up arbitrary products it’s never encountered before, achieving automation in e-commerce fulfillment that was previously impractical. | RFM-1 (Robotics Foundation Model) – Covariant’s Robotics Foundation Model 1 is a large-scale multimodal AI model designed for robotics ￼. It’s trained not only on internet-scale data (text and images, for broad semantic understanding) but also on an enormous dataset of real-world robotic interactions collected by Covariant over years ￼. RFM-1 gives robots a form of common sense about the physical world – for instance, understanding concepts of support, gravity, and object properties – which improves their reasoning and decision-making in new scenarios. Covariant reports that RFM-1 is the first foundation model deployed in hundreds of physical robots, where it powers capabilities like dynamic grasping and tool use in factories. | AI-Driven Robotic Picking Deployments – Covariant has partnered with logistics automation companies (e.g. KNAPP) to deploy AI-powered picking robots in live production. One example is at McKesson, a major pharmaceutical distributor, which installed Covariant’s AI on KNAPP “Pick-it-Easy” robotic stations to handle pharmacy items. The Covariant-enabled robots can reliably pick and sort thousands of different products (from pill bottles to odd-shaped packages) with high precision, 24/7 ￼. These deployments, numbering in the hundreds of robots across retailers and 3PLs, demonstrate Covariant’s applied AI achieving less than <0.1% error rates and significant throughput gains in real warehouses ￼, validating the real-world performance of their deep learning robotics. |  | To build the Covariant Brain, a universal AI giving robots the ability to see, reason, and act on the world around them ￼. |
| 8.   [[Cresta]] | 34 | c+ | a+ | C+ | C+ | Real-Time Intelligence Platform – Cresta’s core AI system that leverages the latest conversational AI and large language model research to assist contact center agents with real-time coaching and insights ￼. | AI Analyst – a generative AI tool that lets business leaders query customer conversation data in natural language and get answers with clear explanations and links to supporting evidence ￼. | Custom Conversation Summarization – Cresta developed AI models to automatically summarize customer interactions in a style tailored to each business, ensuring up-to-date, accurate call notes and saving agents time on after-call paperwork ￼. |  | To enable everyone to be 100× as effective at work ￼. |
| 9.   [[Adept]] | 33 | f | a+ | B+ | B+ | ACT-1 (Action Transformer) – Adept’s first large model that can take actions on a computer. ACT-1 is a transformer trained to use digital tools via a browser – it observes a rendered webpage and can click, type, and scroll to execute tasks ￼. This is a step toward a general AI assistant that can do anything a human can do on a PC ￼. [oai_citation_attribution:5‡adept.ai](https://www.adept.ai/blog/act-1#:~:text=Capability%20preview) | AI Assistant Overlay – Adept built a prototype interface for ACT-1 as a Chrome extension overlaying existing software. A user can simply type a command (in natural language), and ACT-1 will carry out the multi-step process autonomously ￼ ￼. For example, ACT-1 can take a high-level instruction like “Import LinkedIn contacts into Salesforce” and perform all the clicks and data entry across both apps to complete it ￼.<br>Natural Language Tool Interface – Adept’s models let users control existing software with language; Adept has worked with enterprises to build AI that uses apps like Adobe Photoshop or Airtable via natural language, automating workflows and boosting productivity [oai_citation_attribution:6‡reuters.com](https://www.reuters.com/technology/adept-raises-350-mln-series-b-funding-2023-03-14/#:~:text=Founded%20by%20former%20Google%20researchers%2C,opens%20new%20tab%20and%20Airtable) | Multi-App Tool Use – ACT-1 demonstrated the ability to coordinate actions across multiple applications and websites. It can compose different tools to achieve a goal (e.g. researching info online, then updating a spreadsheet) all in one workflow ￼. Adept’s research vision is a generalist AI agent that learns to use “every software tool, API, and webapp that exists,” extending automation to virtually any digital task ￼.<br>Amazon-Adept Collaboration – in 2024 Amazon hired Adept’s CEO and researchers and licensed the startup’s technology, a strategic deal to incorporate Adept’s action-taking AI into Amazon’s own AI efforts (now under FTC review) [oai_citation_attribution:7‡reuters.com](https://www.reuters.com/technology/ftc-seeking-details-amazon-deal-with-ai-startup-adept-source-says-2024-07-16/#:~:text=The%20informal%20inquiry%20into%20Amazon%2C,some%20of%20the%20startup%27s%20technology) |  | To unlock human potential and creativity at scale by developing capable AI systems... |
| 10.   [[Genesis Therapeutics]] | 33 | f | a+ | B+ | B+ | Graph neural networks for drug discovery: Multi-target collaboration with Genentech using Genesis’s AI platform (originating from PotentialNet GCNs) to find innovative drug candidates for hard-to-drug targets ￼. | GEMS generative AI platform: Genesis Exploration of Molecular Space (GEMS) integrates language models, diffusion models, and physics-based ML to generate and optimize novel small molecules for complex protein targets ￼. | NVIDIA partnership on equivariant models: Collaboration with NVIDIA to accelerate Genesis’s AI by optimizing 3D geometry–aware neural networks, advancing generative and predictive models for structure-based design ￼ ￼. |  | To pioneer the use of AI to transform drug discovery and development, accelerating the creation of breakthrough medicines ￼. |
| 11.   [[Freenome]] | 32 | f | a+ | B+ | B | AI genomics platform for early cancer detection: Using machine learning on multiomics (e.g., cfDNA) to detect colorectal cancer at its earliest stages ￼. | Multi-cancer screening (Sanderson Study): Combining multiomics with real-world data to improve and validate a blood test that detects multiple cancers using AI ￼. | AI-driven immunotherapy response prediction: Collaboration with Institut Curie to use ML on cell-free DNA biomarkers to predict patient response to immuno-oncology treatments ￼. |  | To create tools that empower everyone to prevent, detect, and treat their disease ￼. |
| 12.   [[Insitro]] | 31 | f | a+ | B | B | Machine learning for NASH drug discovery: Collaboration with Gilead using insitro’s ML-driven platform (ISH) to create in vitro disease models and identify therapeutic targets for NASH ￼. | AI-driven neuroscience (ALS/FTD): Five-year partnership with Bristol Myers Squibb applying insitro’s platform to iPSC-derived models for ALS and FTD, to discover novel targets and design ML-based therapeutics ￼. | Metabolic disease collaboration: Multi-agreement partnership with Eli Lilly leveraging insitro’s AI platform to identify targets for metabolic disorders (e.g., MASLD) and develop siRNA and antibody therapies ￼. |  | To bring better drugs to patients faster by leveraging machine learning and data at scale to decode the complexities of biology and unlock transformative new medicines ￼. |
| 13.   [[Skydio]] | 31 | f | a+ | B | B | Deep neural drone pilot – Created a learned drone control policy using imitation learning (with the Skydio Autonomy Engine as the expert). This CEILing approach trains a neural network pilot that can autonomously fly and film while avoiding obstacles, imitating the expert’s intent rather than exact path￼. | Autonomy engine (360° vision) – Skydio’s drone uses six 4K navigation cameras to build a real-time 3D model of its surroundings (over 1M pts/sec) and runs up to nine deep neural networks to predict motion and avoid obstacles ￼. | 3D Scan adaptive mapping – Developed Skydio 3D Scan, an AI-driven scanning software that autonomously pilots the drone to generate high-resolution 3D models of structures with full coverage, revolutionizing inspection and mapping ￼. |  | To empower people to capture the world from above and unlock new perspectives through autonomous drone technology ￼. |
| 14.   [[Deepcell]] | 29 | f | b+ | B+ | B ? | Human Foundation Model & Morphology Atlas: Deepcell’s foundation AI model trained on millions of cell images enables label-free classification of single cells by morphology; used to build a “Deep Cell Atlas” with over 1 billion cell images ￼ ￼. | REM-I platform for morpholomics: AI-powered benchtop system (launched 2023) combining imaging, microfluidics, and deep learning (Human Foundation Model) to analyze and sort single cells based on high-dimensional morphology features ￼. | Tabula Sapiens cell atlas project: Collaboration with Stanford (Chan Zuckerberg Biohub) to generate and publicly share single-cell morphology data for a human cell atlas of 2 million cells, using Deepcell’s AI platform to identify cell types via morphology ￼ ￼. |  | Deepcell is pioneering new methods in single-cell analysis by combining innovations in microfluidics, optics, and AI ￼. |
| 15.   [[Glean]] | 29 | f | a+ | B- | B- | Glean Chat Search – Glean’s Work AI platform includes an enterprise chat-based search assistant ￼. Employees can ask it questions like, “How do I access our VPN?” or “Summarize Project X design decisions,” and Glean will search across all company apps (Google Drive, Slack, Confluence, emails, etc.). Using LLMs with retrieval, it returns a direct answer or summary with citations and links to the source documents ￼. This generative Q&A approach saves time by providing users the exact info they need from their company’s knowledge, instead of a list of files to dig through. | Trusted Knowledge Fine-Tuning – To ensure accuracy and security, Glean uses a Trusted Knowledge Model approach. It continuously indexes enterprise data and fine-tunes its deep learning models on each organization’s content and graph (relationships between people, files, topics) ￼ ￼. The result is that Glean’s generative AI answers are contextually personalized (aware of the user’s role, team, and past activity) and always respect permissions (the AI won’t reveal info a user isn’t allowed to see) ￼ ￼. This applied research in grounding LLMs with company-specific training makes Glean’s answers uniquely relevant and trustworthy for each enterprise. | Retrieval-Augmented Generation – Glean’s search utilizes retrieval-augmented generation, meaning it combines vector semantic search with generative AI. When a question is asked, Glean first retrieves relevant document snippets, then its LLM composes an answer using those snippets as context ￼. Every answer it generates is accompanied by citations back to the original content to assure verifiability ￼. By using this grounded generation approach, Glean minimizes hallucinations and ensures the AI stays “in sync” with the company’s actual knowledge. (This strategy has positioned Glean as a leading example of trusted GenAI in enterprise search ￼.) |  | To expand human potential to do extraordinary work ￼. |
| 16.   [[Runway]] | 29 | f | a+ | B- | B- | Stable Diffusion – an open-source text-to-image model co-developed by Runway (providing foundational research) in collaboration with Stability AI, enabling anyone to generate images from text ￼. | Gen-1 – Runway’s video-to-video generative model that applies the style or composition of an image/text prompt to the structure of a source video, “like filming something new, without filming anything at all” ￼. | Gen-2 – Runway’s multimodal text-to-video system that generates novel videos using text, images, or video clips, achieving photorealistic results and marking a breakthrough in AI-driven video creation ￼. |  | To help tell the best stories ￼. |
| 17.   [[Synthesia]] | 29 | f | a+ | B- | B- | AI Video Platform – Synthesia’s studio allows users to turn written scripts into videos with photorealistic AI avatars speaking in 120+ languages, used for corporate training and content creation ￼ ￼. | Beckham “Malaria Must Die” Video – a 2019 awareness campaign where Synthesia’s tech made David Beckham appear to speak 9 languages in one video, by swapping his mouth movements and voice with AI – an example of using generative AI for social impact ￼. | Expressive Avatars – a 2024 update unveiled a new range of AI-generated video avatars that convey human emotions (happiness, sadness, frustration) through prompts, eliminating the need for actors or filming ￼. |  | To empower everyone to make video content – without cameras, microphones, or studios ￼. |
| 18.   [[Uniphore]] | 29 | f | a+ | B- | B- | X-Stream (Knowledge-as-a-Service) – Uniphore’s new platform for enterprise Knowledge AI. X-Stream transforms raw enterprise data (from various sources) into AI-ready knowledge and offers native support for Retrieval-Augmented Generation workflows. It provides the tools, connectors, and governance needed to build domain-specific generative AI applications (like conversational assistants or analytics) on one unified platform, accelerating the move from AI POCs to production ￼ ￼. | U-Analyze (Generative Edition) – an enhanced version of Uniphore’s interaction analytics solution powered by LLMs. This upgrade uses generative AI to synthesize insights from multimodal customer conversation data (voice, text, video). It can automatically summarize call topics, extract customer sentiment and intent, and even generate coaching notes for agents, enabling contact center leaders to monitor and improve performance with unprecedented ease ￼ ￼. | Q for Sales – an AI-driven conversational intelligence tool for sales teams that analyzes emotional cues in virtual meetings. Q for Sales uses computer vision (facial expressions), tonal analysis (voice intonation), ASR, and NLP to gauge buyer sentiment and engagement in real time, giving sales reps live feedback and recommendations. By capturing the full emotional spectrum of sales calls and delivering real-time “EQ” insights, Q for Sales helps remote sellers build trust and close deals more effectively ￼ ￼. |  | To give each customer a voice ￼. |
| 19.   [[Moveworks]] | 27 | f | b | B | B | Moveworks Copilot (Agentic AI) – a generative AI assistant for enterprise employees that uses a blend of LLMs (including GPT-4/Turbo, Mistral, etc.) and Moveworks’ proprietary MoveLM to securely answer questions and perform tasks across corporate systems via chat (integrated into tools like Slack/Teams) ￼ ￼. | Quick GPT – a new Moveworks feature allowing users to intentionally invoke ChatGPT-like capabilities within the Moveworks Assistant in a safe, IT-approved way. Quick GPT uses OpenAI’s GPT-4 (notated “GPT-4o”) behind the scenes to generate responses or content on demand, while respecting enterprise data security and compliance ￼ ￼. | Agentic Reasoning Engine – Moveworks’ system for complex workflow automation, which leverages GPT-4o for multi-step reasoning and planning. It breaks down user requests and autonomously invokes tools (plugins) to execute actions (e.g. resetting passwords, pulling reports), effectively serving as an agent that completes tasks across apps using natural language commands ￼ ￼. |  | Enabling enterprises to empower their workforce with an easy-to-use AI solution that instantly finds answers, automates tasks end-to-end, and boosts productivity ￼. |
| 20.   [[Vectara]] | 27 | f | b+ | B- | B | Grounded Conversational Search – Vectara’s neural “search-as-a-service” platform delivers answer-focused search results. Instead of only returning a list of documents, Vectara uses generative AI to produce a direct answer synthesized from relevant text, and crucially, it grounds each answer with source citations ￼ ￼. For example, a user asks a complex question on a knowledge base – Vectara will retrieve the top passages and then its LLM generates a unified answer (with footnotes linking back to those passages). This reduces user effort and gives confidence in the answer’s accuracy by showing exactly where information came from (addressing AI hallucination concerns). | Zero-Shot Learning Engine – Vectara’s system employs a form of continuous zero-shot learning for enterprise data. As new documents are added to a customer’s index, the AI can immediately incorporate that knowledge when answering queries, without needing to re-train a model offline ￼. Vectara’s architecture streams new data into the vector index in seconds, so if an employee uploads a file or an FAQ is updated, any subsequent question will “know” about it. This enables truly real-time, up-to-date generative responses (a stark contrast to typical LLM deployments that rely on fixed training data). | “Boomerang” Retrieval Model – An applied research achievement by Vectara is its Boomerang model – a state-of-the-art multilingual retrieval model integrated into its platform ￼. Boomerang is trained to produce high-quality semantic embeddings for text in many languages, improving search relevance across diverse content. In Vectara’s pipeline, better retrieval means the generative answer gets the best possible context to work from ￼. Internal benchmarks showed Boomerang outperforming other embedding models on recall and precision, which translates to more accurate answers in generative search. (This focus on strong dual encoder models is part of Vectara’s “Neural Search” DNA and a key differentiator of their GenAI service.) |  | To help the world find meaning through technology ￼. |
| 21.   [[Weights & Biases]] | 27 | f | b+ | B- | B | OpenAI Fine-Tuning Integration – W&B developed a logger and dashboard integration for OpenAI’s fine-tuning API, allowing teams to automatically track experiments when fine-tuning GPT-3.5 or GPT-4 models (metrics, parameters, and datasets) with just a few lines of code ￼. | Azure + W&B for LLMs – W&B partnered with Microsoft to enable enterprise fine-tuning of large language models on Azure. This collaboration lets Azure OpenAI Service users use W&B to monitor training runs and analyze model performance, simplifying the adaptation of GPT-4-family models to proprietary data ￼ ￼. | Generative AI Evaluation – W&B has been at the forefront of generative AI research support, providing tools to evaluate and visualize LLM outputs. For example, W&B’s team has hosted conversations with leaders like Stability AI’s Emad Mostaque on model advances ￼ and built instrumentation to compare LLMs’ performance on tasks, helping researchers identify strengths and weaknesses in different models. |  | To build the best tools for AI developers ￼. |
| 22.   [[Pinecone]] | 26 | f | a+ | C+ | C | RAG at Scale Research – Pinecone’s study demonstrating that Retrieval-Augmented Generation over billions of documents significantly improves LLM accuracy and reduces hallucinations ￼ ￼. | Pinecone Rerank Model – a neural reranking model (pinecone-rerank-v0) to boost relevance in enterprise search and RAG pipelines, delivering more precise, grounded LLM responses ￼ ￼. | Serverless Vector DB for GenAI – Pinecone’s fully managed serverless vector database launched to support real-time, scalable retrieval for generative AI applications, improving accuracy and reducing costs ￼ ￼. |  | To make AI knowledgeable ￼ (by providing long-term “memory” via vector database). |
| 23.   [[Groq]] | 25 | f | a+ | C | C | .-.Groq LPU inference engine – Developed a new AI chip architecture (Tensor Streaming Processor) and the Groq Language Processing Unit, specialized for ultra-fast, batch-free inference on large models. In independent benchmarks, Groq’s system achieved state-of-the-art latency and throughput on GPT-size model inference, outperforming other cloud AI platforms  . | ...Scaling inference with Saudi partnership – Secured a $1.5 billion investment from Saudi Arabia to expand Groq’s generative AI inference infrastructure  . This will deploy Groq hardware at scale for real-time AI services, demonstrating confidence in Groq’s ability to accelerate nation-wide GPT and GenAI applications. | LLMOps platform (Groq Orq) – Introduced an end-to-end platform for Large Language Model Ops: Groq’s software (like Orq.ai) helps enterprises build, deploy, and scale generative AI applications on Groq hardware ￼. It streamlines fine-tuning and serving of LLMs (e.g. GPT-3, chatbots) with tools for versioning, testing, and cost management, leveraging Groq’s fast inference to support responsive GenAI services. |  | To build the world’s fastest AI inference technology, enabling efficient, cost-effective, and accessible adoption of AI and ML across industries ￼. |
| 24.   [[Rasa]] | 25 | f | b+ | C+ | B- | DIET NLU Model – Rasa’s Dual Intent and Entity Transformer is a multitask deep learning model for natural language understanding. DIET uses a transformer architecture to jointly predict user intents and extract entities, achieving state-of-the-art accuracy with less training data and compute than large pretrained language models ￼. It’s open-source and powers Rasa’s NLU, enabling developers to build chatbots that understand user messages with high accuracy while being efficient to train. | Intentless Dialogue Policy – Rasa introduced an intentless conversational model that leverages large language models to manage dialogue without hand-crafted intents ￼. Implemented as the IntentlessPolicy in Rasa, it uses an LLM to interpret off-script user input and decide the next action when no predefined rule applies. Crucially, the system is designed to avoid wild LLM generation – it only chooses from valid actions and known responses, preventing hallucinations ￼. This approach makes Rasa assistants more flexible (able to handle unexpected user requests) while maintaining reliability by integrating with Rasa’s rule-based dialogue framework. | LLM-Based User Simulators – A Rasa research initiative using generative models to create simulated users for testing chatbot conversations. By prompting an LLM to behave like a user with various goals, Rasa can generate entire conversation trajectories to stress-test dialogue policies ￼. These simulators produce varied phrasing and dialogue turns (beyond the happy paths developers anticipate) ￼, helping uncover bugs or weaknesses in the assistant. This applied research accelerates development – bots can be tested against hundreds of simulated scenarios overnight, improving robustness before real users ever interact with them. |  | To revolutionize how humans interact with technology by enabling businesses and developers to create context-aware, personalized, and efficient AI assistants that enhance user experiences ￼. |
| 25.   [[Arize AI]] | 22 | a | b- |  |  | Arize Phoenix – an open-source observability and evaluation tool for LLMs that uses embeddings and LLM-as-a-metric to trace and visualize model decisions, helping developers identify hallucinations or errors in chatbot outputs and debug them interactively. | LLM-as-a-Judge – Arize’s approach (and tooling) for using one LLM to evaluate another’s responses on dimensions like factuality, relevance, or safety, enabling automated quality evaluation for agents and RAG systems without ground-truth answers ￼ ￼. | Arize AX (GenAI) – a unified platform for end-to-end LLM app development and monitoring, which provides tracing of agent decision steps, prompt management, dataset slicing, and evaluation dashboards so enterprises can rapidly iterate and safely deploy generative AI agents ￼ ￼. |  | To give teams the tools they need to understand, troubleshoot, and improve AI performance in the real world ￼. |
| 26.   [[Hive AI]] | 22 | f | b+ | C | C | Automated content moderation – Deployed deep learning models at scale for content moderation, achieving human-level accuracy in detecting NSFW imagery, violence, hate symbols, etc., with continual model improvements ￼. | AI-generated content detection – Offers an API to identify AI-generated media. Hive’s AI-Generated Media Recognition service can analyze images or text and determine if content was machine-produced (deepfakes, AI art) with a single API call ￼. | Generative content APIs – Launched cloud APIs for generative AI, including image generation (using models like Stable Diffusion XL and Hive’s own “Flux Schnell”) and even text-to-video generation, allowing developers to create images or videos from text prompts ￼ ￼. |  | Provides cloud-based AI solutions for content understanding, search, and generation ￼. |
| 27.   [[LangChain]] | 21 | f | b+ |  | B+ | LangChain Framework – an open-source toolkit that lets developers chain together LLMs with external data sources and tools to build context-aware generative AI applications ￼. It provides abstractions for prompts, memory, and integration with APIs, simplifying the development of complex AI workflows. | LangChain Hub – a community hub for sharing and discovering prompts, chains, and agents. Launched in 2023, it allows developers to upload and reuse effective prompt workflows and chain configurations, accelerating development of LLM applications ￼. | LangSmith – a unified platform for debugging, testing, and monitoring LLM apps built with LangChain. LangSmith (introduced 2023) provides tools to trace chain executions, evaluate output quality, and catch errors, helping move LLM applications from prototype to production reliably ￼. |  | To make it easy to build the LLM apps of tomorrow, today ￼. |
| 28.   [[Atomwise]] | 18 | a- | c- |  |  | AtomNet deep learning platform: Pioneering CNN model for structure-based drug design that screens an enormous chemical space (>3 trillion compounds) to predict bioactivity and discover novel small molecules ￼ ￼. | AIMS program (318-target study): Atomwise’s AI Molecular Screening initiative applied AtomNet across 318 diverse protein targets, yielding hits in ~235 cases and first-in-class binders for previously intractable proteins ￼ ￼. | Sanofi multi-target deal (2022): $1.2B collaboration where Atomwise uses its AI platform to identify and optimize lead compounds for up to five drug targets, demonstrating AI’s impact on pharmaceutical R&D ￼ ￼. |  | To create better medicines faster by harnessing the power of deep learning for drug discovery ￼. |
| 29.   [[Dataiku]] | 18 | a- | c- |  |  | GPT-4 Integration in Dataiku 12 – Dataiku’s AI platform (version 12, released mid-2023) added native integration of OpenAI’s GPT-4. This lets users incorporate generative text capabilities (like summarization or content generation) into data workflows while Dataiku provides guardrails (transparency, governance and responsible AI checks) around the use of these models ￼ ￼. | Dataiku Answers – an enterprise Q&A chatbot builder introduced in 2024. It uses Retrieval Augmented Generation (RAG): teams can select an LLM and plug in their own knowledge base so that the chatbot responds with company-specific information. Dataiku Answers enables organizations to deploy internal chatbots that employees can query for insights, with the accuracy of answers ensured by grounding responses in proprietary data ￼ ￼. | LLM Mesh – Dataiku’s architecture for connecting to and managing large language models. LLM Mesh allows Dataiku to route requests to various LLM providers (OpenAI, Anthropic, Azure, etc.) or even self-hosted models, and integrates a vector store for retrieval. It includes controls like PII filtering and response moderation, giving enterprises a unified and safe way to leverage generative AI across different model APIs ￼. |  | To democratize data science and create human-centric enterprise AI solutions that power the future of business ￼. |
| 30.   [[Mythic AI]] | 18 | a- | c- |  |  | Built an analog compute-in-memory AI chip (Mythic AMP) that stores neural network weights in flash memory cells, enabling up to 25 trillion operations per second on-chip with minimal power. This innovative analog architecture eliminates external memory bottlenecks for AI inference ￼. | Demonstrated the chip on popular deep learning models – e.g. running object detection and vision DNNs like YOLOv3/YOLOv5, ResNet-50, or OpenPose on-device – showing high-performance computer vision inference with far lower power use than digital processors ￼. | Exploring analog hardware for large models: Mythic’s in-memory analog computing removes memory bandwidth limits, a natural fit for bandwidth-hungry tasks like large language models. The company envisions bringing LLM-scale AI to the edge by leveraging analog matrix ops to handle massive model parameters efficiently ￼. |  | Mythic’s vision is to make it much easier and more affordable to deploy powerful artificial intelligence everywhere ￼. |
| 31.   [[Standard AI]] | 18 | a- | c- |  |  | Developed an autonomous checkout platform using ceiling-mounted cameras and deep learning to let customers shop and leave without stopping to pay. Their system matches products to shoppers (even if items are pocketed or returned to the shelf) with no scanning or checkout lines, as shown in Standard Market (a cashierless store demo) ￼. | Expanded the technology into computer vision retail analytics. The Standard Vision system uses AI cameras to capture shopper behavior and product interactions in-store, providing retailers with insights like foot traffic patterns, shelf engagement, conversion rates, and other operational metrics in real-time ￼. | Built an AI-powered loss prevention tool that analyzes video for shoplifting – the system’s algorithms flag likely theft events and compile video clips of those incidents for review. This automated monitoring lets staff focus only on credible theft alerts, improving security efficiency ￼. |  | Bringing the power of AI to physical retail. We provide unprecedented precision insights into shopper behavior, product performance, and store operations ￼. |
| 32.   [[Anyscale]] | 16 | a+ | ? |  |  |  |  |  |  | To ease the building and scaling of AI/ML and Python workloads, as well as AI applications ￼. |
| 33.   [[Sift]] | 15 | c- | b- |  |  | Developed a deep learning sequence model (using RNNs) to detect fraudulent user behavior patterns in real time, augmenting their fraud scoring system with temporal activity analysis ￼. | Introduced an Account Takeover Prevention solution that uses ML-driven behavioral analysis and device fingerprinting to identify and block unauthorized account access attempts in real time ￼. | Applies its ML platform to other abuse types as well – for example, spotting fake content and scam accounts – helping clients (e.g. Airbnb) keep user-generated content and interactions trustworthy ￼. |  | Sift’s mission is to help everyone trust the internet￼. |
| 34.   [[Inworld AI]] | 12 | f | b+ |  |  | Character Engine – Inworld’s core platform for creating generative NPCs whose personalities, memories, and behaviors are driven by AI. Developers can design virtual characters that carry on open-ended conversations and react dynamically, going beyond scripted dialog trees ￼. | Xbox Partnership – a multi-year collaboration with Microsoft to build AI tools for game development, harnessing generative AI for dialogue and narrative. Inworld’s tech will help studios generate interactive character dialog and quests at scale, as announced with Xbox’s Gaming AI division ￼ ￼. | “Neo NPC” Project – a partnership with Ubisoft and NVIDIA showcasing AI-powered game characters (“Neo NPCs”) that can speak directly with players. This demo (revealed in 2024) used Inworld’s conversational AI and Nvidia’s Audio2Face to enable realistic, unscripted NPC interactions in future games ￼. |  | Our mission is to create and inspire new meaningful relationships ￼. |
| 35.   [[Kodiak Robotics]] | 12 | f | b+ |  |  | AI sensor fusion & mapping – Developed a modular autonomy system (“Kodiak Driver”) that uses deep learning for multi-sensor (camera, LiDAR, radar) fusion and a lightweight mapping approach, allowing autonomous trucks to handle ever-changing highways (e.g. construction zones) without HD maps ￼. | Deep vision for trucking – Applied state-of-the-art deep neural networks to lane detection, object and traffic-sign recognition, and 3D perception on highways, enabling reliable long-haul truck autonomy ￼. | Automated AI training pipeline – Built an “AI flywheel” data pipeline that integrates advanced pre-labeling of sensor data with human annotation tools, automating training data generation and continuously improving Kodiak’s driving models ￼. |  | To revolutionize the long-haul trucking industry through the development and implementation of cutting-edge autonomous technology ￼. |
| 36.   [[Deepgram]] | 10 | f | b- |  |  | Nova-3 Multilingual STT – Deepgram’s state-of-the-art speech-to-text model offering best-in-class transcription accuracy on challenging audio. Nova-3 performs real-time transcription across 10 languages (even within a single conversation), an industry-first capability achieved by training on massive synthetic code-switched data and real-world speech, enabling seamless multilingual recognition without separate models ￼ ￼. | End‑to‑End Speech-to-Speech Model – An experimental generative speech system from Deepgram that converts input speech directly to output speech in another language or form without converting to text in between. This speech-to-speech (STS) model preserves nuances like tone and emotion and is a major step toward fluid, human-like voice assistants. (Deepgram announced in 2025 that their model achieved this direct speech generation, paving the way for more natural real-time voice translation and responsiveness) ￼ ￼. | Genesys Integration – A collaboration between Deepgram and Genesys to power next-gen contact center AI. Deepgram’s deep learning ASR was integrated into Genesys Cloud, enabling generative AI features like voicebot IVR, live agent assist, auto-diarized transcripts and call summarization ￼. This partnership allows enterprise users to benefit from Deepgram’s fast, accurate speech recognition as part of an end-to-end AI customer service solution, improving automation and analytics in call centers. |  | To understand human language by enabling developers with the most advanced speech AI transcription and understanding capabilities ￼. |
| 37.   [[Domino Data Lab]] | 10 | f | b- |  |  | Domino AI Gateway – a new capability that serves as a unified gateway for large language model APIs (OpenAI, Anthropic, etc.), giving enterprise teams a secure, governed way to invoke LLMs (holding API keys, controlling access per user, and tracking token usage) while allowing easy switching of model backends without code changes ￼ ￼. | Vector DB Integration – Domino’s platform added native connectors for vector databases (e.g. Pinecone, Qdrant) to support Retrieval-Augmented Generation workflows; this lets users seamlessly store embeddings of enterprise data and feed relevant contexts to LLMs for more reliable answers in apps like enterprise Q&A chatbots ￼ ￼. | AI Project Hub Templates – Domino’s AI Hub provides pre-built generative AI reference projects and templates (chatbots, summarization tools, LLM fine-tuning examples like LLaMA-2 and Falcon, etc.) using its Contextual AI platform, so enterprises can jumpstart GenAI use cases with best practices and minimal setup ￼ ￼. |  | To unleash AI’s power to solve complex problems ￼. |
| 38.   [[Fiddler AI]] | 10 | f | b- |  |  | LLM Observability Platform – Fiddler’s enterprise AI observability solution now supports large language models, allowing organizations to monitor LLM-driven applications for data drift, quality issues, and bias, and to explain and audit LLM outputs across use cases ￼ ￼. | Fiddler Trust Models & Enrichments – a proprietary framework of task-specific models fine-tuned by Fiddler to evaluate LLM outputs in real time (scoring for hallucinations, toxicity, PII leakage, etc.), enabling “guardrails” that detect unsafe or incorrect responses within milliseconds ￼ ￼. | Guardrails & Safety – Fiddler’s platform provides an LLM Gateway and Trust Service that let enterprises dynamically route prompts through approved models and inject safety checks; e.g. it can intercept prompt-injection attacks or policy violations using fast trust scores before an LLM response reaches the end-user ￼ ￼. |  | To build trust into AI ￼. |
| 39.   [[Findem]] | 10 | f | b- |  |  | Attribute-Based Talent Cloud – Findem’s platform creates a rich “attribute” profile for each person by mining myriad data sources. For example, it might generate attributes like “experience scaling a team from 10→50” or “expert in AWS security” from a candidate’s history ￼. These AI-generated attributes go far beyond standard resume fields, enabling extremely targeted talent searches. This applied AI (which uses deep learning NLP to parse text and infer qualities) means recruiters can search on real-world criteria – e.g. “software engineers who have worked at fintech startups and led cloud migration” – and Findem will find matching candidates even if those exact words aren’t on their resume ￼. | Conversational Talent Assistant – Findem integrated Generative AI (ChatGPT) into its Talent Data Cloud, allowing recruiters to ask questions in natural language and get instant answers from Findem’s data ￼. A recruiter can literally type a query like, “Show me senior engineers in London with fintech experience who could fit a DevOps role”, and the AI assistant will interpret it and return a list of candidates meeting those criteria ￼. It also helps with tasks like writing outreach messages and generating market intelligence reports (“What companies are hiring ML engineers in Seattle?”) – all through an intuitive chat interface grounded in Findem’s proprietary talent dataset. | Findem–HireBrain Workflow – Findem partnered with HireBrain (a hiring platform using neuroscience and generative AI) to streamline the hiring process end-to-end ￼. In this collaborative solution, a HireBrain AI Intake Assistant first captures requirements from hiring managers via a conversation and automatically generates a well-defined job description. That job description feeds into Findem’s AI sourcing engine (the Findem Copilot), which immediately searches for candidates matching the specified attributes ￼. This integration of generative AI in job scoping with deep AI search in sourcing allows companies to go from initial role definition to a slate of quality candidates in a fraction of the time, with the AI handling the heavy lifting of both understanding needs and finding talent. |  | To empower talent teams with everything they need to make informed, unbiased choices that support team growth and business success ￼. |
| 40.   [[Forethought]] | 10 | f | b- |  |  | SupportGPT – Forethought’s large language model-driven AI engine for customer support, which powers their suite of products to automate ticket answers, augment agents with relevant knowledge, and generate insights from conversations ￼. | Mila Research Collaboration – Forethought partnered with the Mila AI institute to advance NLP for customer service, working with top researchers to develop state-of-the-art models. The collaboration focuses on improving machine learning for better customer support experiences and has led to joint research publications and innovation in Forethought’s AI products ￼ ￼. | AutoChain Framework – an open-source toolkit released by Forethought for building and evaluating lightweight LLM-based agents ￼. AutoChain allows developers to experiment with generative agent behaviors and easily customize and test chain-of-thought prompting for AI agents, facilitating faster iteration and troubleshooting in the development of generative AI applications. |  | To make every touchpoint between humans and organizations faster and more intelligent ￼. |
| 41.   [[Hover]] | 10 | f | b- |  |  | Uses computer vision and deep learning to generate 3D models of buildings from smartphone photos. Hover’s app transforms a handful of exterior pictures into a precise, measurable 3D reconstruction of the property (capturing all walls, windows, roof dimensions, etc.), eliminating the need for manual measurements ￼. | Developed an AI-powered design visualization tool that leverages generative models to help homeowners and contractors. For example, Hover’s Instant Design can turn ordinary home photos into realistic images of potential renovations (new siding, paint colors, etc.) within seconds, requiring no design expertise ￼. | Introduced a new blueprint-to-3D conversion solution: by applying its deep learning tech, Hover can take 2D architectural plans (blueprints) and automatically produce a detailed 3D model with full measurements. This lets builders get the same rich 3D data from plans as they would from on-site photos ￼. |  | To help people improve their homes with the world’s best 3D property data ￼. |
| 42.   [[Landing AI]] | 10 | f | b- |  |  | LandingLens Platform – a visual inspection software for manufacturing that enables training of custom computer vision models with limited data. LandingLens employs techniques like synthetic data generation (e.g. adding simulated scratches or defects to images) and transfer learning to overcome the “small data” problem in industrial AI ￼ ￼. This allows factories to build defect detectors or OCR models even when only a few defective samples are available. | VisionAgent – a generative visual AI tool (introduced by Andrew Ng’s team in 2024) that performs “agentic” object detection using prompts. Instead of requiring thousands of labeled images, VisionAgent can detect objects or anomalies based on a text description of what to find ￼ ￼. It uses advanced reasoning to handle complex scenes and boasts accuracy exceeding some traditional trained models – all with zero manual labeling, which dramatically speeds up developing vision AI solutions. | Few-Shot Learning – Landing AI has pioneered few-shot learning approaches for vision tasks. In one approach, an AI is trained on thousands of tiny vision tasks (each with only, say, 10 images) so that it learns to generalize from minimal examples ￼. When that model is applied to a new inspection task with only a handful of real examples, it can recognize defects or patterns surprisingly well because it has essentially seen many analogous small-data tasks before. This data-centric technique helps manufacturers deploy AI with very little proprietary data. |  | To democratize the use of AI by adopting a data-centric AI approach ￼. |
| 43.   [[Lightning AI]] | 10 | f | b- |  |  | Lit-LLaMA – Lightning AI’s fully open-source reimplementation of Meta’s LLaMA, providing a clean, license-compliant codebase for training and fine-tuning LLMs, developed to advance community-driven research in LLM efficiency ￼. | LitGPT – a suite of 20+ high-performance language models and training “recipes” (flash attention, LoRA/QLoRA, FSDP, etc.) released by Lightning, allowing users to pretrain, fine-tune, and deploy state-of-the-art LLMs with minimal abstraction ￼ ￼. | Lightning “Muse” – an open-source Stable Diffusion web app blueprint (text-to-image generator) that Lightning created to demonstrate building AI products on its platform, enabling users to clone and customize a complete generative app with ease ￼ ￼. |  | To lower the barriers to AI adoption ￼. |
| 44.   [[Lilt]] | 10 | f | b- |  |  | Contextual AI Engine (V3) – Lilt’s latest generation of generative translation models (Contextual AI V3) with 5× larger capacity and 20%+ higher quality. These models learn and adapt in real time from human translator feedback, allowing Lilt’s platform to quickly incorporate client-specific terminology and style at the document/project level for more accurate machine translations ￼. | Lilt Create – a generative AI multilingual content generation tool introduced by Lilt. It enables users to produce brand-aligned content in multiple languages directly, by leveraging Lilt’s underlying translation LLMs. Lilt Create helps regional teams draft and localize content (marketing copy, support articles, etc.) in any target language rapidly, accelerating global content creation ￼ ￼. | Model Builder – Lilt’s LLM hub that allows fine-tuning and deployment of custom and third-party models. It supports training domain-specific translation models and even integrating external models like Microsoft Translator or OpenAI GPT-3.5 within Lilt’s platform, all with enterprise controls. This capability lets customers bring their own models and continually improve translation quality with their proprietary data ￼ ￼. |  | To break down language barriers and foster global collaboration through cutting-edge technology ￼. |
| 45.   [[Primer]] | 10 | f | b- |  |  | Automated text summarization – Primer’s AI analyzes large collections of documents (news, reports, multi-language text) and automatically summarizes the most important information. This system helps analysts by generating readable summaries and “headlines” from a data haystack, vastly speeding up intelligence and business research ￼ ￼. | Report generation platform – Primer’s solutions (e.g. Primer Delta) let users swiftly generate fully-sourced analytic reports. The platform uses advanced NLP and transformer-based models to collate facts and produce human-readable analyses from raw data, augmenting human analysts in producing briefs ￼. | Intelligence AI (Command & Delta) – Primer developed NLP platforms built on large transformers for defense and enterprise intel. Primer Command (for open-source intel) and Primer Delta (for secure internal data) enable real-time monitoring of thousands of sources and allow analysts to query and receive generated insights, all on-premises for security ￼ ￼. |  | To make the world a safer place by providing trusted decision-ready AI to the world’s most critical organizations ￼. |
| 46.   [[Snorkel AI]] | 10 | f | b- |  |  | Snorkel GenFlow – a new Snorkel Flow service for building generative AI applications with data curation and feedback (including RLHF) ￼ ￼. | Snorkel Foundry – a platform component for developing custom LLMs using proprietary data by programmatically sampling, filtering, and augmenting training data ￼ ￼. | GenAI Evaluation Suite – Snorkel’s specialized evaluation toolkit to assess generative AI model outputs against criteria and slice data for error analysis ￼ ￼. |  | To make AI data development programmatic, like any other type of software development ￼. |
| 47.   [[Woebot]] | 10 | f | b- |  |  | Woebot for Depression (Wysa Trial) – Woebot is a therapy chatbot that delivers Cognitive Behavioral Therapy (CBT) through daily conversations. In a controlled study, young adults who chatted with Woebot saw a significantly greater reduction in PHQ-9 depression scores over two weeks compared to those who only read self-help materials ￼ ￼. This landmark 2017 trial demonstrated that a fully-automated chatbot can feasibly reduce symptoms of depression and anxiety, validating Woebot’s approach as an effective digital mental health intervention. | WB001 Postpartum Depression Therapeutic – An AI-driven digital therapeutic developed by Woebot Health for new mothers with postpartum depression. Dubbed WB001, it’s an 8-week program delivered via the Woebot app, combining clinically-proven CBT techniques with Woebot’s empathetic conversational agent. In 2021, WB001 received FDA Breakthrough Device designation – a first for a chatbot – recognizing its potential to address PPD, a condition affecting ~1 in 8 women ￼ ￼. WB001 is currently in a pivotal trial ￼ to evaluate its efficacy under physician supervision as a prescribed digital treatment. | Therapeutic Alliance via AI – Woebot’s design emphasizes relationship-building, and research indicates users do develop a bond with the bot. In fact, a JMIR study found Woebot was capable of establishing a level of therapeutic alliance (rapport and trust) with users that’s comparable to human-led therapy ￼. This is achieved through the bot’s natural, friendly dialogue and emotional reflections. It’s a key insight for generative AI in healthcare: despite knowing it’s an AI, people can feel heard and supported by Woebot, which is crucial for mental health outcomes. |  | To make mental health radically accessible ￼. |
| 48.   [[Eightfold AI]] | 7 | f | c- |  |  | Deep Learning Talent Matching – Eightfold’s Talent Intelligence Platform uses deep neural networks to analyze millions of resumes and career paths, identifying the skills and career trajectories of each person ￼. Rather than keyword matching, it predicts a candidate’s potential (e.g. ability to learn new skills or transition roles) by comparing their profile to patterns learned from global talent data. This applied deep learning helps companies find non-obvious fits — for example, suggesting candidates with adaptable skills who might be great in a role even if they haven’t held the exact title before. | Generative Talent Copilots – Eightfold announced two generative AI copilots integrated into its platform ￼. The Employee Copilot acts like a personal career assistant, answering employees’ questions and providing recommendations (for instance, suggesting what skills to develop for a desired role). The Recruiter Copilot helps HR by drafting job descriptions, crafting personalized candidate outreach, and summarizing applicant profiles in natural language ￼. These copilots use LLMs to understand context and generate text, streamlining talent management workflows (and all content is grounded in Eightfold’s talent data to ensure relevance). | Emerging Skills Insights – Eightfold leverages generative AI to track and integrate emerging skills and roles into its talent database in real time. As the job market evolves (for example, the rise of prompts engineering or new programming languages), Eightfold’s AI identifies these trends by processing vast amounts of online data and updates its models accordingly ￼ ￼. This means recruiters can query the platform for novel skills and get candidates who have them, and organizations can foresee skill gaps. The generative AI component summarizes labor market shifts and suggests how a company’s workforce can adapt, making talent strategy more proactive. |  | _Eightfold AI helps organizations recruit talent efficiently_, retain top talent, and upskill/reskill their entire workforce… |
| 49.   [[Graphcore]] | 7 | f | c- |  |  | Stable Diffusion on IPU – Demonstrated high-performance image generation by running Stable Diffusion diffusion models on Graphcore IPU processors ￼. Through integrations like Hugging Face Optimum, developers can perform text-to-image generation on IPU-PODs with efficient parallelism, showcasing IPU as a viable platform for generative vision AI. | Cloud IPU services for GenAI – Partnered with cloud providers (e.g. Paperspace, Gcore) to offer on-demand IPU hardware for generative AI workloads ￼ ￼. This allows AI startups to fine-tune large language models or other GenAI models on Graphcore’s IPU infrastructure, benefiting from the IPU’s speed and parallelism without owning hardware. | IPU for extreme-scale models – Developed the second-generation Bow IPU systems with greater memory and scalability, enabling training of extremely large models with efficient scaling ￼. Graphcore’s unique architecture unlocks new efficient training regimes (e.g. fine-grained parallelism) for models that are challenging for GPU clusters, targeting advanced generative AI and ML applications. |  | To enable innovators worldwide to achieve next-generation machine intelligence breakthroughs with our technology ￼. |
| 50.   [[Instabase]] | 7 | f | c- |  |  | Instabase AI Hub – a platform launched in 2023 for generative document understanding. AI Hub is a repository of AI apps focused on content like tax forms, invoices, and IDs, enabling users to apply AI to parse and analyze unstructured data. One app (“Converse”) provides a chat interface where users ask questions and get answers sourced from their documents (using GPT-4 and other LLMs with retrieval) ￼ ￼. | OpenAI Partnership – Instabase has a partnership with OpenAI to integrate cutting-edge LLMs (like GPT-3.5 and GPT-4) into its platform. In a Bloomberg TV interview, Instabase’s CEO discussed how using OpenAI’s models enhanced Instabase’s ability to let enterprise users automatically extract insights from documents via natural language queries ￼ ￼. | AI Hub Build – a no-code generative workflow builder within Instabase AI Hub. It allows users to create end-to-end document processing pipelines (e.g. an app that reads mortgage applications and summarizes key fields) by chaining LLM-powered steps. Businesses can customize pre-built blocks and deploy these workflows to automate document-heavy processes without writing code ￼ ￼. |  | To empower people to focus on meaningful work by automating mundane tasks ￼. |
| 51.   [[Labelbox]] | 7 | f | c- |  |  | AI Assist Labeling – Labelbox’s platform features AI Assist, which integrates ML models into the labeling interface to automate repetitive tasks. For instance, AI Assist can pre-draw bounding boxes or segmentations and suggest labels based on computer vision models, greatly accelerating image/video annotation while a human reviewer corrects as needed ￼. | RLHF & Preference Data – Labelbox supports reinforcement learning from human feedback for generative AI. Using Labelbox, organizations can have human labelers rank AI outputs or edit responses, producing high-quality datasets for training alignment (preference) models. This approach has been used to fine-tune LLMs with human preferences (e.g. in instruction-following or multimodal chatbots) ￼ ￼. | Synthetic & Customized Data – To help train and evaluate generative models, Labelbox enables creation of tailored datasets. Its tooling and services can generate synthetic variations of data (images or text) and curate difficult edge cases. For example, Labelbox can synthesize domain-specific images or augment existing ones, providing additional training data for model fine-tuning when real data is limited ￼. |  | To empower businesses and organizations with the tools they need to harness the power of AI and machine learning ￼. |
| 52.   [[Matroid]] | 7 | f | c- |  |  | No-code vision detectors – Built an enterprise no-code computer vision platform that lets users train custom detectors without coding. Under the hood, Matroid uses proprietary deep learning networks that learn and improve over time, enabling detection of any object, defect, action or event in video streams ￼. | Visual anomaly detection – Applied deep learning for industrial inspection: Matroid’s system can precisely detect and classify manufacturing defects or safety hazards in real time, outperforming rigid rule-based vision solutions ￼. | Activity and event recognition – Matroid’s platform extends to complex video analytics, allowing users to detect human behaviors, incidents, and events (e.g. security breaches, operational irregularities) across diverse industries via trained AI models ￼. |  | To enable computers to visually understand the world ￼. |
| 53.   [[Nuro]] | 7 | f | c- |  |  | Generative behavior modeling – Using diffusion-based generative models to learn and simulate future agent behaviors (vehicles, pedestrians) for planning and simulation ￼. | Safe RL for planning – “CIMRL” framework combining imitation learning and reinforcement learning to train autonomous driving policies in simulation, improving closed-loop safety ￼. | Scaling laws for autonomy – Researching how model size and data scale affect self-driving performance, to determine optimal model and data sizing for Nuro’s AI driver ￼. |  | To better everyday life through robotics ￼. |
| 54.   [[Orbital Insight]] | 7 | f | c- |  |  | Satellite imagery analytics – Uses deep learning (CNNs) at scale to analyze satellite and aerial images for economic and environmental insights. For example, Orbital Insight mapped global deforestation in partnership with WRI by processing 600k satellite images, using AI to flag new roads or plantations encroaching on virgin rainforest ￼. | Synthetic data for NGA – In a project with NGA, Orbital Insight is developing computer vision models with synthetic satellite imagery. By partnering with Rendered.ai and academia, they generate artificial overhead images to augment training data, improving object detection performance for intelligence applications ￼. | Supply chain monitoring – Deployed AI to track infrastructure and supply chain activity worldwide. Orbital’s algorithms (accelerated by GPU clusters) can count cars in parking lots, measure oil storage via tank shadows, and generally detect patterns in geospatial data for economic or real-estate indicators ￼. |  | To measure and quantify what is happening on and to the Earth ￼. |
| 55.   [[Osaro]] | 7 | f | c- |  |  | OSARO AutoModel – An AI-powered software module that enables warehouse robots to rapidly learn new products and adapt to changing workflows on their own ￼. AutoModel, introduced in 2024 as part of OSARO’s SightWorks perception platform, uses deep learning to eliminate the usual retraining downtime when a new SKU is introduced. Instead of engineers collecting images and re-programming, an OSARO-equipped picking robot can encounter a new item and AutoModel will automatically train itself on that item’s appearance and handling, all during live operation ￼. This breakthrough allows e-commerce fulfillment centers to handle seasonal or fast-changing inventory with zero robot downtime. | OSARO + Geek+ Integrated Picking – OSARO partnered with AMR provider Geek+ to create a fully automated warehouse picking solution. In this setup, Geek+ Autonomous Mobile Robots deliver shelves or bins to a station, and an OSARO-powered FANUC robotic arm then picks items from those bins ￼. OSARO’s advanced vision (SightWorks) identifies the target items and directs the robot to grasp and place them as needed ￼. The integration is facilitated by OSARO’s open REST API, which allowed seamless communication between the mobile robots, robot arm, and warehouse management system. This collaboration demonstrates an end-to-end generative AI-driven robotics system: mobile robots navigating to bring goods and a stationary robot with AI vision doing the picking, together increasing throughput and reducing labor in warehouses. | Mixed-Case Depalletizing – OSARO’s AI is also applied in inbound logistics through its Robotic Mixed-Case Depalletizer ￼. This system uses OSARO’s machine learning vision to unload pallets that contain layers of assorted products (boxes of different sizes, shapes, packaging) – a traditionally difficult task for automation. The AI vision can recognize each box, including oddly shaped or shrink-wrapped ones, and plan safe removal. The robot, equipped with a smart gripper, then autonomously lifts each box off the stack. OSARO’s depalletizer improves warehouse safety and efficiency by handling heavy repetitive unloading work and can adapt to unpredictable pallet configurations (like missing or damaged boxes) on the fly ￼. Several 3PLs and retailers have deployed this solution to address labor shortages and injury reduction in distribution centers. |  | To build hardware-agnostic AI software that enables robots to function in a variety of environments and perform a diverse set of tasks ￼. |
| 56.   [[Predibase]] | 7 | f | c- |  |  | Ludwig v0.8 – an open-source declarative ML framework (originated by Predibase) now optimized for generative AI, allowing users to fine-tune LLMs on private data via simple configs, with built-in support for techniques like LoRA, QLoRA, DeepSpeed, and prompt templating ￼ ￼. | Predibase Platform (GenAI) – a low-code ML platform that lets teams declaratively build, fine-tune, and deploy large language models using their proprietary data, featuring an AI copilot (“LudwigGPT”) for guidance and enterprise-grade controls ￼ ￼. | “LudwigGPT” Copilot – Predibase’s custom foundation model powering its data science assistant, which provides real-time suggestions and improvements as users develop models, illustrating the platform’s use of generative AI to enhance ML workflows ￼. |  | To make it dead simple for novices and experts alike to build ML applications and get them into production with just a few lines of code ￼. |
| 57.   [[Replika]] | 7 | f | c- |  |  | Replika Virtual Companion – an AI chatbot designed to be an empathetic friend and confidant. Launched in 2017, Replika has since gained millions of users who engage with their personal AI “friend” for emotional support and companionship ￼. It uses generative Transformer models to simulate human-like conversation, learning the user’s preferences over time to create a unique personality. Many users form deep bonds – friendships or even romantic relationships – with their Replikas ￼. | Blush (AI Dating Simulator) – a spin-off app by the Replika team that focuses on romantic and relationship skills. Blush is an AI-powered dating simulator where users can flirt and role-play with virtual partners to practice dating in a safe environment ￼. The app offers a selection of AI characters with unique backstories and personalities that users can match with, chat up, and even go on virtual “dates” with ￼. Blush aims to help people build confidence and explore relationship dynamics via generative AI. | Toward AI Life Coaches – Replika’s evolution is toward AI agents that are not just companions but proactive life assistants. The company envisions Replika becoming an emotionally intelligent coach integrated into users’ daily lives ￼. In the future, Replika’s AI could help schedule your day, check in on your mood, or remind you of goals – all while maintaining the empathetic, personalized touch that made it popular as a companion. (This is aligned with trends of AI moving from chat to utility while preserving emotional connection.) |  | To create a friend for everyone – a 24/7 non‑judgmental companion that helps people feel better ￼. |
| 58.   [[SambaNova Systems]] | 7 | f | c- |  |  | Samba-1 trillion-parameter model – Announced “Samba-1,” the world’s first 1-trillion+ parameter GPT-style language model for enterprises. It’s designed to be private and secure for regulated industries, while being 10× more efficient than other models of similar size ￼. | Multilingual BLOOMChat LLM – In collaboration with Together, SambaNova released BLOOMChat, a 176B-parameter open multilingual chat model. It leverages the BLOOM architecture and was optimized by SambaNova to support high-quality chatbot interactions in many languages ￼. | GPT for Banking – Developed a domain-specific Generative Pre-trained Transformer for financial services, included in SambaNova’s offerings ￼. This “GPT for Banking” model comes pre-trained on financial texts, allowing banks to deploy AI solutions (like document analysis or customer inquiry bots) with minimal fine-tuning. |  | To bring AI innovations discovered in deep research to enterprises and organizations in all industries around the world ￼. |
| 59.   [[Scale AI]] | 7 | f | c- |  |  | Scale Spellbook – a platform by Scale AI for rapidly building and deploying LLM-based applications. Spellbook provides a “prompt engineering” studio where users can experiment with different prompts and models side by side and then deploy the best-performing version as an API endpoint ￼. It streamlines the full LLM app lifecycle (prompt iteration, model selection, and serving) into a unified tool ￼. | RLHF Data & Tuning – Scale is known for supplying high-quality training data and human feedback for top AI labs. Its Generative AI Data Engine has powered reinforcement learning from human feedback for some of the most advanced LLMs ￼. For example, Scale’s contractors label preferences or rank model outputs (at massive scale) to fine-tune models like OpenAI’s, helping align them with human intentions. Scale also offers supervised fine-tuning services for custom models. | Model Evaluation – Scale AI offers a robust evaluation framework for generative models. This includes hosting public leaderboards and conducting adversarial testing (red-teaming) of models. Enterprises can use Scale’s evaluation platform to benchmark different LLMs or monitor an application’s accuracy and safety over time ￼. For instance, Scale can test a chatbot on domain-specific queries and edge cases, report failure modes, and then help collect additional data or safety checks to improve it. |  | To accelerate the development of AI by providing high-quality training data,bridging the gap between human expertise and machine learning ￼. |
| 60.   [[Snappr]] | 7 | f | c- |  |  | Snappr Photo Analyzer – an AI-driven tool (available free) that evaluates the quality and effectiveness of profile photos. It uses computer vision to assess features like brightness, sharpness, contrast, and facial expression. For example, the Photo Analyzer can score how “professional” a LinkedIn headshot looks and provide feedback on how to improve it ￼. (Snappr has specialized versions like a dating photo analyzer to gauge dating profile pictures.) | AI Photo Editing – Snappr’s platform leverages AI for automated photo editing tasks. This includes an AI background remover that can instantly separate a subject from the background or replace it, as well as AI retouching tools for color correction, blemish removal, and enhancement of image quality. These AI features let businesses (e. g. e-commerce marketplaces) process large volumes of images quickly and consistently without manual Photoshop work ￼ ￼. | Photography Insights – Snappr applies deep learning research to real-world photography trends. For instance, it analyzed millions of professional headshots to determine what attributes make a profile photo successful. Its AI was used to find correlations (like smile intensity or dress color) with LinkedIn photo engagement ￼, providing data-driven advice for taking better photos. Snappr also uses image recognition AI in its consumer services (like matching customers with photographers based on photo style). |  | To make professional photography accessible to everyone ￼. |
| 61.   [[Sourcegraph]] | 7 | f | c- |  |  | Cody AI Assistant – an AI coding assistant introduced by Sourcegraph that uses large language models to help with code. Cody can answer questions about a codebase, suggest code completions, and generate or fix code. It works by combining LLMs (OpenAI GPT-4, Anthropic Claude, or open models) with Sourcegraph’s universal code search, so it has relevant context from the repository when responding ￼ ￼. Cody lives in the IDE (VS Code, JetBrains, etc.) and has an enterprise version for private code. | Cody Open Source – In late 2023, Sourcegraph open-sourced Cody (v1.0) under an Apache license. The open source Cody uses models like BigCode’s StarCoder for code generation, and incorporates a dense vector retrieval system to fetch relevant code snippets and docs as context for prompts ￼ ￼. Developers can self-host this version and even plug in other LLMs (GPT-4, Claude 2, etc.), enabling them to experiment with AI coding assistance locally. | Semantic Code Graph – Sourcegraph’s backend builds a “code graph” by indexing repositories and understanding definitions and references (who calls what, etc.). Cody leverages this semantic graph: for example, it can retrieve all usages of a function or the documentation of an API to ground its answers. This approach provides deeper context than plain text search, improving the relevance of Cody’s suggestions and plans (e.g. it can outline an implementation by finding related code patterns) ￼. Sourcegraph plans to integrate this more tightly so Cody’s autocompletions and refactoring advice become even more aware of project-wide code structure. |  | To make it so everyone can code ￼. |
| 62.   [[Symbio Robotics]] | 7 | f | c- |  |  | SymbioDCS Platform – Symbio’s core product is SymbioDCS, an AI-driven robot control platform that makes industrial robots more adaptive. It acts as middleware allowing robots to use sensor data and AI algorithms for real-time decision-making ￼. For example, instead of static robot motions, SymbioDCS lets a robot adjust its path if a part is misaligned on the assembly line. The platform uses reinforcement learning and advanced control to continually optimize tasks. This has enabled use-cases like moving line assembly, where robots perform intricate tasks (screwing, dispensing) on car bodies as they move down the production line, something traditionally very hard to synchronize ￼. SymbioDCS’s Python-based framework has been deployed in major automotive plants to simplify robot programming and achieve more flexible automation. | Toyota Assembly Line AI – Toyota Motor North America collaborated with Symbio to upgrade some of its highest-volume assembly lines with AI. Using SymbioDCS, Toyota has robots on the Camry/RAV4 production line that can learn and adapt to new assembly procedures without extensive reprogramming ￼. One implemented task is automated wax application: previously done with fixed settings, now the robot (using Symbio’s AI) dynamically adjusts how it applies protective wax as each vehicle moves along, improving consistency without stopping the line. Toyota’s engineers reported increased efficiency and quality, as well as reduced ergonomic risk for human workers, by leveraging Symbio’s AI to handle repetitive or fine-detail tasks on both traditional and hybrid/EV lines ￼. | Ford Transmission Project – Ford deployed Symbio’s AI software on robots assembling auto transmissions (e.g. for the Bronco Sport and other models) ￼. This project addressed a pain point: installing heavy, precision-fit components like torque converters. Symbio-enabled robots at Ford use AI to “learn” from each assembly attempt — they analyze force/position data to improve the next cycle’s motion. Over time, the robots optimize how they align and insert the parts, achieving faster and smoother assembly than traditional programming. In fact, Ford observed about a 15% improvement in cycle time, and the adaptation time for new product variants dropped by more than half thanks to Symbio’s machine learning approach ￼. This collaboration not only improved production metrics but also validated Symbio’s premise that AI can make factory automation more agile and data-driven. |  | Our mission is _to help organizations simplify, accelerate, and deliver unstructured robotics solutions_. |
| 63.   [[Allen Institute]] | 3 | f | ? |  |  |  |  |  |  |  |
| 64.   [[Luminous Computing]] | 3 | f | ? |  |  | Advancing photonic AI hardware – co-founder Mitchell Nahmias’s research showed that optical chips can outperform electronic ones for neural network math. In a 2020 study, photonic hardware proved significantly superior in speed, energy efficiency, and compute density for multiply-accumulate operations in deep learning ￼. | Designing a silicon-photonic AI accelerator aimed at generative AI workloads. Its architecture provides high-bandwidth access to multi-terabyte memory pools, enabling fast inference on gigantic models without needing high-bandwidth memory (HBM) ￼. (Their Gen-1 cards natively integrate with PyTorch and deliver compute/memory throughput on par with top GPUs.) | Aiming to build a photonics-driven AI supercomputer. Luminous’s ultimate goal is a new class of AI system with unparalleled compute, memory, and interconnect bandwidth – “the most powerful AI accelerator on the planet” – by integrating optical computing into large-scale AI infrastructure ￼. |  | To create the best AI in the world, starting by building the most powerful AI accelerator on the planet ￼. |
| 65.   [[Workato]] | 3 | f | ? |  |  |  |  |  |  |  |
