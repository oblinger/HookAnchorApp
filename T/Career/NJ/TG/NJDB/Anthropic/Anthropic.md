.[[Anthropic]].  [[@Anthropic]]. 
  , ,
  , ,
  , ,
  , [Anthropic Obsidian](spot://anthropicobsidian),
  DELS: ,[Anthropic Obsidian](spot://anthropicobsidian),
  , ,
  , [Anthropic Note](spot://anthropicnote), 
  DELS: [Anthropic Note](spot://anthropicnote),[Anthropic Obsidian](spot://anthropicobsidian),[Anthropic Note](spot://anthropicnote),[Anthropic Note](spot://anthropicnote),

# Top
#### kind: Top
#### area: CoreDL
#### stance: 
## Sections
### Cash
#### cash_trend: spiking
#### cash: 
#### cash_available: 1500
#### funding: 
Finalizing a fresh $3.5B round (Lightspeed, GC, Bessemer) ￼; reportedly raised $2B from Google in Oct 2023
### Coolness
#### cool: 
#### cool_why: 
#### cool_mission: 
#### cool_balance: 
#### cool_dan: 
#### mission: To build reliable, interpretable, and steerable AI systems ￼.
### Deep Learning Projects (DLP)
#### dlp: 
#### dlproj1: 
Claude – a next-generation AI assistant by Anthropic, trained to be helpful, honest, and harmless, capable of complex conversational and text-processing tasks ￼. It can even handle extremely long context (100K-token inputs, ~75,000 words) after a recent upgrade ￼.
Claude – a next-generation AI assistant trained to be helpful, honest, and harmless, capable of a wide range of conversational and text tasks
Claude is a family of large language models developed by Anthropic as a competitor to ChatGPT, first released in March 2023 [oai_citation_attribution:28‡en.wikipedia.org](https://en.wikipedia.org/wiki/Claude_(language_model)#:~:text=Claude%20is%20a%20family%20of,was%20released%20in%20March%202023)
#### dlproj2: 
Constitutional AI – Anthropic’s alignment technique that guides AI behavior by a set of principles in a “constitution.” Claude is tuned to follow high-level norms (inspired by documents like the U.N. Declaration of Human Rights) to produce helpful, harmless outputs ￼.
Constitutional AI – an alignment method where an AI model self-critiques and improves its responses using a set of principles as a 'constitution' to reduce harmful outputs [oai_citation_attribution:0‡anthropic.com](https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback#:~:text=As%20AI%20systems%20become%20more,model%20to%20evaluate%20which%20of)
(Not applicable).
#### dlproj3: 
100K Context – Anthropic expanded Claude’s context window from 9k to 100k tokens, allowing it to ingest and analyze hundreds of pages or hours of information in a single query ￼. This long-context version can, for example, read an entire book and answer detailed questions in seconds. ￼
Claude and Alexa+ – collaboration with Amazon integrating Anthropic's Claude models into Alexa, bringing advanced AI capabilities to the voice assistant with Anthropic’s safety measures [oai_citation_attribution:1‡anthropic.com](https://www.anthropic.com/news/claude-and-alexa-plus#:~:text=Today%2C%20we%27re%20announcing%20that%20Claude,and%20consumers%20around%20the%20world)
(Not applicable)
### Job Postings
#### job: 
#### job_why: 
#### job_bay: 
#### job_remote: 
### Toxicity
## Misc Fields
#### bam:
#### dlp_:
### proj1: Claude (Large language model chatbot)
### justification: 
Anthropic, founded by OpenAI alumni, developed Claude, a generative AI assistant similar to ChatGPT, with a focus on AI safety and ethics in its design [oai_citation_attribution:30‡eweek.com](https://www.eweek.com/artificial-intelligence/generative-ai-startups/#:~:text=Anthropic)
### proj2: Constitutional AI (Techniques for safer AI alignment)
### sdfsdfsfsfds: foo
