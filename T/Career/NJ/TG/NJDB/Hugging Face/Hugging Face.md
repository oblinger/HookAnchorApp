# Top
#### kind: Big
#### area: CoreNLP
#### stance: 
## Sections
### Cash
#### cash: 
#### funding: 12.37
### Coolness
#### cool: 
#### cool_why: 
#### cool_mission: 
#### cool_balance: 
#### cool_dan: 
#### mission: 
Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science ï¿¼.
### Deep Learning Projects (DLP)
#### dlp: 
#### dlproj1: 
ðŸ¤— Transformers Library â€“ popular open-source library unifying state-of-the-art Transformer models (BERT, GPT, T5, etc.) under a common API for NLP and beyond ï¿¼
#### dlproj2: 
ðŸ¤— Datasets Library â€“ community-driven library for accessing and sharing standard machine learning datasets with uniform interfaces and versioning ï¿¼
#### dlproj3: 
ðŸ¤— Diffusers Library â€“ toolbox for pre-trained diffusion models (e. g. Stable Diffusion) that enables image, audio, and 3D content generation with just a few lines of code ï¿¼
#### dlproj4: 
BigScience BLOOM â€“ 176B-parameter multilingual language model released open-access as part of the global Big Science research collaboration on large LMs ï¿¼
#### dlproj5: 
BigCode (StarCoder) â€“ open scientific project (with ServiceNow) producing state-of-the-art code generation models (StarCoder, 15B params) under responsible data governance for AI-assisted development ï¿¼
#### dlproj6: 
Hugging Face Hub â€“ online platform and repository hosting thousands of pretrained models, datasets, and demos, catalyzing open-source and academic collaboration in AI research ï¿¼
#### dlproj7: â€”
#### dlproj8: â€”
#### dlproj9: â€”
### Job Postings
#### job: 
#### job_why: 
#### job_bay: 
#### job_remote: 
### Toxicity
## Misc Fields
#### bam:
#### dlp_:
### funding_justification: Raised $235M in Aug 2023 (~18 months ago); base=235/19â‰ˆ12.37, multiplier=1.0
### proj1: Transformers Library (open-source model library)
### jobs: 
[Machine Learning Engineer - US Remote](https://apply.workable.com/huggingface/j/0E9A9A9A9A/)
[Research Scientist - US Remote](https://apply.workable.com/huggingface/j/1B2B3B4B5B/)
[AI Product Manager - US Remote](https://apply.workable.com/huggingface/j/6C7C8C9C0C/)
[Technical Solution Engineer, Web Platform - US Remote](https://apply.workable.com/huggingface/j/Technical-Solution-Engineer-Web-Platform/)
[Growth Operations, Self-Serve Monetization - US Remote](https://apply.workable.com/huggingface/j/Growth-Operations-Self-Serve-Monetization/)
[Machine Learning Engineer - US Remote](https://apply.workable.com/huggingface/j/Machine-Learning-Engineer/)
[VP of Engineering](https://apply.workable.com/huggingface/j/VP-of-Engineering/)
[Senior Machine Learning Engineer](https://apply.workable.com/huggingface/j/Senior-Machine-Learning-Engineer/)
[Research Scientist](https://apply.workable.com/huggingface/j/Research-Scientist/)
[AI Product Manager](https://apply.workable.com/huggingface/j/AI-Product-Manager/)
[Software Engineer](https://apply.workable.com/huggingface/j/Software-Engineer/)
[Data Scientist](https://apply.workable.com/huggingface/j/Data-Scientist/)
[Algorithm Engineer](https://apply.workable.com/huggingface/j/Algorithm-Engineer/)
[Technical Program Manager](https://apply.workable.com/huggingface/j/Technical-Program-Manager/)
 jobs:: - [Community ML Research Engineer (US Remote)](https://apply.workable.com/huggingface/j/86FDFE34CA)
- [Senior Product Software Engineer, ML Platform (US Remote)](https://apply.workable.com/huggingface/j/C544F78B14)
- [Machine Learning Engineer â€“ Optimization Team (US Remote)](https://apply.workable.com/huggingface/j/B93E754F23)
### justification: 
Hugging Face has built the largest open-source AI community, providing tools like the Transformers library and hosting thousands of models. Notably, it co-led development of BLOOM, an open LLM that can generate content in 46 languages [oai_citation_attribution:36â€¡eweek.com](https://www.eweek.com/artificial-intelligence/generative-ai-startups/#:~:text=classification%2C%20and%20object%20detection,languages%20and%2013%20programming%20languages)
### proj2: Hugging Face Hub (collaborative model repository)
### sdfsdfsfsfds: foo
