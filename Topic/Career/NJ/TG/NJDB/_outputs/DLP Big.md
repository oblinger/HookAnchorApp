| name | dlp | dlproj1 | dlproj2 | dlproj3 | dlproj4 | dlproj5 | dlproj6 | dlproj7 | dlproj8 | dlproj9 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 1.   [[ABBYY]] |  | Neural Network OCR â€“ ABBYYâ€™s FineReader engine employs deep CNNs and Transformer-based language models to recognize printed or handwritten text, then uses a custom LLM (trained on billions of parameters) to interpret context and produce highly accurate text output from images ï¿¼ ï¿¼ | Document AI for GenAI â€“ ABBYYâ€™s Intelligent Document Processing platform converts unstructured documents into structured data and embeddings, enabling Retrieval-Augmented Generation for enterprise LLMs (injecting business-specific context to improve generative AI accuracy and reduce hallucinations) ï¿¼ ï¿¼ | NeoML Library â€“ ABBYYâ€™s open-source cross-platform machine learning framework (C++/Python) used internally for computer vision and NLP tasks (image pre-processing, layout analysis, OCR, etc.), released to help developers build and deploy deep learning models with high performance ï¿¼ |  |  |  |  |  |  |
| 2.   [[Adobe]] |  | Firefly is Adobeâ€™s family of creative generative AI models integrated into Creative Cloud apps for tasks like image and video generation [oai_citation_attribution:24â€¡it.hms.harvard.edu](https://it.hms.harvard.edu/news/adobe-firefly-now-available#:~:text=Firefly%20is%20Adobe%E2%80%99s%20new%20family,Firefly%C2%A0are%20on%20the%20HUIT%20website) | Project VoCo is a prototype that enables novel editing and generation of speech audio, dubbed 'Photoshop-for-voice' since its reveal in 2016 [oai_citation_attribution:25â€¡en.wikipedia.org](https://en.wikipedia.org/wiki/Adobe_Voco#:~:text=software%20by%20Adobe%20that%20enables,It%20was) | (Not applicable) |  |  |  |  |  |  |
| 3.   [[Alibaba]] |  |  |  |  |  |  |  |  |  |  |
| 4.   [[Aurora Innovation]] |  | Proposer-Ranker Architecture â€“ Auroraâ€™s motion planning AI uses a two-tier system: it proposes a broad set of possible driving behaviors and then ranks them by cost, executing the highest-scoring feasible plan. This ensures â€œcorrectness by constructionâ€ by never considering options that violate dynamic feasibility or safety constraints ï¿¼ ï¿¼ | Transparent & Verifiable AI â€“ Auroraâ€™s self-driving software is built with internal interpretable predictions (e.g. traffic light state, other actorsâ€™ intentions) at each decision step, allowing engineers to pinpoint why the car behaved a certain way. This modular transparency enables rigorous validation and root-cause fixes, as opposed to opaque end-to-end approaches ï¿¼ ï¿¼ | GNN-Based Behavior Model â€“ Aurora pioneered using graph neural networks with attention (Transformer-style) for learning driving policy. This generative behavior model approach, which uses graphs of agents and relationships as input, is now increasingly adopted across the AV industry to produce more human-like driving decisions ï¿¼ | â€” | â€” | â€” | â€” | â€” | â€” |
| 5.   [[Automation Anywhere]] |  | Automation Co-Pilot (2023) â€“ An AI assistant embedded in enterprise applications to help users with workflow automation via natural language. Co-Pilot is powered by generative AI, letting employees simply ask in plain English to fetch data or execute business processes. It orchestrates the appropriate bots and API calls under the hood, so complex tasks (from updating records to handling insurance claims) can be initiated through a conversational chat interface ï¿¼ ï¿¼ | AI Agent Studio (2024) â€“ A generative AI-based development studio for creating custom â€œAI agentsâ€ that can automate complex processes. AI Agent Studio provides low-code tools to design, deploy, and govern AI-driven bots that use LLMs and enterprise data (via retrieval-augmented generation) to make decisions and take actions. It enables developers of all skill levels to build specialized agents (with access to company knowledge bases) that execute tasks via natural language instructions, with built-in governance and transparency features ï¿¼ ï¿¼ | IQ Bot (2018) â€“ An intelligent document processing bot that applies deep learning to extract structured data from unstructured documents. IQ Bot uses computer vision and machine learning to â€œreadâ€ semi-structured documents like invoices, purchase orders, and emails â€“ classifying fields and capturing values with minimal human training. It learns from each document example, improving accuracy over time, and integrates with RPA workflows to automate data entry and document-heavy processes ï¿¼ ï¿¼ | â€” | â€” | â€” | â€” | â€” | â€” |
| 6.   [[Baidu]] |  | â€¦ | ... |  |  |  |  |  |  |  |
| 7.   [[CrowdStrike]] |  | Charlotte AI â€“ a generative AI â€œsecurity analystâ€ integrated into the Falcon platform that answers usersâ€™ English questions about threats and speeds up workflows using CrowdStrikeâ€™s high-fidelity security telemetry (continuously improved with human feedback) ï¿¼ ï¿¼ | Contrastive Malware Learning â€“ CrowdStrike researchers demonstrated that applying contrastive self-supervised learning to a dataset of 15.5 million portable executable malware samples significantly improves a classifierâ€™s ability to detect novel and emerging malware threats ï¿¼ ï¿¼ | AI-Generated IOAs â€“ the Falcon platform leverages AI to automatically generate and validate new Indicators of Attack (IOAs) beyond what human experts have written, enabling it to catch emerging tactics by recognizing behavior patterns that were previously unseen ï¿¼ | â€” | â€” | â€” | â€” | â€” | â€” |
| 8.   [[Cruise]] |  | Continuous Learning Machine â€“ an active learning system that automatically mines and labels rare driving scenarios to improve the AVâ€™s prediction models ï¿¼ ï¿¼ | Webviz â€“ an open-source web-based robotics data visualization tool for exploring autonomous driving sensor data and simulation results ï¿¼ ï¿¼ | Massive Simulation Platform â€“ Cruise orchestrates ~200,000 hours of driving simulation per day across 30,000 virtual cars to train and test its self-driving AI at scale ï¿¼ | â€” | â€” | â€” | â€” | â€” | â€” |
| 9.   [[Databricks]] |  | Dolly 2.0 (2023) â€“ An open instruction-tuned LLM released by Databricks. Dolly 2.0 is a 12-billion-parameter model fine-tuned on a new 15K record human-generated dataset (databricks-dolly-15k) and openly released for commercial use, allowing organizations to create ChatGPT-like apps without relying on proprietary APIs ï¿¼ ï¿¼ | MPT (2023) â€“ Family of open-source â€œMosaic Pretrained Transformerâ€ models (7B and 30B parameters) introduced after Databricksâ€™ acquisition of MosaicML. MPT-7B prioritizes efficiency and MPT-30B higher quality; both are commercially usable and can be further trained on custom data, enabling organizations to deploy their own advanced LLMs ï¿¼ ï¿¼ | Mosaic Diffusion (2023) â€“ A text-to-image generative model released by Databricks/MosaicML. Mosaic Diffusion is optimized for efficiency, turning text descriptions into images. The code and pre-trained weights were open-sourced, allowing enterprises to generate and customize images with a model trained on a trusted, proprietary dataset (e.g. a collaboration where it was trained on Shutterstockâ€™s image library) ï¿¼ ï¿¼ | LLM Foundry (2023) â€“ An open-source library by Databricks for training, fine-tuning, and evaluating large language models. LLMÂ Foundry provides highly optimized code and recipes (e.g. support for FlashAttention, low-precision techniques) to help researchers and industry train big models like GPT-style transformers efficiently at scale ï¿¼ | â€” | â€” | â€” | â€” | â€” |
| 10.   [[Hugging Face]] |  | ğŸ¤— Transformers Library â€“ popular open-source library unifying state-of-the-art Transformer models (BERT, GPT, T5, etc.) under a common API for NLP and beyond ï¿¼ | ğŸ¤— Datasets Library â€“ community-driven library for accessing and sharing standard machine learning datasets with uniform interfaces and versioning ï¿¼ | ğŸ¤— Diffusers Library â€“ toolbox for pre-trained diffusion models (e. g. Stable Diffusion) that enables image, audio, and 3D content generation with just a few lines of code ï¿¼ | BigScience BLOOM â€“ 176B-parameter multilingual language model released open-access as part of the global Big Science research collaboration on large LMs ï¿¼ | BigCode (StarCoder) â€“ open scientific project (with ServiceNow) producing state-of-the-art code generation models (StarCoder, 15B params) under responsible data governance for AI-assisted development ï¿¼ | Hugging Face Hub â€“ online platform and repository hosting thousands of pretrained models, datasets, and demos, catalyzing open-source and academic collaboration in AI research ï¿¼ | â€” | â€” | â€” |
| 11.   [[IBM]] |  | Watson (DeepQA) â€“ question-answering AI that made history by defeating champions on Jeopardy! (2011), using IBMâ€™s DeepQA architecture to parse natural-language clues, generate hypotheses, gather evidence from huge text corpora, and rank answers with high confidence ï¿¼ ï¿¼ | Project Debater â€“ first AI system to meaningfully debate humans on complex topics, scanning billions of sentences to generate persuasive speeches, listen to a human opponent, and formulate rebuttals using a rich knowledge graph of world facts ï¿¼ | RXN for Chemistry â€“ cloud AI platform treating chemistry like a language: uses sequence-to-sequence Transformer models to predict chemical reaction outcomes and assist in retrosynthesis planning by â€œtranslatingâ€ between molecular representations (SMILES) ï¿¼ | Maximo Visual Inspection â€“ IBMâ€™s deep learning computer vision platform that generates and deploys custom vision models (e.g. defect detection in manufacturing), combining generative data augmentation and explainability for industrial inspectionã€n/aã€‘ | IBM FedML (FL) â€“ IBMâ€™s research in federated learning enables training generative models on decentralized data (e.g. edge devices) with privacy, demonstrated on tasks like emoji prediction and medical imaging (applied DL at the edge)ã€n/aã€‘ | ** - ** | ** - ** | ** - ** |  |
| 12.   [[Intel]] |  | FakeCatcher â€“ real-time deepfake video detection platform by Intel that analyzes subtle â€œblood flowâ€ cues in video to spot AI-generated fakes, boasting 96% accuracy in lab tests ï¿¼ | OpenVINO Toolkit â€“ Intelâ€™s open-source deep learning optimization and inference toolkit used to accelerate models like FakeCatcher on CPUs (e.g. running face detection and landmark AI models in milliseconds) ï¿¼ | Loihi â€“ Intelâ€™s neuromorphic research chip that mimics brain neurons/spikes to enable energy-efficient generative models and sparse coding; has been used to generate simple patterns and solve optimization via spiking neural nets (exploring non-von Neumann AI hardware)ã€n/aã€‘ | ChatGPT on Xeon â€“ Intel engineers optimized OpenAIâ€™s GPT models on Intel Xeon CPUs using oneDNN and AVX-512, demonstrating generative text inference without a GPU and paving the way for enterprise CPU-based AI deploymentã€n/aã€‘ | Intel DALL-E Demo â€“ Intel showed a diffusion model generating images on its Arc GPUs and optimized libraries at SIGGRAPH, highlighting how Intelâ€™s Open Source Ray Tracing and oneAPI tools can accelerate visual generative AI on their hardware ï¿¼ | ** - ** | ** - ** | ** - ** | ** - ** |
| 13.   [[Matterport]] |  | Cortex AI (2019) â€“ Matterportâ€™s proprietary AI engine for 3D reconstruction. Cortex is a deep learning-based system that converts 2D imagery from panoramic cameras into dimensionally accurate 3D digital twins. It combines computer vision, image processing, and neural networks to automate the creation of immersive 3D models of real spaces, enabling thousands of captures per day without manual post-processing ï¿¼ | Property Intelligence (2022) â€“ A suite of AI analytics for Matterport digital twins that uses deep learning to automatically extract property insights. For any scanned building, the system can compute metrics like total floor area, room dimensions (ceiling heights, wall lengths), detect objects or features, and output informed estimates. These AI-derived details â€“ generated from Matterportâ€™s vast spatial data library of billions of sq. ft. â€“ help in facilities management, interior design, and real estate marketing ï¿¼ | Project Genesis (2023) â€“ A generative AI initiative to allow on-the-fly editing and enhancement of 3D spaces. Genesis combines Matterportâ€™s computer vision breakthroughs (Cortex, Property Intelligence) with new generative models so that a digital twin is no longer static but â€œdynamicâ€ â€“ users can automatically remove furniture, swap design elements, or re-stage a room in 3D. For example, Genesis can generate alternate interior layouts or virtual renovations within a captured space, leveraging Matterportâ€™s 3D data to ensure all AI-generated modifications are spatially and dimensionally accurate ï¿¼ ï¿¼ | Defurnishing AI (2024) â€“ Matterportâ€™s Vision & Learning research team (with partners) developed a generative model that can â€œdefurnishâ€ an indoor panorama â€“ i.e. remove furniture via AI inpainting. Using a fine-tuned Stable Diffusion pipeline, it segments furniture in 360Â° images and fills in the room as if empty ï¿¼ ï¿¼. This project, presented at CVPR 2024, showcases how generative models can synthetically declutter or modify real estate visuals, a capability being integrated into Matterportâ€™s platform to aid virtual staging and space planning. | â€” | â€” | â€” | â€” | â€” |
| 14.   [[OpenAI]] |  | GPT-4 (2023) â€“ A large multimodal transformer with 175B+ parameters accepting text and image inputs, achieving human-level performance on many academic and professional benchmarks (e.g. top-10% on the bar exam) after extensive alignment tuning ï¿¼ | ChatGPT (2022) â€“ An AI chatbot based on the GPT-3.5 series (InstructGPT), tuned for conversational dialogue. It can answer follow-up questions, admit mistakes, and reject improper requests, demonstrating the ability to carry out natural conversations and assist users ï¿¼ | GPT-3 (2020) â€“ A 175 billion-parameter language model that revolutionized few-shot learning. Without task-specific training, GPT-3 could translate text, answer questions, and generate articles, often matching or beating state-of-the-art models fine-tuned on those tasks ï¿¼ ï¿¼ | DALLÂ·E 2 (2022) â€“ A generative vision model that creates original images from natural language descriptions. It can blend concepts, styles, and attributes to produce realistic art from text prompts, significantly improving resolution and fidelity over the first DALLÂ·E ï¿¼ | OpenAI Codex (2021) â€“ A descendant of GPT-3 fine-tuned on billions of lines of code. Codex translates natural language to code in over a dozen programming languages, powering tools like GitHub Copilot. It enables a user to describe a task in English and get executable code as output ï¿¼ ï¿¼ | CLIP (2021) â€“ A multimodal model (Contrastive Language-Image Pretraining) that learned visual concepts from 400 million imageâ€“text pairs. CLIP can recognize and classify images in zero-shot fashion by ranking which text description fits an image, enabling flexible image recognition without traditional training data ï¿¼ ï¿¼ | Whisper (2022) â€“ An open-source automatic speech recognition model trained on 680k hours of multilingual audio. Its large-scale training made it robust to accents, background noise, and technical jargon, allowing transcription in multiple languages and even translation to English, approaching human-level accuracy in many cases ï¿¼ | OpenAI Five (2019) â€“ A deep reinforcement learning project that trained five neural-network agents to play the complex esports game DotaÂ 2. OpenAI Five became the first AI to defeat the reigning world champion DotaÂ 2 team in live matches, marking a milestone in AI teamwork and long-horizon game strategy ï¿¼ | Jukebox (2020) â€“ A generative model for music that produces songs with vocals in various genres. Given a genre, artist style, and lyrics, Jukebox generates new music as raw audio. OpenAI open-sourced Jukeboxâ€™s code and model weights, demonstrating AI-created music with recognizable singing and instrumentation ï¿¼ |
| 15.   [[Palantir]] |  | Palantir AIP â€“ Palantirâ€™s new Artificial Intelligence Platform that integrates large language models (like GPT-4) into private defense and enterprise data environments. AIP acts as a secure â€œcopilotâ€ allowing users to query, monitor, and manage operations through natural language while respecting fine-grained security controls ï¿¼ | Foundry & Gotham â€“ Palantirâ€™s flagship platforms now embed generative AI capabilities (via AIP) to help analysts generate insights from Big Data. For example, Gotham (defense) can use LLMs to draft reports from multi-source intel, and Foundry (commercial) can generate Python code or SQL for analysts based on plain English requests ï¿¼ | ** â€“ ** | ** â€“ ** | ** â€“ ** | ** â€“ ** | ** â€“ ** | ** â€“ ** | ** â€“ ** |
| 16.   [[SRI International]] |  | Pelican (Anti-Hallucination) â€“ SRIâ€™s researchers developed Pelican, a framework that splits tasks into sub-queries to make generative AI more trustworthy, reducing hallucinated content by ~32% in image-based question answering experiments ï¿¼ ï¿¼ | AiCorb Generative Design â€“ a collaborative project with Obayashi Corp. and Hypar: AiCorbÂ® is an AI â€œmachine creativityâ€ toolkit that lets architects input a rough 2D sketch or photo and automatically generate a feasible 3D building model (BIM) for rapid ideation and visualization of architectural designs ï¿¼ ï¿¼ | Generative Memory (Lifelong RL) â€“ SRIâ€™s AI researchers (as part of DARPAâ€™s L2M program) created a generative memory mechanism for reinforcement learning agents that â€œreplayâ€ imagined past experiences, allowing continuous learning without catastrophic forgetting (inspired by how sleep consolidates human memory) ï¿¼ ï¿¼ | TrinityAI (Neuro-Symbolic) â€“ under DARPAâ€™s ANSR program, SRI leads TrinityAI, a hybrid AI system combining symbolic reasoning with deep learning (large language models) to create transparent, resilient agents that adapt safely to never-before-seen situations, improving human trust in AI recommendations ï¿¼ ï¿¼ | â€” | â€” | â€” | â€” | â€” |
| 17.   [[Salesforce]] |  | CodeGen â€“ Salesforceâ€™s open-source 16B-parameter language model for code generation, trained on massive natural language and code corpora; it turns English instructions into code in languages like Python or JavaScript and even powers GitHub Copilot-like capabilities ï¿¼ | ProGen â€“ Salesforce Researchâ€™s protein-generating language model (trained on ~280 million amino acid sequences) that can generate novel protein sequences; remarkably, 73% of ProGenâ€™s AI-designed enzymes were functional in lab tests, outperforming many natural proteins ï¿¼ | AI Economist â€“ a multi-agent reinforcement learning research environment where AI â€œagentsâ€ and a simulated government explore tax policies for optimal social outcomes; a generative economic simulation by Salesforce to discover policies balancing equality and productivityã€n/aã€‘ | BLIP â€“ Salesforceâ€™s Bootstrapping Language-Image Pre-training model that learns joint visual-text representations; it can generate rich captions for images and was used as a foundation for vision-language tasks like VQA and image retrievalã€n/aã€‘ | CTRL â€“ Salesforceâ€™s 2019 1.6B-parameter controllable text generation model that introduced the ability to steer GPT-2â€“style generation via control codes (e.g., news, dialog) in the prompt, an early approach to guided generative textã€n/aã€‘ | ** - ** | ** - ** | ** - ** | ** - ** |
| 18.   [[SentinelOne]] |  | Generative AI Threat Hunting â€“ a first-of-its-kind cybersecurity AI platform that embeds a large language model interface into threat hunting, letting analysts ask complex questions in natural language and get detailed, correlated threat answers in seconds ï¿¼ | Embedded Neural Nets â€“ the SentinelOne agent uses on-device deep learning models (neural networks) to autonomously detect malicious behaviors and stop attacks on endpoints in real time without human intervention ï¿¼ | Deep Learning Endpoint Protection â€“ as an early mover in AI security, SentinelOne pioneered using deep neural networks (instead of signatures) for malware detection, enabling its autonomous endpoint protection platform to identify threats with high speed and accuracy ï¿¼ | â€” | â€” | â€” | â€” | â€” | â€” |
| 19.   [[SoundHound]] |  | Speech-to-MeaningÂ® ASR â€“ one-step automatic speech recognition and understanding system that converts speech directly to meaning (bypassing raw text transcription) for real-time voice queries ï¿¼ | Deep Meaning UnderstandingÂ® â€“ proprietary NLU technology for complex, multi-part queries and context, allowing voice assistants to handle compound user requests with high accuracy ï¿¼ | Chat AI for Automotive â€“ an in-vehicle voice assistant that integrates generative AI (e.g. ChatGPT) with SoundHoundâ€™s platform to enable conversational question-answering and dynamic dialog in cars ï¿¼ | â€” | â€” | â€” | â€” | â€” | â€” |
| 20.   [[Upstart]] |  | ModelÂ 19 & PTM â€“ Upstartâ€™s 19th-generation lending model introduced a Payment Transition Model that learns from intermediate loan delinquency states (current, delinquent, etc.) to better predict defaults, significantly improving credit risk accuracy ï¿¼ | ModelÂ 18 (APR Feature) â€“ an earlier Upstart model version that first incorporated loan APR as an input feature, a change that produced a large jump in predictive accuracy for borrower risk ï¿¼ | Fair Lending LDAs â€“ Upstartâ€™s AI fairness research uses Less Discriminatory Alternative analyses to find credit models that reduce bias against protected classes while preserving accuracy in lending decisions ï¿¼ | â€” | â€” | â€” | â€” | â€” | â€” |
| 21.   [[Waymo]] |  | Waymo Open Dataset (2019) â€“ A large-scale autonomous driving dataset (sensor data from cameras and LiDAR) released to the public to fuel state-of-the-art deep learning research in self-driving cars. It has enabled academic and industry researchers to develop and benchmark perception and prediction models for autonomous vehicles ï¿¼ | GINA-3D (2023) â€“ Generative Implicit Neural Assets in 3D, a research project by Waymo and Stanford (CVPRÂ 2023). GINA-3D uses generative models to create realistic 3D models of vehicles and pedestrians from real-world driving data. Trained on over 520k images of vehicles and people from the Waymo Open Dataset, it produces diverse, high-fidelity 3D assets (geometry and texture) for simulation, improving the richness of virtual test environments ï¿¼ ï¿¼ | EMMA (2024) â€“ End-to-End Multimodal Model for Autonomous Driving, a new Waymo model that leverages Googleâ€™s Gemini LLM as part of an end-to-end self-driving network. EMMA takes raw sensor data (camera images) and map text as input and generates future vehicle trajectories, performing joint tasks of motion planning, object detection, and road comprehension. It demonstrated that integrating a multimodal large language model can improve planning and perception by sharing a unified â€œlanguageâ€ representation of the driving scene ï¿¼ ï¿¼ | â€” | â€” | â€” | â€” | â€” | â€” |
| 22.   [[Zoox]] |  | Scenario Diffusion â€“ a novel generative AI framework (latent diffusion model) that creates realistic, controllable traffic scenarios at scale for AV simulation and testing ï¿¼ ï¿¼ | 8â€‘Second Trajectory Prediction â€“ Zooxâ€™s robotaxi uses a 60+ channel CNN on 360Â° sensor data to predict the future trajectories of vehicles, pedestrians, and others up to 8 seconds ahead ï¿¼ ï¿¼ | CLAMS (Calibration & Localization Mapping Simultaneously) â€“ ML-driven system for sensor calibration and HD mapping that removes transient objects from LiDAR data and achieves centimeter-level localization accuracy ï¿¼ ï¿¼ | â€” | â€” | â€” | â€” | â€” | â€” |
