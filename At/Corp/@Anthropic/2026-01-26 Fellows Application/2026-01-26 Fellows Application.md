


## Todo


## Andrew Ask

Andrew:



## Info
- The deadline is January 12, 2026.
  The program runs in two cohorts (May and July 2026). Fellows get:
  - $3,850/week stipend
  - ~$15k/month compute
  - 4 months of mentorship from Anthropic researchers
  - Workspaces in London and Berkeley (or remote in US/UK/Canada)
  Over 40% of fellows from the first cohort joined Anthropic full-time.

  Sources:
  - https://alignment.anthropic.com/2025/anthropic-fellows-program-2026/
  - https://www.anthropic.com/careers/jobs/5023394008
  - https://constellation.fillout.com/anthropicfellows

- [[Anthropic AI Safety Fellow]]
- [[Fellows Program Blog]] 
- [[Researchers]] 
- https://oblinger.github.io/abio-docs/  


  The paper is: "Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations"
  - Authors: Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng
  - Venue: ICML 2009 (Best Application Paper Award)

  Acknowledgment section:
  "We give warm thanks to Daniel Oblinger and Rajat Raina for helpful discussions. This work was supported by the DARPA transfer learning program under contract number FA8750-05-2-0249."

  PDF: https://ai.stanford.edu/~ang/papers/icml09-ConvolutionalDeepBeliefNetworks.pdf


### Researchers
- Jan Leike
- Sam Bowman
- Sara Price
- Alex Tamkin
- Nina Panickssery
- Trenton Bricken
- Logan Graham
- Jascha Sohl-Dickstein
- Nicholas Carlini
- Joe Benton
- Collin Burns
- Fabien Roger
- Samuel Marks
- Kyle Fish
- Ethan Perez


## Application Notes

LinkedIn:
GitHub:
PersonalWebsite:  
Other Site:

**Share Links Here:**

Alien Biology - Framework for generating synthetic "Alien" biological ecosystems with alien organisms, with alien molecules, alien bio chemical reactions, pathways

Half a year ago, I wrote a white paper for AlienBiology—a provably Taint-free testbed, since all reasoning problems come from a generated universe with novel, synthetically generated organisms, bioreactions, and molecules.

I think it is a great testbed for studying AI reasoning in a context where one can provably isolate reasoning from any trained priors, since the world is synthetic from the molecules up.  I was reluctant to implement this, as it seemed more useful for advancing AI capabilities than for AI safety.


75% complete 


WHY ARE YOU INTERESTED IN PARTICIPATING IN THE AI FELLOWS PROGRAM?   (1-2 paragraphs)





PLEASE TELL US BRIEFLY ABOUT AN AREA OF TECHNICAL AI SAFETY WORK YOU’RE CURRENTLY EXCITED ABOUT, AND WHY.   (1 paragraph)




(Optional) Please share any relevant AI safety background you have and provide links where possible (e.g., research experience, coursework, self-directed study, past roles, relevant projects).



How likely are you to be interested in continuing to work on AI safety after the Fellows program? *



References:
- Andrew Ng
- Nina Mishra


Do you have any other commitments or obligations during the Fellows program?
- I will be on an unpaid leave

How Did you hear about the Fellows program?  

Is there anything else you would like to share?














