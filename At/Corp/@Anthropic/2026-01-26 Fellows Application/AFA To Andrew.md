







## 2026-01-11  

Andrew:

Tomorrow I am applying for an Anthropic Fellowship in AI safety. Would you be okay with me summarizing an interaction we had while I was at DARPA as a reference in that application?

Here is the context:  We spent a day discussing unsupervised methods for learning deep representations. You were skeptical until I narrowed one of the ideas into an approach for inducing deep and/or trees. You suggested that we collaborate with one of your students.  He went on to win best paper award at ICML for "Convolutional Deep Belief Nets," while the general council at DARPA refused to allow me to collaborate!  At the end of that day's discussion, you offhandedly told me I should come to be a postdoc after DARPA. Well, maybe I should have!

Let me know if I can use this interaction as a reference,
Dan



## 2026-01-11  

Time-sensitive: Can I reference a discussion you and I had in my application for an for an AI-safety fellowship at Anthropic?

Andrew:  
  
I am not sure if you remember the better part of a day that we spent in 2009 talking about unsupervised methods for learning deep representations.  You were interested, but also frustrated that my ideas seemed too big/vague to make progress on. I responded by driving one of the ideas down into a very narrow approach for inducing deep and-or trees.  You liked it and asked if you could share it with a student for exploration, and ended the day telling me that I should come be a post-doc after DARPA.  Well, perhaps I should have!  
  
I think your students went on to publish: *"Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations"*, from that idea, while the general council at DARPA forbade me from participating (at least Honglak acknowledged me in the paper!)  
  
Besides saying "hello" after so many years, the reason I am writing is to ask if you could provide a reference for an AI safety fellowship program at Anthropic.  
  
I recognize we never collaborated on completed work, so if you were contacted, you could only provide the context based on our few deep discussions.  Still, I think that thin slice would still add value.  
  
Let me know.  
-- Dan



1. You miss 100% of the shots you don’t take!
2. But I think there is an inverse relationship between length & chances of him responding. Is it possible to cut the length by at least half?
3. Is it possible to make it easier for him to say yes to? Eg: we met, remember this thing happened, I’m applying for Anthropic, if I use this discussion as a reference would you confirm that?

TESTTEXT
HELLO



❯ can you help me find multiple email addresses xr for Andrew Ng?

⏺ Web Search("Andrew Ng email address contact")
  ⎿  Did 1 search in 14s

⏺ Here are the email addresses and contact info I found for Andrew Ng:

  Academic (Stanford):
  - ang@cs.stanford.edu - his Stanford CS email

  Business:
  - hello@landing.ai - Landing AI inquiries
  - contact@aifund.ai - AI Fund inquiries

  Physical:
  - Stanford CS Department, Room 156 Gates Building, Stanford CA 94305
  - Phone: (650) 725-2593

  Note: His official website https://www.andrewng.org/contact/ routes inquiries through the appropriate channels rather than giving a direct personal email.

  Sources:
  - https://robotics.stanford.edu/~ang/contact.html
  - https://www.andrewng.org/contact/
  - https://profiles.stanford.edu/131927

