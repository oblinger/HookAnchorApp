GUI elements and structure elements
GUI control, and procedural control.  (e.g. a choice box is really a kind of branch)

# ### UNICORE OBLITS ###
## >>> DECOMPLECTING <<<

TL;DR.  Uniform is able to unify many aspects of different SW ecosystems, and many parts within each ecosystem by first splitting these parts into their smallest conceptuarlly coherent elements.

Important splits of unicore:

SPLIT
SPACE / TIME -- "unit.graph" defines a notion of space w/o time, while "Place" defines a notion of time, change, and persistence w/o a notion of space.
- UNIT.GRAPH defines a notion of structure and data w/o any referecne to a notion of change or time.
- PLACE defines a notion of time expressed as a timeline encoding persistence and change over time w/o any reference to an idea of multiple places, nor of structure between places nor structure of data
	
DATA MODEL / ACCESS MODEL -- 
- UNIT.GRAPH defines a particular kind of data (a particular family of graphical models)
- UNIT.ACCESS restricts all data access to be a vertex-centric operation, and fully constrains the data model underlying this access layer in terms of the three core operators:  IDX, ITR, and LEN

ACCESS MODEL / PERSISTENCE IMPLEMENTATION




## >>> STRUCTURE RELATED OBLITS <<<
## === UNIT ===
- **STRUCTURED-TYPES HIERARCHY OBLITERATION**.
	Existing languages tend to have a very-hit-or-miss hierarchy of structured data types that is akwardly constrained by the ways that OO-inheritance is used as a primary mechansim for type generativity.  Want an unordered collection with unique elements, use a set.  want an ordered multi-element set, no problem, use a list.  But what about an unordered multi-element set, use a multi-set --- oh wait that only exists in math, but not in these type hierarchies.  What about an undirected, labelled, ordered, persistent, multi-DAG, with historical value versioning?  Just fuggeditaboutit!  With uniform this, and thousands upon thousands of other data structuring types, come as native types straight out of the can.
- NO PERFORMANCE LOSS -- Because uniform does not attempt to achieve this generality using some inheritance hierarchy one is not limited to the tricks such implementations afford.  Instead uniform employes a generic types templating approach similar to C++ in order to build vertex specific virtual function tables where the methods attached to each vertex type is jit compiled based on the specific mix of vertex modifiers for this type.  Most of the jit complation is still allows modular addition of new vertex modifiers since each modifier is operating as jit-compile-time code modifier of the code generated by the other modifiers. with the occasional conflict case handling thrown in in the rare cases that one cannot design these code trasforms in an entirely modular way.
- SINGLE DATA TYPE
- SINGLE ACCESSOR PARADIGM -- 100% of all structural content for all variations of the unit form can be uniformed access via the itr (iterator) accessor -- unifies over 1K structure type-variations into single structure type with a unified access model.
- OBLITERATION OF THE STRUCTURE / FUNCTION DICOTOMY -- the 'ops' operator transforms the function of an entity into an "unwrapped" a purely structural form.  Conversely the dual 'structure' meta key "rewraps" a structure back into a functional form.  These dual forms obliterate the need for many meta programming forms since now one can use all existing structural operators to manipulate the functional semantics of those entities.  This is analogous to, but more uniform and general, than the manipulation of the javascript prototype object, or operating on Pythons attr/_ dict _ strcutures.
- FUNCTIONALITY EMBEDDING -- In order to avoid huge swathes of languages-forking madness, to greatly simplify the full spec of a language's ecosystem, and bring the full generality and power of the language structure mainpulation operations onto every kind of interface we embed ALL interfaces as a kind of structure-capable entity.
- 
- META PROGRAMMING -- Most "full service" programming language eventually grow a pretty gross bolt on meta-programming / inspection facility.  Because this capability is generally added after the fact, it ends up having a painfully bysantine, ugly, idiosyncratic nature.  Because these are typically implemented as "add on" method into sturucutres that were defined prior to the creation of these interfaces, and because the interface itself is pretty lowlevel and sometimes performance sensitive, a tremendous amount of plain ugly idiosyncrtic behavior exists here.  Uniform builds these in from the get go, and it jit compiles usage of these interfaces in a way that often allows one to be very general, very elegant, and very performant.
		// STACK FRAME
		
		// MULTI-LEVEL CLOSURE STRUCTURE
		
		// RPC CALL
		SOAP CALL

- OBLITERATION OF THE FOREIGN FUNCTION INTERFACE -- 
	In uniform every object is a foreigner in every land except its place of birth.  Thus in that sense a non-uniform native struct
	UNIT - obliterate foreign function interfaces

obliterate the distinction between foreign and native by making natives foreigners within their own land.

essentially we require all citizens of the uniform universe to carry their backing passport, not just the foreigners.

This obliteration relates to obliteration of factory distinction, by requiring all creation is done by factories, there is no 'native' class instantiator.

- DECOMPLECTED BACKING -- most 

	
- OBLITERATION OF THE ORM (OBJECT RELATIONAL MODEL)

UNIT - "Live" data oblits

// "LIVE" EXTERNALLY-BACKED STRUCTURES
// A few langauges like Python allow native POD treatment for arbitrary structures,
//	but none seem to allow simultanous advantages of POD and typed interfaces

FILESYSTEM READ / WRITE OPERATIONS -- Many languages

BROWSER DOM -- Javascript

DB-ORM-LIKE OPERATIONS

WEB-SOCKET-LIKE DATA BACKING
- Http CRUD Operations
- JSON-end point backing

IMAP / LDAP DATA BACKING

UNIT - Execution internal oblits

#### ,
UNIT - data patterns oblits

Nearly all languages have multiple incompatible ways of representing various, partially overlapping, categories of structured data.  

// STRUCTURAL ENTITIES WITH VARYING ELEMENT ORGANIZING PROPERTIES
LIST / SET / MULTISET / QUEUE / STACK -- Many languages
MAP / ORDERED MAP / RELATION / GRAPH / TREE / DAG         
	(Include directed / undirected, labelled/unlabelled versions of each)

// PERSISTENT STRUCTURES

_
UNIT - functional pattern oblits



_
####  


_
### UNIT.STREAM - Temporal structure oblits ---
#### _

UNIT.STREAM is a significant generalization of most popular langauage.  It defines a lossless bidirectional mapping between temporal and spatial structure for all data forms implicitly allowing very powerful operations to be performed 

Significant generalization of many languages, now all structures expressed spatially implicitly have a temporal expression as well.  Symmetrically any temporally expressed structure (e.g. a variable whose value is changes) implicitly has a spatial expression of the same strcuture.  (essentially a history)

_
#### UNIT.STREAM.ITERATOR -- temporal operations over existing structures

_
#### UNIT.STREAM.GENERATOR -- temporal operations over a computationally emergent structure

_
#### UNIT.STREAM.FILE -- temporal rendition of persistent storage structures

_
#### UNIT.STREAM.PIPE -- temporal operations as communication between the distinct interpretation processes

_
#### UNIT.STREAM.HISTORY -- temporal change-log-like rendition of structural updates

_ 
## >>> FUNCTION RELATED OBLITS <<<
## === GND ===
Three things wrong w. most lang object groundings:
- conflate class instantion (load time) with object instantiation (run time) into a single with varient behaivor for each, this forks much of the object-instance logic with class-instance alternatives.
- conflates the factories the create things with the specifications that define things.
	this creates 
- provides overly specializes object implementations, so proxy objects, ORMs, etc

	
## === LANG ===
### LANG.SLOT
#### LANG.SLOT.VAR -- Slots as program variables maintaining procedural state during execution
#### LANG.SLOT.FIELD -- Slots as object field accessors
#### LANG.SLOT.METHOD -- Slots as method invocation
#### LANG.SLOT.METASPEC -- Slots as 

// ASSIGNMENT-REDEFINION-LIKE OPREATIONS
Lisp's SETF, Python's []= dunders

// OBJECT-SETTER-GETTER-LIKE OPERATIONS
object.foo
object.foo = 7

_
### LANG.DATA -- Data-parsing, data-matching, data-expansion, data-generation language systems
#### LANG.DATA.PARSE -- Data languages focused more on the parsing/matching side
##### LANG.DATA.PARSE.STRING -- 
- REGEX -- Regular expressions language features and/or library extensions
- YACC -- LALR and host of many text to structure formal parsing system

_
##### LANG.PARSE.STRUCTURE - templates used to 
###### _
=== UNDERSTOOD AS FORMS THAT CONTAIN SLOTS ===


// TEMPLATE-PARSING LIKE OPERATIONS
REGEX MATCHING - 

// TEMPLATE-EXPANSION LIKE OPERATIONS
STRING FORMAT OPERATOR -


// TYPE HIEARARCHIES --  
//    To assert an object's type is to assert its slot structure, thus
//    Subclasses are just types with more restrictions on type structure
SUBCLASS -- many languages
EXTENDS -- many languages
TYPE_OF / INSTANCE_OF -- many langauges
###### LANG.PARSE.STRUCTURE.GRAMMAR -- Grammar based structural parsing
- CFG Parsers
###### LANG.PARSE.STRUCTURE.TEMPLATE -- Template based structural parsing systems

_ 
#### LANG.DATA.PRINT -- Data langauges focused more on the data generation side
##### LANG.DATA.PRINT.STRING -- String Printing languages
- FORMAT -- string formatter like sub-languages
- DATE -- data formatters
##### LANG.DATA.PRINT.STRUCTURE -- 
###### LANG.DATA.PRINT.STRUCTURE.GENERATORS -- 
###### LANG.DATA.PRINT.STRUCTURE.TEMPLATES -- 
## === EXE.BANG ===
- OBLITERATION OF THE STATIC / DYNAMIC LANGUAGE LIMITATIONS -- combines the declartional clarity of static languuages like C or Java with the crazy monkey-patching powers of dynaimic Ruby/Python/Lisp capabilities
- 
## === FLOW ===
Generality of control flow backbone.

super clean decomposition of flow types into a five part grammar

### -- FLOW.BRANCH --

The BRA operator is the only Unicore mechanism that provides any kind of conditioning on execution flow
thus, by construction, all branch-like actions in uniform built from the BRA operator.
The BRA thesis is that this moperator provides a uniform cover for all modern SW constructs

// BRANCH
IF-ELIF-ELSE like structures

// CASE


// TRY-EXCEPT like behaviors
CTX( form, BRA(=~, ))

// METHOD CALL

// TYPECASE like speciality branching

# ### Unicore Later Oblits ###

### 

### FLOW.BRANCH has some sequencing in it.
### OP value binding had some sequencing in it.
### FLOW.REPEAT has some conditioning in it.
### LANG had some PKG combining properties in it.


## OBLITS not yet done?
### GET/SET seem to be a kind of value update but are structural operators, do these need to merge?



# ### OBLITS DISCUSSION ###
### STRUCTURE SUFFICES MONDO-OBLIT

Often OO-functionality is used in cases that could be reduced to a structure-only encoding.  

Mutable structures are used in cases where immutable structures would suffice.

OBLIT!  Uniform does not force all to be immutable strcuture, but it does favor immutable over mutable, and structure over function.

~~~~
Better said:

OO-procedural attachment is kind of like infinite lazily constructed structure.  OBLIT!  All procedural attachment is infinite lazily constructed structure.

(we preserve the familiar OO-method structure as it is often easier to think about than infinite lazily constructed structures.  Still structure is often easier to think about rather than function, so both views are simultaneously presented.  E.g. the filesystem interface is just a tree of file nodes that are dynamically constructed as code traverses this structure.)

By allowing infinite and lazy structures these reduction

_
### STRUCTURE / FUNCTION MONDO-SPLIT-OBLIT

A virtual zoo of frankenstein-ian overlapping - gapping structuro-functional chimeras exist across the worlds language libraries.  Not only is the result a bloated over explosion of needless complexity -- worse still many possible combinations of structure and function are not supported by the many gaps in this collosal and illconceviend cross product space.

Uniform obliterates all of these by fully decomplecting structure from function.  In this way all logically consistent combinations are constructable from a much smaller cleaner basis set of mixins.

Want a have a Pathy, Watchy, Typey, DOM browser proxy implementation that can be updated using a language-native comprehension, whose elements are woven into the existing applications type hierarchy in one view and treated a plain old JSON in another view.  No problem, just declare it and map it onto a browser's DOM and get the rest for free.

This ain't your mamma's OO.


WTF did you just say?  Are you speaking English?  Ok an example:


class DomNode(Pathy, Watchy, Typey, Proxy)
	def GET ....
	def ITR ....

io.DOM = DomNode(type_from_head=myapp.DOM_Types)
bindNodeToBroserRootNode()

def clear_contents():
	fields = [ele for ele in io.DOM.flatten() 
				if ele isa Form and ele.under(isa(UserEditable))]

;; mostly langs allow robut proxy objects, better example 
;; two different views on same object.  add pathy watchy
;; have procedural attachment to some views of proxy objects





_
### EXPR / INSTANCE MONDO-SPLITTER-OBLIT
The data-level encoding of some info is kind of like its OO-encoding.  E.g.  'json' is kind of like 'oo_instance' below
   json = {"_":"Person", "first":"Dan", "last":"O"}
   oo_instance = Person(first="Dan", last="O")

SPLIT-OBLIT! 
In order to express what is in common between the json and oo_instance we must first decomplect what an object "says it is" from what the object "actually is".  According to the interpreter all json instances are of a single "type" of JSON container object.  But in an important sense the json object above also has a second type ... what is "says" it is.  e.g. "Person"

It is that second type which is parallel to the OO-encoded person type of the second object.  

Thus we first split the notion of 'head' from the notion of 'type' of an object.  In this way we can allow
	json.head() == oo_instance.head()  while also
	json.type() != oo_instance.type()

Introducing this head/type distinction then allows us to OBLIT the deep schism that generally exists in non-homoiconic languages between code and data.


_
### FACTORY / CONSTRUCTOR OBLIT
Factories are kind of like dis-embodied class construtors.

OBLIT!  All instance construction is performed by a factory.  Thus, since classes support instance creation they must be a kind of factory.

_
### SPEC / LANG OBLIT
'spec' is a generalization of pattern of having a desription or 'specification language' which indicates elements of a described universe.

the uniform's language model has code with indicates form.
OBLIT!  all languages are spec models where code is an indicator for interpretable forms.


_
### FUNCTIONAL/STRUCTURAL OBLIT
Operating on the functional slots of an object is kind of like operating on its structural slots.  
OBLIT!  functional slots ARE just structural slots on the Env
_
### MAP/LIST OBLIT
Operating on a map container is kind of like operating on a list container with greater flexibility in what can serve as a key
OBLIT!  lists are a kind of map
_
### POXO/CLASS OBLIT
- Operating on POJO, POPO, ... objects confers great advantage in simplification since all the concise datastructure operators (e.g. list comprehension etc.) operate directly on the POXO objects.
- Operating on task specific class objects confers great advantage in type safety, in convenient access to task specific operators, in semantic complexity reduction since relevant operators are formally tied to the structures they are intended to operate on.
OBLIT!  All POXO objects ARE specialty classes, thus all 'native' operators designed for structure operate directly on all task specialized classes.   
e.g.   	for file in folder: ...   
		will do exactly what you think it should do!

_
### Module/Package/Class/Dataset/KB OBLIT

_
### INHERITANCE/CONTAINMENT OBLIT
Class inheritance is kind of like set containment
OBLIT!  Class inheritance IS set containment of namespaces

_
### SET/TYPE OBLIT
Defining a data type is kind of like defining a predicate indicating set membership.
OBLIT! A datatype is a set membership predicate.


_
# Rest of HTML


<!DOCTYPE html>
<!--suppress ALL -->
<html>
<head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <link href='https://fonts.googleapis.com/css?family=Chivo:900' rel='stylesheet' type='text/css'>
    <!-- link rel="stylesheet" type="text/css" href="stylesheets/bootstrap-theme.min.css" media="screen" -->
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-dark.css.unused" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <title>Lexcore Spec</title>
</head>
<body><div id="container" class="inner">
    <header><h1><centerit>  Distinction Obliteration  </centerit></h1></header>
<pre>

</pre>

    <p> Removing just one unneeded distinction produces much more than an n-fold complexity reduction.
        Thus stringing a sequence of such reductions together produces a super-exponential reduction in complexity.
        This is exactly what Uniform does over and over again, as a conceptual language it is quite complete, yet
        because of repeated distinction obliteration it is quite unique, powerful and simple among software langauges.</p>








    <!--
    Software Engineers have been drowning in an ocean of needless complexity which extends back generations.
    We are so wet with this stuff that we can no longer even see the stuff clearly -- swamped with it,
    we can imagine they are somehow inherent to computation.
    Its not true, but for each it is helpful to explicitly identify the complexity and to
    mention how Lex (and sometimes other languages) obliterates or reduces that particlar complexity.
    -->


    <!-- PREAMBLE #1
    As software engineers we are swimming deep in the filth of needless complexity.

    On occasion we may sense the needless cruft, but mostly we are like fish in water,
    it is, and always has been so pervasively around us, that we are mostly unaware
    that it is even there, or that it could be different, that it could be possible for us to breath.

    The Oblits document is mostly aspirational.  It makes explict the filth that we are swimming
    in.  It puts a target on this needless complexity.  Lex makes strides in obliterating parts of
    many of these complexities.  In the hardest cases, one kind of complexity seeems to trade against another
    type of complexity.  In those cases we must choose the lesser of two evils.... still lex only does
    this as an absolute last ditch response....  and I am ever hopful that someone smarter than
    I can propose a yet simpler approach that better weaves between the perils listed here. -->





    <header><h1><centerit>  The Kill Files  </centerit></h1></header>

    &nbsp; &nbsp; <q>My dad's house is bigger than your dad's house.</q>  -- Arnold (age 7 on the playground)

    <br><br><br>

    <p> I was initially adamant that Uniform was <i>not</i> going to be
        <i>yet-another-engineers-scripting-language-that-was-going-to-fix-everything</i>,
        instead it was the script that was going to <i>connect</i> everything.</p>

    <p> Well it still aims to be that, but as I progressed, I found that the only way to really fully remove
        the corruptions I found in many software languages was to fully remove the languages themselves.
        It was simpler and cleaner to just build from the bottom.  To do that you need something to put in it place,
        and that is what Uniform grew be.</p>

    <p> Except this time it <i>is</i> different.  It is the scripting language that is going to fix everything!
        Well not really, but there are a colossal number of things that it can and does fix.
        So many problems that we have lived with since the birth of computing...
        So many tradeoffs that we have tacitly accepted as inherent, turn out to simply be choices.... BAD CHOICES.</p>

    <p> Thus the "Oblits File" is a bragging and an aspirational document.  I am not claiming that Uniform fully kills
        all of these evils.  It does not.  But it does deliver a fatal blow to some, and for the others
        at least in it draws our enemy fully out into the open where we can take clear shots on it.</p>

    <p> The job of this document is simply to enumerate the evils that we hope to vanquish.</p>








    <h1>The KILL FILES</h1>
    <!----------------------------------------------------------------------------------------------------------------->
    <!----------------------------------------------------------------------------------------------------------------->
    <!----------------------------------------------------------------------------------------------------------------->
    <h2>MULTICATIVE CLUSTER FORKS</h2>

    MCFs cause massive (literally exponential) explosions in amounts of source code, amounts of documentation, amounts
    of bugs in code, amounts of conceptual complexity that hapless programmers are forced to ingest in order to get
    their job done.   oblit this shit!



    <h3>Semantic Reuse</h3>

    <p> Computer science leverages a <i>SMALL</i> number of conceptual ideas to achieve a wide range of effects.
        Sadly our interfaces rarely refect this reuse.  Instead novel methods with slightly tweaked semantics
        are provided, maintained and learn OVER and OVER again.</p>












    <h3>Dilutional Forks</h3>

    somewhere....
    each mutually exclusive N-way choice divides resources expontially in the number of such force choices.



    <h3>xxxx</h3>

    Key MFCs to oblit:
    <ul>
        <li></li>

    </ul>





    <!----------------------------------------------------------------------------------------------------------------->
    <!----------------------------------------------------------------------------------------------------------------->
    <!----------------------------------------------------------------------------------------------------------------->
    <h3>FALSE FORKS</h3>

    mostly are assumed rather than asserted choices.
    or simply practical choices.

    Either way the result is both <d>Exponential Dilution</d> and dis-allows simultanously leveraging the advantages of each.


    <h3>Beauty <i>and</i> Brains</h3>

    <h4>Syntactic beauty vs. Meta-programming Flexibility</h4>

    Aparent impossibility:  semantics free parsing of human-beautiful syntactic forms

    In nearly programming languages, valid source form is defined <i>textually</i>.
    This seems reasonable, since source code is text after all.  But this unconsidered choice all the
    difference makes.  It means that meta-programming can only occur at the TEXT level.

    Those languages

    But the path





    <!----------------------------------------------------------------------------------------------------------------->
    <!----------------------------------------------------------------------------------------------------------------->
    <!----------------------------------------------------------------------------------------------------------------->
    <h2>CRACKED ABSTRACTIONS</h2>

    Abstractions that lead the hapless user (end-user or programmer)
    to imagine that they are operating within the abstraction itself.

    Yet intended execution cannot be achieve w/o understanding and
    indirectly manipulating the layer below the abstraction.

    sometimes authors admit this failing, but just as often they are
    two faced.  at one time promising this beautiful higher level,
    but then inconsistently providing the lower level details
    in a requirement that the user deal (usually INDIRECTLY)
    with the mess below.

    Either with humilty, or as a "declared feature" these cracked abstractions
    cause great pain.  Stack overflow is littered with poor souls
    trying to understand they things are not happening as they were casually lead to believe.

    <h3>FRACTURED MAPPINGS</h3>

    One extremely common, painful form of cracked abstractions is fractured mappings.
    This happens when person is lead to expect that the parts of A and the parts of B are
    somehow parallel to each other.

    <br><br>... and then they are not!<br><br>

    A classic form of this is nearly every ORM layer in existence.
    The user is lead to view the in-memory objects as parallel to those
    in the database that backs them.

    In reality they can become divergent, and the complexity of bugs surrounding this
    particular form of fracturing are notoriously difficult to understand and fix.
    Many programmers simply forgo ORM layers, not becuase having them would not be helpful
    -- they are a time&code huge savings.

    Until you have to fight with one of these bugs, then all the inital time savings
    whither away in late night bouts at the debugger.

    SHAME!

    <h5>code combination</h5>

    But at least ORM authors seem to have a bit of humility about these issues.
    No one seems to be claiming that these divergences are a *FEATURE*, or are
    somehow a good bit of flexibilty to have -- a bit of flexibility that
    one can productively use to solve certain problems!

    But those are *exactly* the claims that are made about most software combining mechanisms
    that exist in neary every modern software langauge!

    <br><br>
    There is a tacit "declarish" relationship between the the source code for these langauges,
    and the hierarchy of packages of things that results in memory when on executes those languages.

    But these mappings are BROKEN!  All manner and forms of divergence are possible between ones
    source code, and the resulting in-memory packages, modules, etc.

    And without a hint of embarrasment at this collossal mess, language documentation tells us
    we simply need to completely understand the sematnics and execution of all code touched
    during startup in order to understand whta is in memory -- and indirectly manipulating those in
    memory objects is really the name of the game, since it is those actual obects that control exection
    not the abstractions one might falsely believe when looking at the source code!

    <br><br>
    There is tradeoff here:  flexibiilty vs. simplicity.
    But here Lex beat them all.  At level of Uniform 100% mapping exists.
    At level of lexcore 100% mapping exists w/o backings
    At level of lexlang similar flexibility as with Ruby/Python AND nearly the same level clarlity
    as with Java.  e.g. editor can reliably show you the source code for a bit of stuff.




    <h4>STALE CACHE COMPLEXITY</h4>

    Virtually all practical languages have stale caching issues, these issues mostly stay out of the
    way, but when they bite, they ususally bite HARD!  One of the marks of an advanced user
    of a language or framework is whether that programmer understands the under the covers caching
    that the langauge uses well enough to solve stale cache issues when they bite.

    Many stack overflow pages are devoted to hapless programmers entirely flummox by this
    evil and largely needless class of complexity.

    Stale caching can occur ANYTIME a langague defines one bit of data in terms of another bit of data,
    and the language does not ensure the derived data is updated when the original is updated.

    This evil is absolutely pervasive!

    ORM layers expose object out of data with underlying store.
    Nearly every langauge has imparative package construction which can (and will)
    yield packages
    compiled files may not reflect the current contents of source code.
    JIT compilation can get out of sync with sources.  (e.g. python pyc files)
    class loaders
    execution envorinments
    class definitons

    langauge adherants will declare that this wont happen "if you use the languege in th right way"
    Ok, but why are we needlessly running with sissors here?
    My MUST the langauge allow the possibility of these parts getting out of sync?
    And if it is not an inherent reuqriemnt of the universe that such sync issues exist,
    why the heck to we allow them to persist.

    Either lack of imagination, or lack of diligence on the language author's part.  SHAME!








    <!----------------------------------------------------------------------------------------------------------------->
    <!----------------------------------------------------------------------------------------------------------------->
    <!----------------------------------------------------------------------------------------------------------------->
    <h2>USERS FIRST</h2>

    -- inverted pyramid
    -- each level larger than the last
    -- thus each level should care more about convenience of its users than its own convenience.
    -- but downward pressures are haphazard and incomplete.  thus users are rarely first, indeed
       are often not really considered as many of the most damaging choices are obliviously made.

    most programmers *think* they are considering their users, but since they don't actually live the lives
    of their users, they often fail at this even when trying.  Worse yet, for expediency, they don't always even try!


    Focus on MCFs and PowerToThePeople are in service of users first.







    <!----------------------------------------------------------------------------------------------------------------->
    <!----------------------------------------------------------------------------------------------------------------->
    <!----------------------------------------------------------------------------------------------------------------->
    <h1>SEMANTIC OBITERATIONS</h1>




    <!----------------------------------------------------------------------------------------------------------------->
    <h2>DECOMPLECTING OBLITERATIONS</h2>

    Practical software is large.  If you must understand something about one whole subsystem
    in order to understand one part of the whole, the mental costs skyrocket.

    Certain application logic requires understanding the whole, docmposition is impossible.
    This complecting is inherent in the algorithm itself -- if that is the best algorithm, then
    this is an UNAVOIDABLE complexity.

    Still most langauges needlessly force users to introduce complecting that is inherent detritus
    of the language itself, not of the underlying algorithm.  SHAME!

    <b>Needless Language-Imposed Compoenetial Complecting</b> is any case where parts of a
    software system could be more understood in isolation, but the langauge constructs themselves
    require needlessly deep understanding of other parts.


    <h4>Variable / Value / Name complections</h4>

    <h4>Declared type vs. Verified type</h4>

    In the software world, just as in the real world, things aren't always as they appear.

    It is useful to have and distinguish between an assertion that some data meets some expectations,
    and a validation that it does meet those expectations.

    Thus in Uniform we use the head of a unit as an informal promise the the underlying data adheres to
    some expected protocol, from a "type" which is a validation that it does, or MUST adhere to
    a specific type requirement.

    [[really should also distinguish between a static type, and a type verified on a given structure at a given time.]]



    <h4>Variable Storage Kind Complexity</h4>

    In many languages different kinds of variables are treated very differently.  So function parameters,
    local variables, global variables, static variables, closure variables, etc. all may
    have different syntax, operations available, and operational semantics.

    Many langauges have different categories of containers for these variables that all behave differently.
    Java's anono, inner, static, protected, diarreah of needless complexity is by no means the worse in this
    regard, but it is a great example of the affliction.

    ==

    In Lex there is a single semantic relationship between a piece of code (a lexical scope) and a variable.
    That is a semantic of unambiguous reference.  This means for a given execution of that code there is a
    durable association of exactly one variable place with each varaible name reference.

    And there is a single operation for altering these mappings:  Object allocation.
    In Lex, an object is "born" in a location (a Lex).  At that instant a fresh infinite subspace below that
    point comes into existence, and it is permanently tied to the infinite space above and around that point.

    Lex implements the full managerie of funky language constructs from this single elegant operation.

    --

    STRUCT

    OO-OBJECT

    DYNAMIC METHODS

    STATIC METHODS

    INNER CLASS OBJECT

    CLOSURE

    STACK FRAME

    SINGLETON



    <!----------------------------------------------------------------------------------------------------------------->
    <h2>Spooky action at a distance</h2>

    Albert Einstein was famously dissatisfied with theories based on <q>spooky action at a distance.</q>
    Analogously programmers generally agree that non-explicit effects within software systems are
    extremely difficult to understand, and should be avoided.

    Indeed most langauge scoping rules are all about enforcing explicitness in part connections.
    Still most langauges don't practice what they preach, they allow, condon, or REQUIRE spooky
    action at a distance in getting work done.

    Rails pervasive usage of monkey-patching in it core libraries is a particular egregious
    example, but even in some of the cleanest langauges like Go or Python, the construction
    of the execution environment itself has much spookyness in it.

    This is a tricky line to follow since obliteration of boilerplate is often done by adding
    "spooky" constructs...  still grasping boilder plate in hand on the left side of the table,
    and spooky action in hand on right side, then banging forehead forward enough, it is possible to
    mostly avoid both simultaneously





    <h4>Imparative Indirection Obliteration</h4>

    -- n
    Modern software is generally impratively defined (thru execution).
    This is a tragedy of unneeded complexity in the case that one is
    impratively constructing and a structured object.

    Understanding how each part of the constructed object requires full understanding of the execution.
    If the object is complex, then that construction will be complex.

    Each part of a "scaffolded computation" by contrast, can be understood by simply understanding
    the computation of the relevant scaffold part.  A spreadsheet computation or an HTML template
    are examples of these much easier to understand scaffold computations.

    Lex obliterates the distinction between the strcucture of imaparative code, and the
    structures produced by that code in the default case.  objects, packages, complex
    returned results are by default expressed in scaffolded form.  (Of course intermediate
    computations which do not map onto resulting strcucture must be handled using imarative
    construction.  Still the default is scaffoleded construction.




    <h2>GRATUITOUS CONCEPTUAL STUFF</h2>

    -- pattern divergence





    <h3>TIME</h3>

    Reasoning about time is extraordinarily messy, and complexity can result from both too much and too little
    specificity about time.


    <h4>COMPUTATION PHASES</h4>

    inherent complexity -- data dependency
    accidental complexity -- explicit phases -- synchronization issues -- update ordering issues -- multiple environments


    there is the time that a lex is assigned a value.  that is the only notion of time.

    there is no such thing as install time, build time, combination time, file loading time, parsing, binding,
    configuration time, compiling time, dynamic load time.


    OBLITERATE!!  In Lexspace there is no "time" when parsing happens, no compiling, no configuring.
    There is one time point: The time that a lex obtains new value.  that is the only time, and the only
    time that matters.  Any other lex whose value depend on that lex are now out of date.



    <h4>SYNCHRONIZATION COMPLEXITY</h4>

    two things are related, but there are periods when they are out of sync.
    often modern software systems partially hide this from the programmer,
    while useful, this partial hiding, can result is some of the most painful bugs to find and understand.
    reasonging about this can be tremendously complex.





    <h2>INFORMATIONAL COMPLEXITIES</h2>

    There is alot to know about with modern software systems.  The majority of the stuff we need to know
    is accidental complexity.

    <h3>Naming Complexities</h3>

    <h4>Case Complexity</h4>

    Case complexity is a small thing, but a stupid needless small thing, and Lex obliterates it!<br><br>

    Case complexity is the ambiguity that occurs when a language does not fully specify how
    case, underscore, abbreviations, etc. should be handled.  Thus even when you know what something is called
    you still don't know what identifier to use.  After years with the documentation you can memorize that it
    is Hashtable with a lowercase 't' but ArrayMap with an uppercase 'M', an underscore in URI_Element, but
    not in HTTPOpen, lowercase abbreviation in url_array, but not in URL_map.

    Lex mostly uses snake_case, but has 3 rules, which control exceptions which allow Lex follow
    paradigms used by existing langauges, and also to specify where underscores should occur and where words
    should be connected without underscores.  Lex largely obliterates this complexity by fully specifying the
    mapping from a sequence of words onto the space of identifiers.



    <h3>Power to the People!</h3>

    A languge core should never enforce a constraint on the programmer which is not inherent to the operation
    in question unless it is inconceivable that one perform said operation in that way.

    Still guidelines and constraints can be quite valuable not just for the authoring programmer, but often
    even more for the hapless soul that must later understand that code.

    Language awesomeness is achieved when it allows a programmer (and society of programmers) to collectively
    choose when which places to tighten down, and which places to allow free.

    Importantly for the creation of strong DSLs, it is critical that <i>DSL</i> specific rules be in effect.


    <p>

    Many other TOmato, toMAto choices are made by lanaguage designers based on one kind of expected
    application or another.  SHAME!  Provide all choice to the programmer and let them choose based
        on their application context.  If a choice has negative consequences, then define a conformance
        rule and allow programmers to choose to adhere or not.

        for example, whitespace sensitivity is a choice.  Why should the langauge designer force a choice
        if they need not?

    </p>


    <br>=====================================<br>


    <h2>Complexity Obliteration</h2>

    <p> The accidental complexities below are such a part of software systems that it is hard to even conceive
        of software without them -- yet that is the claim being made here.  Lex provides a framework which allows
        one to completely eliminate or drastically reduce the accidental complexities below.  Before we
        re-imagine software systems, lets first list out the many types of complexity that are in our gun sights: </p>


    <h4>VARIATION COMPLEXITY</h4>

    Variation complexity occurs when two components achieve a similar end

    <br><br><b>API VARIATION COMPLEXITY</b>


    <br><br><b></b>
    <br><br><b></b>
    <br><br><b></b>
    <br><br><b></b>
    <br><br><b></b>
    <br><br><b></b>


    <br><br><b>FORMAT COMPLEXITY</b> -- Using a presentation format which is not adapted to the meaning of the
    data presented can result in trival but very damaging accidental complexity.

    <br><br><b>BOILERPLATE COMPLEXITY</b> --

    <br><br><b>VOCABULARY COMPLEXITY</b>


    <h4>DOCUMENTATION COMPLEXITY</h4>

    <br><br><b>CASE COMPLEXITY</b>


    <br><br><b>VOCABULARY COMPLEXITY</b>


    <br><br><b>SEMANTIC COMPLEXITY</b>


    Sadly nearly all of

    Operating on computing systems is needlessly complex, and that
    needless complexity costs considerable time and money to overcome.




    <h1> Unsorted Stuff (skip to next section)</h1>
<pre>



    WHY
    -- Language Writing Laguage
    -- Declarish.  why is primitive.  TMS.
    -- ProcLang--

    SUMMARY
    -- Multiplicative Cluster Forks


    OUTLINE




    -- distinction obliteration does not mean they are the same, it means that they are distinct usages of an underlying unified form,
       such that parallel usages can result from identical code.

    == VISUAL COMPLEXITY ==
    -- K-complexity : thing : name : case
    -- K-complexity : thing : name : word structure
    -- K-complexity : thing : signature : arg-order

    -- Vol-complexity : boilerplate : fn_repack
    -- Vol-complexity : boilerplate : un-needed-header-complexity


    == BIJECTIVE OBLITERATIONS ==
    -- making two different kinds of things become one thing
    -- semantics free parsing  :  making textual printed form become the data form



    a structured-thing, an iterator over a structured-thing


    exiting a function, terminating a process   ???  exiting a loop, exiting to a catch

    == MANIPULATION DISTINCTIONS ==

    -- destructive type changing (set_head) while keeping sub-structure intact

    -- NULL POINTER -- running off the ends of lists
    -- NULL POINTER -- running off the bottom of structures
    -- NULL POINTER -- jumping to a place that is not yet created (down tree, or over list)









</pre>



    <footer>
        Copyright (c)  Daniel Oblinger.  All rights reserved.
    </footer>


</div>
</body>
</html>


