# 2023-W34
- [ ] [[2023-08 Ingest Alternatives Analysis]]:  many tasks
- [ ] Interviewing BBI questions
- [ ] Eli schools


### Mon
- [x] [[Repeat]]
- [x] cycle
- [x] [[2023-08 Ingest Alternatives Analysis]]: Taskings
- [x] [[BKT]]:	Cycle

### Wed
- [ ] cycle
- [ ] Interviewing BBI questions
- [ ] Eli schools


### Thr
- [ ] Send BBI questions
- [ ] cycle
- [ ] Segments Task
- [ ] CV test
- [ ] Add tracking

### Fri
- [ ] hiring sync
- [ ] Edits on [[2023-08 Ingest Alternatives Analysis]]
- [ ] Eli school


In general ANY data source we can get our hands upon is gold for our team to at least be aware of.  Lets at least put these pointers into the technical channel!  and have a discussion about how they might be used.


But we should not think about data like we think about water.  It is not an interchangeable quantity.  The devil is really in the details.  Our system now has many dozens of modules with over a dozen that have been trained in one way or another.

Typically each of those module was trained on data that was framed specifically for training that one module.  Of course it IS possible that we can start from one of these data sources and transform it in order to use it for one of these modules.

My sense is from an efficiency point of view we should be starting from the modules in question:  (1) Recognizing which ones are failing us, then (2) analyze why it is failing, often more data isn't the fix, but the approach is wrong.  But certainly sometimes more data IS of big value.  then (3) we need to figure out exactly what data will have value, and finally where could we get that kind of data.

Still it Is very good to just generally know what data is out there... it can spark new ideas about how to train systems!

This sprint we are having each of the guys dig into the errors that our system makes on shooter ID.  Just trying to get a basic handle on where our issues are.  

I dream of a more exhaustive error analysis within our system, but we will need to invent metrics that can tease out where the problems are.... The key is tying the analysis directly to actionable changes within our module structure....  so the data needs to match that well.

Still end to end stats from many games, does have a place in all the data we collect.  The taxonomy of errors analysis that I want before the end of the year would need such data.  But it will likely require paying folks to analyze each failure of our system along with metrics coming out of our system in order to really diagnose things.  The good news is that perhaps the columbian team can be trained for this work once we get far enough to undertake it!