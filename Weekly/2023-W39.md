
# W39   2023-09-25   [[2023-W38|<<]] [[2023-W40|>>]]
- [ ] [[Repeat]] 
- [ ] CVtest

#### Mon-25
- [ ] [[Repeat]]
- [ ] CV test
#### Tue-26
- [ ] 
#### Wed-27
- [ ] 
#### Thu-28
- [ ] [CV test](https://docs.google.com/document/d/1iXhyfyjxna2zGiUs9bg3wmx33DFQrIowdienVyfZVD8/edit) - finish it.
#### Fri-29


In our last management meeting I brought up the issue of hard coded groupings of teams, users, leagues, events, etc. in our tables, and when/if we generalize this.  The top of the doc here give a little more on the intended use cases, here is a quick list:
- Permissions where sub-administrators, coach-assistants, etc can flexibly manage/delegate control to others, private viewing with flexibly defined viewership scope.
- dynamically defined groupings of players, users, teams, games, 
- rollups computed over any combination of these automatically
- top-10 style lists sorted by any dynamically specified attribute of the data
- Skinning our app for other sports

And with typical Oblinger bravado I said, "I know the down stream integration of this stuff will require lots of refactoring, so maybe this should be saved until after the A-round, but I could slam out a reference implementation of its core in a weekend in Python."

So Jack wrote me today and said,  "So Dan, ya gonna slam that out this weekend?"   He actually asked for a "high level architecture" which is less than I brashly claimed.

I can do either of those things, and the coding would be fun.  But should I?  My sense is I won't really finish a debugged version of this on Sunday (which is the only day I have this weekend). But I bet I can get the the data structures in place and the major algorithms written.  I think much harder than slamming out the <1000 lines it gonna take for the core, will be the writing up, testing and debugging the many many unit tests that would would really want to have for such a fancy piece of code.  So one idea would be to just code all the fancy bits, and show how they all fit together, but never complete it do all the unit tests and debugging.

I will be fun to code this, but I don't want to be wasting time here just for the fun of it.  All of you guys are more than capable of understanding DAGs, how to build them and how to use them, even ones that are managed via a change log.  I wont be adding value by showing that.  Here are the parts that I think are a little fancy and might benefit from some clarification in code:
- It seems our rollups will involve data that cannot be mapped directly onto any fixed DAG structure, but instead would be dynamically constructed and cached in memory using some kind of LRU mechanism.
- It seems permissions naturally relate to a node in the tree representing the actor given permission, and a second node which is the asset over which the permission is given.  Again this derived data cannot be compactly expressed directly in the DAG structure, so I think we need to dynamically build a permissions cache for each active user.

My thinking is that even assuming large user growth we can formulate these structures so they fit into RAM on a moderate AWS instance w/o sharding or other tricks until well after the A-round.  And I *think* our users usage patterns allow us to just keep the most recently 100 or 1000 users and rollups dynamically constructed in ram, so even these dynamic structures would remain performant.  Is writing these data-structures and algorithms out even if I don't fully flesh them out, worth doing?  

Happy to do it, just checking first.




And if needed, I think I could fully code it with unit tests and all in a week, but that 






Miles = 2.4%

50K miles ~ 25K spent ~ $600



sep25	16,843.33
		-16,843.33
sep20	16,843.33

Chase Payments 855-267-0428  M-F 8e
Aug23		16,843.33
Sep23		7,477.42

@Michael Seibert ok!  then we will propose a system using Ball tracking, person tracking, AND pose estimation.  I like it!  Still I am think trying to identify the tracklet that has ball possession is probably easier than identifying change in posession.  In order to do that they will need to know which tracklets belong to different people.  We could have associating tracklets as level one, and identifying change of possession as a stregth 
Hey, @mig don't be biting your tongue!  Let's think this stuff thru and make our best plans.  This is my thinking:
- Of all the users segment and all ingest approaches I think it can be boiled down to four key cases:  Cloud, Fixed, Mobile, TryBeforeBuy
- We have errored in trying to build scaled software as a first step.  Instead I want to build human driven first versions of all four as a first step, then allow actual sales growth drive prioritization of automation.

So I was not prioritizing fixed first.  I was just prioritizing which ever one I could get live THIS WEEK first.  My try-before-you-by "share button" approach is also one that I think we can do with ZERO code.  Thus a plan is to essentially do that one at the same time as fixed cameras with the ops team.  I was focusing a bit more on the fixed camera one, just because it was a bit more complex to get all the parts ready.  But really the plan is to have the ops team ramping up on BOTH of those cases at the same time.

I know there will be many bumps in making this work well, so I am anxious to just have someone NOW trying to do these flows.

And of course we already have a Cloud ingest working regularly with Cerebro games.  And right now the Portable solution is kinda kicking my butt, I will save discussion of that for another note.

TL;DR.  I am not trying doing fixed first, I am trying to do them ALL manually now.

Thoughts on this from anyone?




.  I am trying hard to not have sports visio assembly required, but the UX I am able to create with devices I am finding (even looking)


J & S:

FIXED CAMERA RAMP UP
Should we accelerate our ingestion ramp up?

Mark if we have fully automated fixed-camera ingestion working today, how quickly could you find customers?

Miguel has been hard at work getting a BPO setup to automate our game ingestion, but he estimates 4-6 before they can start work with us, and of course that timeline could slip.  Today Achilles solved the last issue in manually ingesting games from fixed cameras.  I don't want to wait 4-6 weeks to begin working out the kinks in the process, I would like to be regularly ingesting fixed camera games today.  What resource do we have inside the team that could learn this task, execute it, and teach Miguel's team when they are ready?



already 55% 



- Shots the don't count (time outs)
- Player ID no where in sight
- Player ID not unique


- Shot detectors (block shot)
- Other algorithms not working
	- 2/3 point line



@Grzegorz Biziel I was thinking about the bounding problem 


@maxim what do you need in order to do good training here?  Lets write up some sentences as a spec to Realplay.  e.g. how many different games?  We want to tell them they should "cover the range of variation" but it will be good to give them examples of differences they should consider.  e.g. different resolutions, different camera angles, different lighting conditions, etc.  what matters the most for them to cover?  Can you write some sentences that I will forward to them as a request?  thx!!
