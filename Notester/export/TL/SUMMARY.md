# TL.SUMMARY --

    - both teams

    BERKELEY
      GRASPING
      - MIT:  Object Grasping By Demonstration  (learn which grasp; learns parameters of grasp)
              features for grasp type decision; transformation operators; features for transformation space search
      - Stanford:  Predict best grasp from images.  Given Image predict grasp behavior

      OBJECT RECOGNITION
      - MIT:  chair recognition   (using relational regions)
      - Stanford:  shape recognition  (use outlines;  predict point; predict entire outline location given pixels?)
      - OSU:       Stratigus:  goals=Gather&Tactical   Delta=

      STRATEGUS

    ISLE
      ISLE
      CYCORP
      Nau & U. Maryland & Lehigh U.
      Pazzani
      Mooney
      Stone.  RoboCup
      Forbus


    ISLE - DOMAINS
    - INT.   Urban Combat  (human comparison ratio to human)
    - EXT.   GGP
    - Phy. 
    - Robo.  


    NRL




       

    --------
    Slides:
    - overview of all experiments
    - drill to results.
      - Each result: what axes mean, algorithm for exp setup, statistical significance, 
      - Comments on: degenerate case, funky bumps etc., 
      - Pictures showing: data, output, features
    -----------------



    ? which version of TL


    - Space of transformations    (should be learnable in cumulative learning system)


    Real comparison:  hard code adaptive general grasper  vs.  TL approach




    - Assumed affine transforms, found best one, used it later.
    - Assumed *some* math transforms (expressible as small lisp expression over predefined math/logic operators)
      learn which are appropriate in world, iteratively home in on useful versions
