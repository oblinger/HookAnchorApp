# life.76\_DARPA\_Morality2 --



    WRITTEN 06/29/07 BY DAN OBLINGER


    I am weighing the possibility of embarking on a new seed effort that I believe could herald
    a radically new chapter (possibly the last chapter) for humanity.  I am not convinced it is 
    necessarily a better chapter for humanity, though it does have tantalizing possbilies.
    I am committed to acting in a way that is in the interests of all, and not just in my
    personal interest. 

    THE POSSIBILITY
    A Bootstrapped AI (B-AI) is a relatively small adaptive algorithm applied on a massive scale 
    in a way that yeilds run-away bootstrsapping.  The system is able to build levels of understanding, levels 
    of redesign, levels of improvement, and levels of capability on prior levels in a self-sustaining loop 
    with indefinite extent.  Humanity is such a bootstrapping intellignece, B-AI refers to the same 
    run-away effect implemnented in silicon.

    The conjecture considered here is that such capability might be generatable from a relatively small/simple
    seed adaption algorithm.  What are the practical,m societal, and moral consequences of engaging in such work?
     Here is my thinking:


    ===================================================
    ===  PROVIDING THIS TECHNOLOGY TO THE MILITARY  ===
    ===================================================

    This is the easiest concern to dispense with.  It is clear that this technology will admit
    profound changes, and that it will reinvent warfare.  It will put letal capability in
    non-human hands.  Society will be more cautious about this step than they are about providing
    that power to humans.  Yet this technology will be more understandable (at least in the short run)
    than human.  In the long run, I dont think the chances that we end in a robo-takeover will
    be greater given that the military develops this technology.  It will be the dramatically higher
    intelligence that is the true threat, and that threat will be with us regardless of where that
    intelligence resides.


    =======================
    ===  A JOB FOR ALL  ===
    =======================

    I believe the automation technologies (bootstrapped AI being only one) will generally do to codified knowledge work, 
    the same thing that robotics has does to assembly line workers.  Largely replaced the lower levels of the job, 
    and pushed the remaining jobs up into less codified spaces.

    The problem (at least in the short run) is not that there will be no jobs, but rather that the jobs
    that remain will be increasingly out of reach for an increasingly large fraction of the population.
    This places enormous pressures on a 'free' market.  Essentially those free to persue happiness will find 
    that quarry elusive, since being a productive member of society will be harder.


    (1) AUTOMATION TECHNOLOGY SEPARATES RICH FROM POOR

    (2) AUTOMATION AND THE THIRD WORLD WILL COMPETE FOR THE SAME JOBS
      If a job can be abstracted, digitized, and the approach codified then such a job is more amenable to automation.
      It is also the same type of job amenable to international outsourcing.
      - IT SUPPORTS RICH COUNTRIES AND DEPRIVES POOR COUNTRIES ACCESS TO THOSE LOW END JOBS in rich coutries REPLACED BY AUTOMATION

    (3) AUTOMATION TECHNOLOGY MAKES MOST EVERYONE WEALTHIER

    (4) AUTOMATION RAISES THE LEVEL, CREATIVITY, AND MOSTLY ENJOYMENT OF MANY OF REMAINING JOBS

    (5) THIS ISSUES IS NOT REALLY ABOUT BOOTSTRAPPED AI.  RATHER IT IS ABOUT MOST ALL AUTOMATION TECHNOLOGIES

    (*) MY TECH AFFECTS CLERICAL WORK MOST OF ALL


    (6) ULTIMATELY SOCIETY MAY NEED TO ADOPT A NON-WORK BASED VALUATION MECHANISM
      This could happen naturally.  As goods of life become commodities that require little human effort from anyone to
      produce (includeing the acquisition of raw materials and energy) then the cost of those items will drop.
      A welfare state will be easy to afford.  freed from the need for basic goods all will focus on goods that are
      somehow restricted.  All forms of Intellectual Property could fit this, and could the value of the attention of
      fellow humans.  

      If society does not have work as a social destinguisher, then possibly people's creative efforts will be
      come the social currency to replace money.  

      This feels like the next evolutionary step of mankind... stopping it, would be like terminating a progression
      from an agriculturally based society because of the costs associated with the transition.

    (7) AI AUTOMATION TECHNOLOGY SEEMS SIMILAR IN EFFECT TO TEXTILE, MANUFACTURING, OR AGRICULURAL AUTOMATION
    This work is one instance of a very large trend prevelant since the industrial revolution:
    Technological advancement increases the wealth of all by producing more using fewer better trained bodies.
    Left uncompensated this divides the rich and poor.

    (8) INCREASES IN WEALTH HAS AFFORDED SOCIETIES ABILITY TO PROVIDE A STRONGER SAFETY NET FOR ALL
    It provides the basis for a welfare net which supports the poor.  (Of course it may not decide to do that.)

    (9) FEW PEOPLE WOULD WANT TO ROLL BACK BEFORE THE IND. REVOLUTION.  IN FIFTY YEARS FEW WILL PROBABLY WANT TO ROLL BACK AI?
    In a sense in arguing that one should not persue this technology, I am arguing that I know better than society as a whole.
    Or maybe that most is society see it too, but like the dieter that cannot resist the cake, is unable to relinquish 
    that which harms.  But the question is in 50 years will we wish we didn't open the box?

    (10) PULLING BACK FROM A TECHNOLOGY IS NOT DENYING SOCIETY A CHOICE, SINCE SOCIETY CANNOT CHOOSE NOT TO ADOPT A USEFUL TECH, IT NEVER HAS A CHOICE.

    (11) SOCIETY IS IN TRANSITION.  SOME NEW SOCIAL ORDER MUST EMERGE FROM AUTOMATION.  CANT TELL IF IT WILL BE BETTER.
    Supporting this automation will get society to its new order faster, especially since it will displace peoples at 
    many differnt levels of the current status and wealth chain.  Such displacements may well build political will for
    change with many fewer people being displace, rather than a purely bottom up displacement which might happen with a 
    less AI centeric automation.  It is not that I don't believe the prior ...

    (12) MY FANCY AUTOMATION WILL ONLY HAVE IMPACT IN LATER STAGES OF AUTOMATION
    Makes it harder to predict how society will be responding.  Rapid shifting of high skill high pay jobs to machines 
    could hasten what ever world order works in a world where many do not need (and don't have the skills) to work.

    (13) EXISTENTIAL THREAT MORE IMPORTANT



    SUMMARY: 
     * This technology, like automation before it, improves overall wealth, and separates rich from poor. 
     * Considerations of the existential threat trump concerns of this transition period (since all of this will happen anyway)
     * Specific automation I am considering will have impacts only in the longer term.
       - harder to predict overall consequence since humanity will have need to adapt
       - may precipite such adaptation since this tech will automate upper middle class jobs
       - current period is a transition period if correct such tech will lead society will adopt some other non-worked based organization.
     * Technology do have different base propensities, but it is up to society to use tools provided productively, 
       not to me to preclude that action, by not creating the tools.  And ultimately it is not up to any of us today to attempt to limit
       choices those of the future might make.  (But perhaps I should focus some efforts toward needed societal changes.)





    ================================
    ===  THE EXISTENTIAL THREAT  ===
    ================================
    The threat to the existence of humanity is real, and it is close at hand (within the 
    lifetime of those living today).  Moores law will not stop in time, we will far surpass
    human coginitive processing power.  Given the right software these systems will surpass 
    out cognitive abilities.

    I cannot see how we can indefinitely avoid constructing such technology (if it is possible).
    Too many aspects of the technology will be too useful for too many important applications.

    Our only escape is to somehow grow with this technology.  We must form a link in the value 
    chain, even if that part grows thinner with time.  The only two solutions I can conceive of
    is (1) that humans are progressively augmented in a way that we feel humanity has survived even
    though it ultimately has little or no physical relation to humans today.  Or (2) the humans of
    the future are handled by race of systems with vastly greater power and capability.


    Really the only part of this future that we can control is the way that we enter this phase.
    There will not be one intelligent system there will be many, and the instruction and operating 
    conditions of each will be unique.  The culture that emerges will emerge from existing human
    culture.  The goals and aspirations of these new systems may be drawn from this context.
    If so, it is critical that consider what this culture might be.

    Today humanity does not even have this 

    If I were to decide one should not persue this, it would be because of #3


    (1) REACTION TIME        POSITIVE FACTOR.   SIGNIFICANT FACTOR.
      Humanity need time to react contructively to a new reality.  Right now conscious computers is not
      really on the radar as a real threat.  The sooner we have them, the sooner we formulate an approach
      to dealing with the new reality (if there is an approach).  Initial systems will not be a threat.
      The point when they become a threat is tied to moores law, so the sooner we have such systems the 
      greater the total time that humanity has to constructively react.

    (2) BASE STABILITY AND COOPERATION       NEGATIVE FACTOR.  MUCH LESS SIGNIFICANT THAN #1.
      Humanity is developing international mechanisms that allow humanity opportunities to constrain humanity
      for collective common good.  (e.g. the UN)  As such institutions mature, their ability to set
      and maintain a consistent world policy increases.  Such abilities could afford humanity 
      options (other than the market forces solution) to the way we approach the singualarity.

    (3) A RACE BETWEEN ALTERNATE TECHNOLOGIES     NEGATIVE FACTOR.
      One potentially positive path forward is one where humanity 'grows' with the capabilities of our silicon
      counterparts.  This is the primary path for symbiosis rather than obsolecence.  This alternatives require
      some mechanism to bridge the two types of cognition.  Two technologies suggest themselves:
      first one could model an individual human brain in a way that it could be simulated in silicon.  This
      would put that brian on a Moore's law path (though likely several orders of magnitude behind a AI brain 
      given the same hardware).  The other possiblity is to interface with the meat brain at a deep enough level that
      the thinking is truely symbiotic (rather that simply talking between two brains without lips)
      Both technologies could be possible, but both seem significantly further behind developing consious AI.
      In fact they seem so much further behind complexity of building a bootstrapped-AI, that it is hard to see 
      how we could get there before the AIs.  (Unless a bootstrapped AI is impossible, but in that case this
      decision is moot anyway, since these efforts cannot by assumption harm humanity, since they will not result in an AI.)

      Assuming Bootstrapped-AI is possible, I believe this race will be lost no matter what.  The only question 
      is how many decades separate the two events.  While I think this is relevant, the most relevant time
      periods is the time between moores law run away and human machine connection.  (At some point
      moores law is sped up by the capabilities of the AIs themselves, when this happens all bets are off)

    (4) A FEW MORE YEARS        NEGATIVE FACTOR.  NOT VERY SIGNIFICANT.
      Well maybe we are just screwed... the clock is ticking, and there is no wires to cut in those last seconds.
      If so, am I dropping a few hours off the countdown.  Almost certainly yes.  While much hangs in the
      balance, there is just too much uncertainty about effects of our approach to the singualarity for
      us to base our decisions on saving a few minutes.

    (5) SOCIAL SHEAR FORCE   ???? FACTOR.
      Distruptive technologies cause social upheval.  Humanity's abiltity to deal constructively with 
      new realities, decreases as the number of simultaneious changes for a give time period increases.
      Thus introducing this new technology earlier potentially increases (or decreases) the churn 
      that exists during the critical reaction period.  I see arguments for both directions on this
      but it seems less of a factor, since I think churn will remain high for some time.

    (6) SHOCK VALUE   COUNTER FACTOR.  NOT SIGNIFICANT.
      By waiting, we might have a greater shock impact on humanity.  When nuclear weapons were first 
      demonstrated they came from nowhere socially speaking.  Because of that, humanity was galvanized to deal with the
      threat.  Today that threat is largely under played by humanity.  It could be the same, by
      having conscious computers early on, may get people used to the idea, before they existential
      dangers are immediately at hand.  Still I feel the possiblity of replacement is so obvious that
      it will remain palpable for many years (especially as base capability of systems grows exponentially)

    SUMMARY:
    * I believe that development of 'cortical compliant' algorithms is quite possibly a key stepping stone
      on the way toward super human conscious systems.
    * I believe that immediate consequense of such technology is mediated principally by our position on
      the Moore's Law curve of computational power, and that developing them sooner affords humanity some
      extra years to react constructively.
    * I do not believe that Moore's Law will stop in time to avert this.  And I believe if such algorithms
      are found through my agenda, they would have been found without that agenda.  It is not plausible that
      simple cortically compliant algorithms are there to be found through this agenda, yet somehow are
      not sought and discoverd without it.  Indeed, even if I am arrogant enought to belive that I have 
      particular perspective, foresight, energy, and position as a PM, to do what others cannot, I still
      cannot conclude that it is my actions that make the difference.  If this idea is doable, it will 
      be done, there are simply too many minds coming at related problems from too many angles for anyone
      to hold such a decisive role.
    * I believe that society would not, and could not stop the creation of such technology if it is possible.

    If the basic hypothesis is true that a small algorithm can self organize to intelligence, then it is
    only a matter of when it happens.  And if it is not possible, then this program causes no harm.

    As to the question of when we demonstrate a conscious computer: I believe the safest answer is as soon as possible.


    -----
    A CODICLE

    I intentionally did not want to allow the following spiritual considerations to enter into my decision 
    making thus I avoided their consideration above.  It is not because they are not appropriate, but rather
    because they are my personal perspective, and I do not feel 'authorized' to consider them in this decision.
    They are opinions that may not be shared by humanity as a whole, and thus using them as a basis on this
    decision seems dubious.  (Making the decions itself in silence also seems dubious, but even if I choose
    otherwise, our technology as a whole continues to move in this direction rapidly.  Demonstrating the viability 
    of this approach provides humanity with the opportunity to shape its implementation.  I cannot see a sequence
    of events that would cause humanity not to proceed except stopping the march of moore's law.  This is
    a step that will probably never be taken, but if it were it would only be because the danger were 
    clear, and immediate.)

    My spritual consideration is to question if preservation of humanity in any form that we would recognize today 
    as somehow human is the prime consideration here.  It seems a larger context should include the desires and
    the rights of those consciousnesses yet to be created, human and otherwise.  If the true nature of intelligence
    computable, then can we really assert the supremacy of our current form over others that are possible?

    Further if there is a spiritual basis for the actions of man, and the truth of the actions of man is that
    they are reducable to computation, then is seems core spritual notions like good and evil will be emergent 
    from our silicon offspring.  In this world today grace dictates that we take the leap of faith in trusting 
    in the ultimate goodness of our fellow man, it is through this leap that goodness emerges from the whole.
    Perhaps our ultimate survival in a world controlled by those beyond us is best ensured by beginning the process
    with an act of faith at that time when we held all the cards.
