.[[ABio]].  [[@Github]] [ABIO Folder](spot://ABIO~Folder) 
   TOP:	[[ABIO.]]  [[ABIO Log|Log]], [[AlienBiologyWhitepaper (do not distribute)|Whitepaper]], [[ABIO Results|Results]], 
   EG:		[[ABIO Photosynthesis]],  [[ABIO CellMetabolism5]],
   REF:		[[ABIO References]], [[ABIO Systems]],
   WP:		[[ABIO Behavior Templates]], [[ABIO Generator]]
   LISTS:	[[ABIO Prompts]], [[ABIO Queries]], [[ABIO Tasks]],



# LOG

### [[ABIO Task Example]]
### [[Measuring Intelligence]]
### OUT TAKES


**Problem**: Because LLMs are constructed from such colossal training sets, it's hard to find tasks to assess their ability to perform truly novel reasoning as opposed to some sophisticated form copying from its training data.

**Problem**:  It is difficult to assess the learning/inference performance of LLMs over novel tasks since nearly any complex task we might use likely already has connections to texts used to train that model.  Perhaps all of its learning and inference are just sophisticated forms of copying.  How can we tell?


**Problem**: It's difficult to assess complex LLM reasoning since nearly any complex test task is tainted by likely but unknown relation to the texts used to train the LLM.


